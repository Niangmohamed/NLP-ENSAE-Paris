{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"TP4NLP.ipynb","provenance":[],"collapsed_sections":["iVTZd85T3fIY","yyf3KO_a3fKA"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"G9Guq-DP3fD2","colab_type":"text"},"source":["### ----  \n","\n","requirements (if run locally) : \n","- `conda create -n td4 python=3.6`\n","- `source activate td4`\n","- `pip install jupyter`\n","- `pip install torch torchvision`\n","- `conda install -c conda-forge spacy `\n","- `python -m spacy download en_core_web_sm`\n","- `cd ./td4`\n","- `jupyter notebook`\n","\n","### ----  \n","\n","\n","\n","# Machine Learning for NLP : TD 4 \n","## _Description_\n","\n","### Course takeaways\n","\n","### TD outline \n","\n","1. Introduction to pytorch\n","2. Sequence Labelling with pytorch\n","\n","\n","### Resources : \n","\n","https://pytorch.org/tutorials/  \n","https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html    \n","https://stats.stackexchange.com/questions/268202/backpropagation-algorithm-nn-with-rectified-linear-unit-relu-activation   \n","https://ruder.io/optimizing-gradient-descent/"]},{"cell_type":"markdown","metadata":{"id":"N30J_iCf3fEC","colab_type":"text"},"source":["## Pytorch\n","PyTorch is a Python based library for scientific computing that provides three main features:\n","- An n-dimensional Tensor, which is similar to numpy but can run on GPUs\n","- Easily build big computational graphs for deep learning\n","- Automatic differentiation for computing gradients \n","\n","Usages : \n","- It’s a Python-based scientific computing package targeted at two sets of audiences:\n","    - A replacement for NumPy to use the power of GPUs\n","    - a deep learning research platform that provides maximum flexibility and speed\n"]},{"cell_type":"markdown","metadata":{"id":"3II9uLKW3fEF","colab_type":"text"},"source":["## Pytorch basics\n","\n","**NB** : Tensor are the basics block of pytorch. Tensor allows to store data (input data or target data) as well as the parameters (also called weights, neurons,...) of your neural network.\n","\n","\n","- tensor creation \n","- tensor types \n","- basic operations between tensors\n","- from and to numpy \n","- about GPU "]},{"cell_type":"code","metadata":{"id":"FITe7Hhp3fEK","colab_type":"code","outputId":"bbb50014-5834-4c24-edf0-19b7063d28e9","executionInfo":{"status":"ok","timestamp":1585563700529,"user_tz":-120,"elapsed":1046,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xDkgzVe13fEd","colab_type":"text"},"source":["### Tensors\n","\n","\n","**What is a pytorch tensor ?** : A torch.Tensor is a multi-dimensional matrix containing elements of a single data type.\n","\n","Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n","\n","**How to define a pytoch tensor ?**\n","- using existing constructors : _torch.ones_ , _torch.zeros_ _torch.rand_\n","- based on existing object\n","    - from another tensor (or only using the shape of the other tensor)\n","    - from a python list \n","    - from a numpy array"]},{"cell_type":"code","metadata":{"id":"DzPgaeY13fEn","colab_type":"code","outputId":"df1e56cb-ea20-4ecc-dd30-a5446f96c363","executionInfo":{"status":"ok","timestamp":1585556106498,"user_tz":-120,"elapsed":1065,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["# define \n","ones = torch.ones(3,2)\n","# a tensor can be printed\n","print(ones)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[1., 1.],\n","        [1., 1.],\n","        [1., 1.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-eW3NOwG3fFE","colab_type":"code","outputId":"72dd1475-0785-4f0a-c320-08220a7c5abe","executionInfo":{"status":"ok","timestamp":1585556116551,"user_tz":-120,"elapsed":1339,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["# other basic definition \n","print(torch.zeros(5,3), \"\\n\", \n","      torch.rand(2,3), \"\\n\", \n","      torch.empty(2,2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]]) \n"," tensor([[0.3339, 0.6934, 0.3167],\n","        [0.3809, 0.1759, 0.6248]]) \n"," tensor([[2.5898e-36, 0.0000e+00],\n","        [0.0000e+00, 0.0000e+00]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nS_i19lt3fFQ","colab_type":"code","outputId":"5844bf10-3c5a-48ec-bd25-e851f807dd18","executionInfo":{"status":"ok","timestamp":1585556140255,"user_tz":-120,"elapsed":1309,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["# from a python list \n","ls = [[[1,3,5,6],[-1,4,4,4]],[[-1,-3,-5,-6],[10,-4,-4,-4]]]\n","tensor = torch.Tensor(ls)\n","print(tensor)\n","# from a numpy array : \n","array = np.array([0,1])\n","#array\n","tensor = torch.from_numpy(array)\n","print(tensor)\n","# symetrically  tensor.numpy()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[[ 1.,  3.,  5.,  6.],\n","         [-1.,  4.,  4.,  4.]],\n","\n","        [[-1., -3., -5., -6.],\n","         [10., -4., -4., -4.]]])\n","tensor([0, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tRaSA_R-3fFp","colab_type":"code","outputId":"df8fed7b-5540-482f-effb-beb8ebfc549e","executionInfo":{"status":"error","timestamp":1585556176961,"user_tz":-120,"elapsed":776,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["# list must be in a proper matrix shape\n","ls = [[[1,3,5,6],[-1,4,4,4]],[[-1,-3,-5,-6],[10,-4,-4]]]\n","torch.Tensor(ls)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-0cbd3fccd9e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 2 (got 3)"]}]},{"cell_type":"markdown","metadata":{"id":"X-KGQ2hK3fGe","colab_type":"text"},"source":["**Basic manipulations**\n","- access type / change data types \n","- access elements \n","- reshape \n","- maths opertions : add, multiply , ..\n","- differentiate / derive\n","- set to a specific _device_ : GPU , GPU:0, GPU:1 , CPU ..."]},{"cell_type":"code","metadata":{"id":"Eu2aGF3j3fGt","colab_type":"code","outputId":"c759c044-ccb0-4773-83e0-5c230615afab","executionInfo":{"status":"ok","timestamp":1585556223738,"user_tz":-120,"elapsed":794,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["# get type \n","print(tensor,tensor.dtype)\n","# change type \n","tensor = tensor.float()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([0, 1]) torch.int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yz2gxNen3fHS","colab_type":"text"},"source":["**NB** : types are important in Deep Learning  because : \n","- some types are more memory consumming than others : e.g : float16 vs float32\n","- some operations require specific type (cf. Embedding layer ...)"]},{"cell_type":"code","metadata":{"id":"FThm_Rqv3fHg","colab_type":"code","outputId":"a6fa41f5-261d-45eb-f2f9-236ecd90480b","executionInfo":{"status":"ok","timestamp":1584520320951,"user_tz":-60,"elapsed":636,"user":{"displayName":"Jeremy Marck","photoUrl":"","userId":"00527775588178291504"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["tensor = torch.rand(5,2,2)\n","print(tensor)\n","# access one element\n","print(tensor[0,1,1])\n","# access several element\n","print(tensor[:3,0,:2])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[[0.9397, 0.6660],\n","         [0.9896, 0.9162]],\n","\n","        [[0.8674, 0.7286],\n","         [0.8566, 0.1337]],\n","\n","        [[0.0909, 0.9817],\n","         [0.2359, 0.2422]],\n","\n","        [[0.3359, 0.9101],\n","         [0.3049, 0.1896]],\n","\n","        [[0.5454, 0.8767],\n","         [0.0199, 0.9253]]])\n","tensor(0.9162)\n","tensor([[0.9397, 0.6660],\n","        [0.8674, 0.7286],\n","        [0.0909, 0.9817]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j5SGNZwf3fHv","colab_type":"text"},"source":["**NB** : pytorch tensor indexing exactly match numpy indexing"]},{"cell_type":"code","metadata":{"id":"GEuGn5Js3fHx","colab_type":"code","outputId":"c15310bf-8e22-4c2e-8e5d-0fd68f3d2661","executionInfo":{"status":"ok","timestamp":1584520329832,"user_tz":-60,"elapsed":645,"user":{"displayName":"Jeremy Marck","photoUrl":"","userId":"00527775588178291504"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["# get the shape of a tensor\n","tensor.size()\n","# reshape it \n","print(tensor, \"\\n\",\n","      tensor.view(2,2,5))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[[0.9397, 0.6660],\n","         [0.9896, 0.9162]],\n","\n","        [[0.8674, 0.7286],\n","         [0.8566, 0.1337]],\n","\n","        [[0.0909, 0.9817],\n","         [0.2359, 0.2422]],\n","\n","        [[0.3359, 0.9101],\n","         [0.3049, 0.1896]],\n","\n","        [[0.5454, 0.8767],\n","         [0.0199, 0.9253]]]) \n"," tensor([[[0.9397, 0.6660, 0.9896, 0.9162, 0.8674],\n","         [0.7286, 0.8566, 0.1337, 0.0909, 0.9817]],\n","\n","        [[0.2359, 0.2422, 0.3359, 0.9101, 0.3049],\n","         [0.1896, 0.5454, 0.8767, 0.0199, 0.9253]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VD2AQmQH3fIN","colab_type":"code","outputId":"38e3936a-f427-4f49-9871-1f93240857a6","executionInfo":{"status":"ok","timestamp":1584520333041,"user_tz":-60,"elapsed":522,"user":{"displayName":"Jeremy Marck","photoUrl":"","userId":"00527775588178291504"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["intTensor = torch.ones(3,2, dtype=torch.float32)\n","print(intTensor, intTensor.dtype)\n","intTensor.int()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[1., 1.],\n","        [1., 1.],\n","        [1., 1.]]) torch.float32\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 1],\n","        [1, 1],\n","        [1, 1]], dtype=torch.int32)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"zR2IEBxj9Nl8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVTZd85T3fIY","colab_type":"text"},"source":["### All operations on tensors \n","- all reshape \n","- squeeze \n","- sum , prod \n","- max, norm ..."]},{"cell_type":"markdown","metadata":{"id":"X0d2Wd-u3fIi","colab_type":"text"},"source":["## Automatic Differentiation \n","\n","The core component of any modern deep learning library is _Automatic Differentiation_. \n","\n","\n","**Recall**\n","- Training any deep learning model requires backpropagatation \n","- Backpropagation is an algorithm that efficiently computes the gradient of a neural network's output based on its input and with regard to all its parameters (or also named weights)\n","\n","_Automatic Differentiation_ provides a way of automatically computing gradients of any function. In other words, _automatic differentiation_ gives you the possibility to build complex neural network without caring about computing the gradients by yourself. \n","\n","\n","**NB** \n","\n","Having access to an open source library that performs Automatic Differentation (tensorflow/pytorch and before Dynet or Theano..) is one of the reasons for the popularity and sucess of Deep Learning today.\n","\n","### Automatic Differentiation in a nutshell\n","\n","\n","**Definition**\n","Automatic differentiation refers to a general way of taking a program which computes a value, and automatically constructing a procedure for computing derivatives of that value.\n","\n","Automatic Differentation requires 3 steps \n","\n","1. Building a computation Graph \n","2. propagating inputs throughout the graph (forward pass)\n","3. Computing gradient of each of the node in the graph (backward pass)"]},{"cell_type":"code","metadata":{"id":"8ufdSVqe3fIn","colab_type":"code","outputId":"677f35f0-af29-42e6-927c-8fe91ba70af9","executionInfo":{"status":"ok","timestamp":1584520419574,"user_tz":-60,"elapsed":538,"user":{"displayName":"Jeremy Marck","photoUrl":"","userId":"00527775588178291504"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x = torch.ones(2, 2, requires_grad=True)\n","# double checking if gradient \n","print(\"Checking gradient is set to {}. Its gradient is still {} \".format(x.requires_grad, x.grad))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Checking gradient is set to True. Its gradient is still None \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gm23ooct3fIy","colab_type":"code","outputId":"f5bb841c-dcc7-4263-96ff-c5beb3f4ee12","executionInfo":{"status":"ok","timestamp":1584520425924,"user_tz":-60,"elapsed":585,"user":{"displayName":"Jeremy Marck","photoUrl":"","userId":"00527775588178291504"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# let us define a basic operation\n","y = x+1\n","print(y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[2., 2.],\n","        [2., 2.]], grad_fn=<AddBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V6y3ScPX3fI6","colab_type":"code","outputId":"3f69664d-886a-4fd1-c05e-8c22880a4011","executionInfo":{"status":"ok","timestamp":1584520437456,"user_tz":-60,"elapsed":621,"user":{"displayName":"Jeremy Marck","photoUrl":"","userId":"00527775588178291504"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# y has now a gradient attribute , grad is none\n","y.grad_fn, y.grad"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<AddBackward0 at 0x7f51ad3d5630>, None)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"U-DRTAqB3fJF","colab_type":"code","outputId":"35360bc2-f694-447d-8c95-40e9535ba17c","executionInfo":{"status":"ok","timestamp":1584520440732,"user_tz":-60,"elapsed":696,"user":{"displayName":"Jeremy Marck","photoUrl":"","userId":"00527775588178291504"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["z = y * y * 3\n","out = z.mean()\n","print(z, out, z.grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[12., 12.],\n","        [12., 12.]], grad_fn=<MulBackward0>) tensor(12., grad_fn=<MeanBackward0>) None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TPBP87F13fJK","colab_type":"code","outputId":"30eaaf72-a796-4c29-dccf-b4942d5024d3","executionInfo":{"status":"ok","timestamp":1584520451504,"user_tz":-60,"elapsed":584,"user":{"displayName":"Jeremy Marck","photoUrl":"","userId":"00527775588178291504"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["out.backward()\n","# Let's inspect the gradient at each previous variable' gradients now\n","print(\"Gradients with regard to intermediate nodes:\", out.grad, z.grad, y.grad)\n","print(\"Gradients with regard to the input node that we considered to be the parameter:\", x.grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Gradients with regard to intermediate nodes: None None None\n","Gradients with regard to the input node that we considered to be the parameter: tensor([[3., 3.],\n","        [3., 3.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"etJYZGzda-i-","colab_type":"text"},"source":["### Questions:\n","- Find the function that is being differentiated with regard to x_ij.\n","- Try to manually retrieve the same gradient with the function you found for x=[[1, 1], [1, 1]]."]},{"cell_type":"code","metadata":{"id":"xVPoBeXf3fJR","colab_type":"code","outputId":"c1fc07d0-febd-43a3-e173-aeced3222b77","executionInfo":{"status":"ok","timestamp":1584520497583,"user_tz":-60,"elapsed":677,"user":{"displayName":"Jeremy Marck","photoUrl":"","userId":"00527775588178291504"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# to manipulate a tensor without its gradient \n","out.detach()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(12.)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"cROAukmM3fJW","colab_type":"text"},"source":["## Pytorch Model\n","\n","\n","Our goal is to define a deep learning model, train it, make prediction with it and evaluate it. \n","\n","With pytorch this means doing the three following \"scripts\" : \n","1. Defining the model \n","2. Implementing the prediction \n","3. Implementing the training loop \n","    - Defining a loss\n","    - Defining an optimizer\n","    - Loop :\n","        - forward pass \n","        - backward pass\n","        - applying optimization update rule\n","4. Evaluating the model / playing with it \n","    - You can use the training criteria (loss) as your evaluation score\n","    - You can use another score : accuracy, F1 , ..."]},{"cell_type":"markdown","metadata":{"id":"qgIXi-gu3fJb","colab_type":"text"},"source":["### 1. Defining the model \n","Pytorch models always follow the same template : \n","\n","- a class\n","- defining all layers (or parameters) in _init_()\n","- defining the forward pass in foward()\n","\n","Let's see what it looks like with a simple 2 layers model.\n","\n","All trivial Neural Network layers can generally be found in [torch.nn](https://pytorch.org/docs/stable/nn.html).\n","\n","**Warning**: All your parametrized modules (Layers or any trainable vectors) must be defined as *direct* attributes to your ```nn.Module``` class so that the call to ```.backward()``` can properly propagate the gradients through everything. To define layers in list attribute, (resp. dictionary attributes) use ```ModuleList``` (resp. ```ModuleDict```).\n","\n","\n","<img src=\"./imgs/nn.png\">\n","\n"]},{"cell_type":"code","metadata":{"id":"c9CXT3hd3fJd","colab_type":"code","colab":{}},"source":["# defining the model \n","class MyModel(torch.nn.Module):\n","    def __init__(self, D_in, H, D_out):\n","        \"\"\"\n","        In the constructor we instantiate two nn.Linear modules and assign them as\n","        member variables.\n","        \"\"\"\n","        super(MyModel, self).__init__()\n","        self.linear1 = torch.nn.Linear(D_in, H, bias=True)\n","        self.linear2 = torch.nn.Linear(H, D_out, bias=True)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        In the forward function we accept a Tensor of input data and we must return\n","        a Tensor of output data. We can use Modules defined in the constructor as\n","        well as arbitrary operators on Tensors.\n","        \"\"\"\n","        h_relu = torch.relu(self.linear1(x))\n","        y_pred = self.linear2(h_relu)\n","        return y_pred"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKt4AmzG3fJp","colab_type":"text"},"source":["### 2. Forward pass \n","1. instanciating the model\n","2. getting input data \n","3. computing the foward pass"]},{"cell_type":"code","metadata":{"id":"hkclHYpb3fJr","colab_type":"code","outputId":"e802ffe2-f660-47c5-a407-f65bb2e75453","executionInfo":{"status":"ok","timestamp":1585563728273,"user_tz":-120,"elapsed":1312,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"source":["# instanciating the model \n","N, D_in, H, D_out = 2, 10, 10, 2\n","\n","# Construct our model by instantiating the class defined above \n","# Note: all the parameters are initialized here \n","model = MyModel(D_in, H, D_out)\n","# You can look up into the model \n","model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyModel(\n","  (linear1): Linear(in_features=10, out_features=10, bias=True)\n","  (linear2): Linear(in_features=10, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"fHDPw4BL3fJw","colab_type":"code","colab":{}},"source":["# Create random Tensors to hold inputs and outputs\n","x = torch.randn(N, D_in)\n","y = torch.randn(N, D_out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_IRdn853fJ9","colab_type":"code","outputId":"d11b85d4-5373-4dd2-f2d5-f18665ddc3d3","executionInfo":{"status":"ok","timestamp":1585563732421,"user_tz":-120,"elapsed":1136,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#model = MyModel(D_in, H, D_out)\n","# forward pass / predict x \n","y_pred = model(x) # almost equivalent to model.forward(x)\n","# y_pred\n","y_pred"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0904, -0.0225],\n","        [ 0.0936,  0.1422]], grad_fn=<AddmmBackward>)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"yyf3KO_a3fKA","colab_type":"text"},"source":["### Questions \n","- Why do the prediction change if the model is re-instanciated ? \n","- Can this be a problem ? \n","- How to avoid it ? "]},{"cell_type":"markdown","metadata":{"id":"yAQ3qFR63fKB","colab_type":"text"},"source":["### 3. Training loop \n","\n","- Criterion : \n","\n","a model is trained with regard to a _training criterion_ or a _loss_.   \n","Pytorch provides many different pre-coded losses : \n","    - Mean-Square Error \n","    - Categorical Cross-Entropy , ...\n","\n","Most of them can be found in [torch.nn](https://pytorch.org/docs/stable/nn.html) \n","- Optimizer \n","\n","In pytorch as in any deep learning framwork, models are trained with backpropagation. Backpropagation consists in applying Stochastic Gradient Descent (SGD) to a neural network. There is a broad range of variants around the simple form of SGD. \n","\n","Pytorch provides pre-defined objects for many different forms of Gradient Descent algorithm in [torch.optim](https://pytorch.org/docs/stable/optim.html):\n","- SGD \n","- Adadelta \n","- Adam \n","\n","Your optimizer will be instanciated with it's configuration(*e.g.* the *step_size* or *learning_rate* for SGD), and the network's parameters.\n","\n","Overview of all the Gradient Descent based algorithms : https://ruder.io/optimizing-gradient-descent/ \n","\n","\n","- Training Loop :\n","    - forward pass to get prediction and the loss value \n","    - zero_grad : Resetting the gradient value to zero for all parameters before adding their newly backpropagated values) \n","    - compute the gradients' value with loss.backward()\n","    - update all the parameters of the model with optimizer.step()\n","\n"]},{"cell_type":"code","metadata":{"scrolled":true,"colab_type":"code","outputId":"feb2409b-5db2-43ec-ba81-185b93620139","executionInfo":{"status":"ok","timestamp":1585563742763,"user_tz":-120,"elapsed":3607,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"id":"EhXD2QDjUpYK","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# instanciate the model \n","# Note: all the model parameters are intialized at this step\n","model = MyModel(D_in, H, D_out)\n","\n","criterion = torch.nn.MSELoss(reduction='mean')\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n","\n","# t is normally also an index over the samples (or batches) in your dataset,\n","# but we will just consider it to be a time-step here\n","for t in range(1000):\n","    # Forward pass: Compute predicted y by passing x to the model\n","    y_pred = model(x)\n","    print('y_pred', y_pred)\n","    # Compute and print loss\n","    loss = criterion(y_pred, y)\n","    print('loss', loss)\n","    if t % 100 == 0:\n","        print(\"Step:{} Loss:{} \".format(t, loss.item()))\n","\n","    # Zero gradients, perform a backward pass, and update the weights.\n","    optimizer.zero_grad()\n","    print('first thing', optimizer.zero_grad())\n","    loss.backward()\n","    #print('second one', loss.backward())\n","    optimizer.step()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["y_pred tensor([[-0.6543,  0.1820],\n","        [-0.3713,  0.4293]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8542, grad_fn=<MseLossBackward>)\n","Step:0 Loss:2.8542280197143555 \n","first thing None\n","y_pred tensor([[-0.6544,  0.1818],\n","        [-0.3718,  0.4289]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8532, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6546,  0.1817],\n","        [-0.3724,  0.4285]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8521, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6547,  0.1815],\n","        [-0.3729,  0.4281]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8510, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6549,  0.1813],\n","        [-0.3734,  0.4277]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8500, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6550,  0.1812],\n","        [-0.3740,  0.4273]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8489, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6552,  0.1810],\n","        [-0.3745,  0.4270]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8478, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6553,  0.1808],\n","        [-0.3750,  0.4266]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8468, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6554,  0.1807],\n","        [-0.3756,  0.4262]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8457, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6556,  0.1805],\n","        [-0.3761,  0.4258]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8447, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6557,  0.1804],\n","        [-0.3767,  0.4254]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8436, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6559,  0.1802],\n","        [-0.3772,  0.4250]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8425, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6560,  0.1800],\n","        [-0.3777,  0.4246]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8415, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6562,  0.1799],\n","        [-0.3783,  0.4243]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8404, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6563,  0.1797],\n","        [-0.3788,  0.4239]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8394, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6565,  0.1795],\n","        [-0.3793,  0.4235]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8383, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6566,  0.1794],\n","        [-0.3799,  0.4231]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8373, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6568,  0.1792],\n","        [-0.3804,  0.4227]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8362, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6569,  0.1791],\n","        [-0.3809,  0.4223]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8351, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6570,  0.1789],\n","        [-0.3815,  0.4219]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8341, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6572,  0.1787],\n","        [-0.3820,  0.4216]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8330, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6573,  0.1786],\n","        [-0.3825,  0.4212]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8320, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6575,  0.1784],\n","        [-0.3831,  0.4208]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8309, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6576,  0.1782],\n","        [-0.3836,  0.4204]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8299, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6578,  0.1781],\n","        [-0.3841,  0.4200]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8288, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6579,  0.1779],\n","        [-0.3847,  0.4196]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8278, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6581,  0.1778],\n","        [-0.3852,  0.4193]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8267, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6582,  0.1776],\n","        [-0.3857,  0.4189]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8257, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6583,  0.1774],\n","        [-0.3863,  0.4185]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8246, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6585,  0.1773],\n","        [-0.3868,  0.4181]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8236, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6586,  0.1771],\n","        [-0.3873,  0.4177]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8225, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6588,  0.1769],\n","        [-0.3878,  0.4173]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8215, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6589,  0.1768],\n","        [-0.3884,  0.4170]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8204, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6591,  0.1766],\n","        [-0.3889,  0.4166]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8194, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6592,  0.1764],\n","        [-0.3894,  0.4162]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8183, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6594,  0.1763],\n","        [-0.3900,  0.4158]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8173, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6595,  0.1761],\n","        [-0.3905,  0.4154]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8163, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6597,  0.1760],\n","        [-0.3910,  0.4150]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8152, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6598,  0.1758],\n","        [-0.3916,  0.4147]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8142, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6599,  0.1756],\n","        [-0.3921,  0.4143]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8131, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6601,  0.1755],\n","        [-0.3926,  0.4139]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8121, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6602,  0.1753],\n","        [-0.3932,  0.4135]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8110, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6604,  0.1751],\n","        [-0.3937,  0.4131]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8100, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6605,  0.1750],\n","        [-0.3942,  0.4128]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8090, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6607,  0.1748],\n","        [-0.3947,  0.4124]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8079, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6608,  0.1747],\n","        [-0.3953,  0.4120]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8069, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6609,  0.1745],\n","        [-0.3958,  0.4116]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8058, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6611,  0.1743],\n","        [-0.3963,  0.4112]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8048, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6612,  0.1742],\n","        [-0.3969,  0.4109]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8038, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6614,  0.1740],\n","        [-0.3974,  0.4105]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8027, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6615,  0.1739],\n","        [-0.3979,  0.4101]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8017, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6617,  0.1737],\n","        [-0.3984,  0.4097]], grad_fn=<AddmmBackward>)\n","loss tensor(2.8007, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6618,  0.1735],\n","        [-0.3990,  0.4093]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7996, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6620,  0.1734],\n","        [-0.3995,  0.4090]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7986, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6621,  0.1732],\n","        [-0.4000,  0.4086]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7976, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6622,  0.1730],\n","        [-0.4006,  0.4082]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7965, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6624,  0.1729],\n","        [-0.4011,  0.4078]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7955, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6625,  0.1727],\n","        [-0.4016,  0.4074]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7945, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6627,  0.1726],\n","        [-0.4021,  0.4071]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7934, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6628,  0.1724],\n","        [-0.4027,  0.4067]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7924, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6630,  0.1722],\n","        [-0.4032,  0.4063]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7914, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6631,  0.1721],\n","        [-0.4037,  0.4059]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7903, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6632,  0.1719],\n","        [-0.4042,  0.4055]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7893, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6634,  0.1717],\n","        [-0.4048,  0.4052]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7883, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6635,  0.1716],\n","        [-0.4053,  0.4048]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7872, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6637,  0.1714],\n","        [-0.4058,  0.4044]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7862, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6638,  0.1713],\n","        [-0.4063,  0.4040]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7852, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6640,  0.1711],\n","        [-0.4069,  0.4037]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7842, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6641,  0.1709],\n","        [-0.4074,  0.4033]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7831, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6642,  0.1708],\n","        [-0.4079,  0.4029]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7821, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6644,  0.1706],\n","        [-0.4084,  0.4025]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7811, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6645,  0.1704],\n","        [-0.4090,  0.4021]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7801, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6647,  0.1703],\n","        [-0.4095,  0.4018]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7790, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6648,  0.1701],\n","        [-0.4100,  0.4014]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7780, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6650,  0.1700],\n","        [-0.4105,  0.4010]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7770, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6651,  0.1698],\n","        [-0.4111,  0.4006]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7760, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6652,  0.1696],\n","        [-0.4116,  0.4003]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7750, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6654,  0.1695],\n","        [-0.4121,  0.3999]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7739, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6655,  0.1693],\n","        [-0.4126,  0.3995]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7729, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6657,  0.1692],\n","        [-0.4132,  0.3991]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7719, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6658,  0.1690],\n","        [-0.4137,  0.3987]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7709, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6660,  0.1688],\n","        [-0.4142,  0.3984]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7699, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6661,  0.1687],\n","        [-0.4147,  0.3980]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7688, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6662,  0.1685],\n","        [-0.4153,  0.3976]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7678, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6664,  0.1683],\n","        [-0.4158,  0.3972]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7668, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6665,  0.1682],\n","        [-0.4163,  0.3969]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7658, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6667,  0.1680],\n","        [-0.4168,  0.3965]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7648, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6668,  0.1679],\n","        [-0.4174,  0.3961]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7637, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6670,  0.1677],\n","        [-0.4179,  0.3957]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7627, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6671,  0.1675],\n","        [-0.4184,  0.3954]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7617, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6672,  0.1674],\n","        [-0.4189,  0.3950]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7607, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6674,  0.1672],\n","        [-0.4194,  0.3946]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7597, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6675,  0.1671],\n","        [-0.4200,  0.3942]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7587, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6677,  0.1669],\n","        [-0.4205,  0.3939]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7577, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6678,  0.1667],\n","        [-0.4210,  0.3935]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7567, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6680,  0.1666],\n","        [-0.4215,  0.3931]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7556, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6681,  0.1664],\n","        [-0.4221,  0.3927]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7546, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6682,  0.1662],\n","        [-0.4226,  0.3924]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7536, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6684,  0.1661],\n","        [-0.4231,  0.3920]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7526, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6685,  0.1659],\n","        [-0.4236,  0.3916]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7516, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6687,  0.1658],\n","        [-0.4241,  0.3913]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7506, grad_fn=<MseLossBackward>)\n","Step:100 Loss:2.7505884170532227 \n","first thing None\n","y_pred tensor([[-0.6688,  0.1656],\n","        [-0.4247,  0.3909]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7496, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6689,  0.1654],\n","        [-0.4252,  0.3905]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7486, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6691,  0.1653],\n","        [-0.4257,  0.3901]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7476, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6692,  0.1651],\n","        [-0.4262,  0.3898]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7466, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6694,  0.1650],\n","        [-0.4267,  0.3894]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7456, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6695,  0.1648],\n","        [-0.4273,  0.3890]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7445, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6697,  0.1646],\n","        [-0.4278,  0.3886]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7435, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6698,  0.1645],\n","        [-0.4283,  0.3883]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7425, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6699,  0.1643],\n","        [-0.4288,  0.3879]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7415, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6701,  0.1641],\n","        [-0.4294,  0.3875]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7405, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6702,  0.1640],\n","        [-0.4299,  0.3871]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7395, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6704,  0.1638],\n","        [-0.4304,  0.3868]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7385, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6705,  0.1637],\n","        [-0.4309,  0.3864]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7375, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6706,  0.1635],\n","        [-0.4314,  0.3860]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7365, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6708,  0.1633],\n","        [-0.4319,  0.3857]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7355, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6709,  0.1632],\n","        [-0.4325,  0.3853]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7345, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6711,  0.1630],\n","        [-0.4330,  0.3849]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7335, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6712,  0.1629],\n","        [-0.4335,  0.3845]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7325, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6713,  0.1627],\n","        [-0.4340,  0.3842]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7315, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6715,  0.1625],\n","        [-0.4345,  0.3838]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7305, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6716,  0.1624],\n","        [-0.4351,  0.3834]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7295, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6718,  0.1622],\n","        [-0.4356,  0.3831]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7285, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6719,  0.1621],\n","        [-0.4361,  0.3827]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7275, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6721,  0.1619],\n","        [-0.4366,  0.3823]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7265, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6722,  0.1617],\n","        [-0.4371,  0.3819]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7255, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6723,  0.1616],\n","        [-0.4377,  0.3816]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7245, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6725,  0.1614],\n","        [-0.4382,  0.3812]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7235, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6726,  0.1612],\n","        [-0.4387,  0.3808]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7225, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6728,  0.1611],\n","        [-0.4392,  0.3805]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7215, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6729,  0.1609],\n","        [-0.4397,  0.3801]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7205, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6730,  0.1608],\n","        [-0.4402,  0.3797]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7196, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6732,  0.1606],\n","        [-0.4408,  0.3793]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7186, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6733,  0.1604],\n","        [-0.4413,  0.3790]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7176, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6735,  0.1603],\n","        [-0.4418,  0.3786]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7166, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6736,  0.1601],\n","        [-0.4423,  0.3782]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7156, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6737,  0.1600],\n","        [-0.4428,  0.3779]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7146, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6739,  0.1598],\n","        [-0.4433,  0.3775]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7136, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6740,  0.1596],\n","        [-0.4439,  0.3771]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7126, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6742,  0.1595],\n","        [-0.4444,  0.3768]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7116, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6743,  0.1593],\n","        [-0.4449,  0.3764]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7106, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6744,  0.1592],\n","        [-0.4454,  0.3760]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7096, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6746,  0.1590],\n","        [-0.4459,  0.3757]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7087, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6747,  0.1588],\n","        [-0.4464,  0.3753]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7077, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6749,  0.1587],\n","        [-0.4470,  0.3749]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7067, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6750,  0.1585],\n","        [-0.4475,  0.3745]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7057, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6751,  0.1584],\n","        [-0.4480,  0.3742]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7047, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6753,  0.1582],\n","        [-0.4485,  0.3738]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7037, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6754,  0.1580],\n","        [-0.4490,  0.3734]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7027, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6756,  0.1579],\n","        [-0.4495,  0.3731]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7017, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6757,  0.1577],\n","        [-0.4500,  0.3727]], grad_fn=<AddmmBackward>)\n","loss tensor(2.7008, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6758,  0.1575],\n","        [-0.4506,  0.3723]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6998, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6760,  0.1574],\n","        [-0.4511,  0.3720]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6988, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6761,  0.1572],\n","        [-0.4516,  0.3716]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6978, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6763,  0.1571],\n","        [-0.4521,  0.3712]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6968, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6764,  0.1569],\n","        [-0.4526,  0.3709]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6958, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6765,  0.1567],\n","        [-0.4531,  0.3705]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6949, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6767,  0.1566],\n","        [-0.4536,  0.3701]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6939, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6768,  0.1564],\n","        [-0.4542,  0.3698]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6929, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6770,  0.1563],\n","        [-0.4547,  0.3694]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6919, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6771,  0.1561],\n","        [-0.4552,  0.3690]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6909, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6772,  0.1559],\n","        [-0.4557,  0.3687]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6900, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6774,  0.1558],\n","        [-0.4562,  0.3683]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6890, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6775,  0.1556],\n","        [-0.4567,  0.3679]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6880, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6777,  0.1555],\n","        [-0.4572,  0.3676]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6870, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6778,  0.1553],\n","        [-0.4578,  0.3672]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6860, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6779,  0.1551],\n","        [-0.4583,  0.3668]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6851, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6781,  0.1550],\n","        [-0.4588,  0.3665]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6841, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6782,  0.1548],\n","        [-0.4593,  0.3661]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6831, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6784,  0.1547],\n","        [-0.4598,  0.3657]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6821, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6785,  0.1545],\n","        [-0.4603,  0.3654]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6812, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6786,  0.1543],\n","        [-0.4608,  0.3650]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6802, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6788,  0.1542],\n","        [-0.4613,  0.3646]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6792, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6789,  0.1540],\n","        [-0.4619,  0.3643]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6782, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6790,  0.1539],\n","        [-0.4624,  0.3639]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6773, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6792,  0.1537],\n","        [-0.4629,  0.3635]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6763, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6793,  0.1535],\n","        [-0.4634,  0.3632]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6753, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6795,  0.1534],\n","        [-0.4639,  0.3628]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6743, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6796,  0.1532],\n","        [-0.4644,  0.3624]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6734, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6797,  0.1531],\n","        [-0.4649,  0.3621]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6724, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6799,  0.1529],\n","        [-0.4654,  0.3617]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6714, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6800,  0.1527],\n","        [-0.4660,  0.3613]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6705, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6802,  0.1526],\n","        [-0.4665,  0.3610]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6695, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6803,  0.1524],\n","        [-0.4670,  0.3606]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6685, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6804,  0.1523],\n","        [-0.4675,  0.3602]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6675, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6806,  0.1521],\n","        [-0.4680,  0.3599]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6666, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6807,  0.1519],\n","        [-0.4685,  0.3595]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6656, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6809,  0.1518],\n","        [-0.4690,  0.3591]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6646, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6810,  0.1516],\n","        [-0.4695,  0.3588]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6637, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6811,  0.1515],\n","        [-0.4700,  0.3584]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6627, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6813,  0.1513],\n","        [-0.4706,  0.3580]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6617, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6814,  0.1511],\n","        [-0.4711,  0.3577]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6608, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6815,  0.1510],\n","        [-0.4716,  0.3573]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6598, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6817,  0.1508],\n","        [-0.4721,  0.3570]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6588, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6818,  0.1507],\n","        [-0.4726,  0.3566]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6579, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6820,  0.1505],\n","        [-0.4731,  0.3562]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6569, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6821,  0.1503],\n","        [-0.4736,  0.3559]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6559, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6822,  0.1502],\n","        [-0.4741,  0.3555]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6550, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6824,  0.1500],\n","        [-0.4746,  0.3551]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6540, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6825,  0.1499],\n","        [-0.4752,  0.3548]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6531, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6827,  0.1497],\n","        [-0.4757,  0.3544]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6521, grad_fn=<MseLossBackward>)\n","Step:200 Loss:2.652092933654785 \n","first thing None\n","y_pred tensor([[-0.6828,  0.1495],\n","        [-0.4762,  0.3540]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6511, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6829,  0.1494],\n","        [-0.4767,  0.3537]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6502, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6831,  0.1492],\n","        [-0.4772,  0.3533]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6492, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6832,  0.1491],\n","        [-0.4777,  0.3529]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6482, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6833,  0.1489],\n","        [-0.4782,  0.3526]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6473, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6835,  0.1487],\n","        [-0.4787,  0.3522]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6463, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6836,  0.1486],\n","        [-0.4792,  0.3519]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6454, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6838,  0.1484],\n","        [-0.4797,  0.3515]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6444, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6839,  0.1483],\n","        [-0.4802,  0.3511]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6434, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6840,  0.1481],\n","        [-0.4808,  0.3508]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6425, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6842,  0.1479],\n","        [-0.4813,  0.3504]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6415, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6843,  0.1478],\n","        [-0.4818,  0.3500]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6406, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6844,  0.1476],\n","        [-0.4823,  0.3497]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6396, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6846,  0.1475],\n","        [-0.4828,  0.3493]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6387, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6847,  0.1473],\n","        [-0.4833,  0.3490]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6377, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6849,  0.1471],\n","        [-0.4838,  0.3486]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6367, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6850,  0.1470],\n","        [-0.4843,  0.3482]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6358, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6851,  0.1468],\n","        [-0.4848,  0.3479]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6348, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6853,  0.1467],\n","        [-0.4853,  0.3475]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6339, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6854,  0.1465],\n","        [-0.4858,  0.3471]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6329, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6855,  0.1463],\n","        [-0.4863,  0.3468]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6320, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6857,  0.1462],\n","        [-0.4869,  0.3464]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6310, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6858,  0.1460],\n","        [-0.4874,  0.3461]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6301, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6860,  0.1459],\n","        [-0.4879,  0.3457]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6291, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6861,  0.1457],\n","        [-0.4884,  0.3453]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6282, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6862,  0.1455],\n","        [-0.4889,  0.3450]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6272, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6864,  0.1454],\n","        [-0.4894,  0.3446]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6262, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6865,  0.1452],\n","        [-0.4899,  0.3442]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6253, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6866,  0.1451],\n","        [-0.4904,  0.3439]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6243, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6868,  0.1449],\n","        [-0.4909,  0.3435]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6234, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6869,  0.1447],\n","        [-0.4914,  0.3432]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6224, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6871,  0.1446],\n","        [-0.4919,  0.3428]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6215, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6872,  0.1444],\n","        [-0.4924,  0.3424]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6205, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6873,  0.1443],\n","        [-0.4929,  0.3421]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6196, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6875,  0.1441],\n","        [-0.4934,  0.3417]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6186, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6876,  0.1440],\n","        [-0.4940,  0.3414]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6177, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6877,  0.1438],\n","        [-0.4945,  0.3410]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6167, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6879,  0.1436],\n","        [-0.4950,  0.3406]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6158, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6880,  0.1435],\n","        [-0.4955,  0.3403]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6149, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6881,  0.1433],\n","        [-0.4960,  0.3399]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6139, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6883,  0.1432],\n","        [-0.4965,  0.3395]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6130, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6884,  0.1430],\n","        [-0.4970,  0.3392]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6120, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6886,  0.1428],\n","        [-0.4975,  0.3388]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6111, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6887,  0.1427],\n","        [-0.4980,  0.3385]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6101, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6888,  0.1425],\n","        [-0.4985,  0.3381]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6092, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6890,  0.1424],\n","        [-0.4990,  0.3377]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6082, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6891,  0.1422],\n","        [-0.4995,  0.3374]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6073, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6892,  0.1420],\n","        [-0.5000,  0.3370]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6063, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6894,  0.1419],\n","        [-0.5005,  0.3367]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6054, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6895,  0.1417],\n","        [-0.5010,  0.3363]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6045, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6896,  0.1416],\n","        [-0.5015,  0.3359]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6035, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6898,  0.1414],\n","        [-0.5020,  0.3356]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6026, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6899,  0.1412],\n","        [-0.5026,  0.3352]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6016, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6901,  0.1411],\n","        [-0.5031,  0.3349]], grad_fn=<AddmmBackward>)\n","loss tensor(2.6007, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6902,  0.1409],\n","        [-0.5036,  0.3345]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5997, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6903,  0.1408],\n","        [-0.5041,  0.3341]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5988, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6905,  0.1406],\n","        [-0.5046,  0.3338]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5979, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6906,  0.1404],\n","        [-0.5051,  0.3334]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5969, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6907,  0.1403],\n","        [-0.5056,  0.3331]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5960, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6909,  0.1401],\n","        [-0.5061,  0.3327]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5950, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6910,  0.1400],\n","        [-0.5066,  0.3323]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5941, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6911,  0.1398],\n","        [-0.5071,  0.3320]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5932, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6913,  0.1396],\n","        [-0.5076,  0.3316]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5922, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6914,  0.1395],\n","        [-0.5081,  0.3313]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5913, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6916,  0.1393],\n","        [-0.5086,  0.3309]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5904, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6917,  0.1392],\n","        [-0.5091,  0.3305]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5894, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6918,  0.1390],\n","        [-0.5096,  0.3302]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5885, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6920,  0.1389],\n","        [-0.5101,  0.3298]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5875, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6921,  0.1387],\n","        [-0.5106,  0.3295]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5866, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6922,  0.1385],\n","        [-0.5111,  0.3291]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5857, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6924,  0.1384],\n","        [-0.5116,  0.3288]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5847, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6925,  0.1382],\n","        [-0.5121,  0.3284]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5838, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6926,  0.1381],\n","        [-0.5126,  0.3280]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5829, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6928,  0.1379],\n","        [-0.5131,  0.3277]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5819, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6929,  0.1377],\n","        [-0.5136,  0.3273]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5810, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6930,  0.1376],\n","        [-0.5141,  0.3270]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5801, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6932,  0.1374],\n","        [-0.5147,  0.3266]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5791, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6933,  0.1373],\n","        [-0.5152,  0.3262]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5782, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6935,  0.1371],\n","        [-0.5157,  0.3259]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5773, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6936,  0.1369],\n","        [-0.5162,  0.3255]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5763, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6937,  0.1368],\n","        [-0.5167,  0.3252]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5754, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6939,  0.1366],\n","        [-0.5172,  0.3248]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5745, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6940,  0.1365],\n","        [-0.5177,  0.3244]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5735, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6941,  0.1363],\n","        [-0.5182,  0.3241]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5726, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6943,  0.1362],\n","        [-0.5187,  0.3237]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5717, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6944,  0.1360],\n","        [-0.5192,  0.3234]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5707, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6945,  0.1358],\n","        [-0.5197,  0.3230]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5698, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6947,  0.1357],\n","        [-0.5202,  0.3227]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5689, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6948,  0.1355],\n","        [-0.5207,  0.3223]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5679, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6949,  0.1354],\n","        [-0.5212,  0.3219]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5670, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6951,  0.1352],\n","        [-0.5217,  0.3216]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5661, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6952,  0.1350],\n","        [-0.5222,  0.3212]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5652, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6953,  0.1349],\n","        [-0.5227,  0.3209]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5642, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6955,  0.1347],\n","        [-0.5232,  0.3205]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5633, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6956,  0.1346],\n","        [-0.5237,  0.3202]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5624, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6958,  0.1344],\n","        [-0.5242,  0.3198]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5615, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6959,  0.1342],\n","        [-0.5247,  0.3194]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5605, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6960,  0.1341],\n","        [-0.5252,  0.3191]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5596, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6962,  0.1339],\n","        [-0.5257,  0.3187]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5587, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6963,  0.1338],\n","        [-0.5262,  0.3184]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5577, grad_fn=<MseLossBackward>)\n","Step:300 Loss:2.5577468872070312 \n","first thing None\n","y_pred tensor([[-0.6964,  0.1336],\n","        [-0.5267,  0.3180]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5568, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6966,  0.1335],\n","        [-0.5272,  0.3177]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5559, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6967,  0.1333],\n","        [-0.5277,  0.3173]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5550, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6968,  0.1331],\n","        [-0.5282,  0.3169]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5540, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6970,  0.1330],\n","        [-0.5287,  0.3166]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5531, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6971,  0.1328],\n","        [-0.5292,  0.3162]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5522, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6972,  0.1327],\n","        [-0.5297,  0.3159]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5513, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6974,  0.1325],\n","        [-0.5302,  0.3155]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5504, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6975,  0.1323],\n","        [-0.5307,  0.3152]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5494, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6976,  0.1322],\n","        [-0.5312,  0.3148]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5485, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6978,  0.1320],\n","        [-0.5317,  0.3144]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5476, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6979,  0.1319],\n","        [-0.5322,  0.3141]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5467, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6980,  0.1317],\n","        [-0.5327,  0.3137]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5457, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6982,  0.1315],\n","        [-0.5332,  0.3134]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5448, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6983,  0.1314],\n","        [-0.5337,  0.3130]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5439, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6984,  0.1312],\n","        [-0.5342,  0.3127]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5430, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6986,  0.1311],\n","        [-0.5347,  0.3123]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5421, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6987,  0.1309],\n","        [-0.5352,  0.3119]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5411, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6988,  0.1308],\n","        [-0.5357,  0.3116]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5402, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6990,  0.1306],\n","        [-0.5362,  0.3112]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5393, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6991,  0.1304],\n","        [-0.5367,  0.3109]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5384, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6992,  0.1303],\n","        [-0.5372,  0.3105]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5375, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6994,  0.1301],\n","        [-0.5377,  0.3102]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5365, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6995,  0.1300],\n","        [-0.5382,  0.3098]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5356, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6996,  0.1298],\n","        [-0.5387,  0.3094]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5347, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6998,  0.1296],\n","        [-0.5392,  0.3091]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5338, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.6999,  0.1295],\n","        [-0.5397,  0.3087]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5329, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7001,  0.1293],\n","        [-0.5402,  0.3084]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5320, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7002,  0.1292],\n","        [-0.5407,  0.3080]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5310, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7003,  0.1290],\n","        [-0.5412,  0.3077]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5301, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7005,  0.1289],\n","        [-0.5417,  0.3073]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5292, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7006,  0.1287],\n","        [-0.5422,  0.3070]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5283, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7007,  0.1285],\n","        [-0.5427,  0.3066]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5274, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7009,  0.1284],\n","        [-0.5432,  0.3062]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5265, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7010,  0.1282],\n","        [-0.5437,  0.3059]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5255, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7011,  0.1281],\n","        [-0.5442,  0.3055]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5246, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7013,  0.1279],\n","        [-0.5447,  0.3052]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5237, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7014,  0.1277],\n","        [-0.5452,  0.3048]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5228, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7015,  0.1276],\n","        [-0.5457,  0.3045]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5219, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7017,  0.1274],\n","        [-0.5462,  0.3041]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5210, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7018,  0.1273],\n","        [-0.5467,  0.3037]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5201, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7019,  0.1271],\n","        [-0.5472,  0.3034]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5192, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7021,  0.1270],\n","        [-0.5477,  0.3030]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5182, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7022,  0.1268],\n","        [-0.5482,  0.3027]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5173, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7023,  0.1266],\n","        [-0.5487,  0.3023]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5164, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7025,  0.1265],\n","        [-0.5492,  0.3020]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5155, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7026,  0.1263],\n","        [-0.5497,  0.3016]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5146, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7027,  0.1262],\n","        [-0.5502,  0.3013]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5137, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7029,  0.1260],\n","        [-0.5507,  0.3009]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5128, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7030,  0.1258],\n","        [-0.5512,  0.3005]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5119, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7031,  0.1257],\n","        [-0.5517,  0.3002]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5110, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7033,  0.1255],\n","        [-0.5522,  0.2998]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5100, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7034,  0.1254],\n","        [-0.5527,  0.2995]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5091, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7035,  0.1252],\n","        [-0.5532,  0.2991]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5082, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7037,  0.1251],\n","        [-0.5537,  0.2988]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5073, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7038,  0.1249],\n","        [-0.5542,  0.2984]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5064, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7039,  0.1247],\n","        [-0.5547,  0.2981]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5055, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7041,  0.1246],\n","        [-0.5552,  0.2977]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5046, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7042,  0.1244],\n","        [-0.5557,  0.2974]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5037, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7043,  0.1243],\n","        [-0.5562,  0.2970]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5028, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7045,  0.1241],\n","        [-0.5567,  0.2966]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5019, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7046,  0.1240],\n","        [-0.5572,  0.2963]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5010, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7047,  0.1238],\n","        [-0.5577,  0.2959]], grad_fn=<AddmmBackward>)\n","loss tensor(2.5001, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7049,  0.1236],\n","        [-0.5582,  0.2956]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4992, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7050,  0.1235],\n","        [-0.5587,  0.2952]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4983, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7051,  0.1233],\n","        [-0.5592,  0.2949]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4973, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7052,  0.1232],\n","        [-0.5597,  0.2945]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4964, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7054,  0.1230],\n","        [-0.5602,  0.2942]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4955, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7055,  0.1228],\n","        [-0.5607,  0.2938]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4946, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7056,  0.1227],\n","        [-0.5612,  0.2934]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4937, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7058,  0.1225],\n","        [-0.5617,  0.2931]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4928, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7059,  0.1224],\n","        [-0.5622,  0.2927]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4919, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7060,  0.1222],\n","        [-0.5627,  0.2924]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4910, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7062,  0.1221],\n","        [-0.5632,  0.2920]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4901, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7063,  0.1219],\n","        [-0.5637,  0.2917]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4892, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7064,  0.1217],\n","        [-0.5642,  0.2913]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4883, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7066,  0.1216],\n","        [-0.5647,  0.2910]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4874, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7067,  0.1214],\n","        [-0.5652,  0.2906]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4865, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7068,  0.1213],\n","        [-0.5657,  0.2903]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4856, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7070,  0.1211],\n","        [-0.5662,  0.2899]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4847, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7071,  0.1209],\n","        [-0.5667,  0.2895]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4838, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7072,  0.1208],\n","        [-0.5672,  0.2892]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4829, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7074,  0.1206],\n","        [-0.5677,  0.2888]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4820, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7075,  0.1205],\n","        [-0.5681,  0.2885]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4811, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7076,  0.1203],\n","        [-0.5686,  0.2881]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4802, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7078,  0.1202],\n","        [-0.5691,  0.2878]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4793, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7079,  0.1200],\n","        [-0.5696,  0.2874]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4784, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7080,  0.1198],\n","        [-0.5701,  0.2871]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4775, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7082,  0.1197],\n","        [-0.5706,  0.2867]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4766, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7083,  0.1195],\n","        [-0.5711,  0.2864]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4757, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7084,  0.1194],\n","        [-0.5716,  0.2860]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4748, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7086,  0.1192],\n","        [-0.5721,  0.2856]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4739, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7087,  0.1191],\n","        [-0.5726,  0.2853]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4730, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7088,  0.1189],\n","        [-0.5731,  0.2849]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4721, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7090,  0.1187],\n","        [-0.5736,  0.2846]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4712, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7091,  0.1186],\n","        [-0.5741,  0.2842]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4703, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7092,  0.1184],\n","        [-0.5746,  0.2839]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4694, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7093,  0.1183],\n","        [-0.5751,  0.2835]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4685, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7095,  0.1181],\n","        [-0.5756,  0.2832]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4676, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7096,  0.1180],\n","        [-0.5761,  0.2828]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4667, grad_fn=<MseLossBackward>)\n","Step:400 Loss:2.4667303562164307 \n","first thing None\n","y_pred tensor([[-0.7097,  0.1178],\n","        [-0.5766,  0.2825]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4658, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7099,  0.1176],\n","        [-0.5771,  0.2821]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4649, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7100,  0.1175],\n","        [-0.5776,  0.2818]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4640, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7101,  0.1173],\n","        [-0.5781,  0.2814]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4631, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7103,  0.1172],\n","        [-0.5786,  0.2810]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4623, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7104,  0.1170],\n","        [-0.5791,  0.2807]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4614, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7105,  0.1168],\n","        [-0.5796,  0.2803]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4605, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7107,  0.1167],\n","        [-0.5801,  0.2800]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4596, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7108,  0.1165],\n","        [-0.5806,  0.2796]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4587, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7109,  0.1164],\n","        [-0.5811,  0.2793]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4578, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7111,  0.1162],\n","        [-0.5816,  0.2789]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4569, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7112,  0.1161],\n","        [-0.5821,  0.2786]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4560, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7113,  0.1159],\n","        [-0.5825,  0.2782]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4551, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7115,  0.1157],\n","        [-0.5830,  0.2779]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4542, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7116,  0.1156],\n","        [-0.5835,  0.2775]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4533, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7117,  0.1154],\n","        [-0.5840,  0.2772]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4524, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7118,  0.1153],\n","        [-0.5845,  0.2768]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4515, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7120,  0.1151],\n","        [-0.5850,  0.2764]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4506, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7121,  0.1150],\n","        [-0.5855,  0.2761]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4498, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7122,  0.1148],\n","        [-0.5860,  0.2757]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4489, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7124,  0.1146],\n","        [-0.5865,  0.2754]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4480, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7125,  0.1145],\n","        [-0.5870,  0.2750]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4471, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7126,  0.1143],\n","        [-0.5875,  0.2747]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4462, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7128,  0.1142],\n","        [-0.5880,  0.2743]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4453, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7129,  0.1140],\n","        [-0.5885,  0.2740]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4444, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7130,  0.1139],\n","        [-0.5890,  0.2736]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4435, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7132,  0.1137],\n","        [-0.5895,  0.2733]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4426, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7133,  0.1135],\n","        [-0.5900,  0.2729]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4417, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7134,  0.1134],\n","        [-0.5905,  0.2726]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4409, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7135,  0.1132],\n","        [-0.5910,  0.2722]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4400, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7137,  0.1131],\n","        [-0.5915,  0.2718]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4391, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7138,  0.1129],\n","        [-0.5920,  0.2715]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4382, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7139,  0.1127],\n","        [-0.5925,  0.2711]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4373, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7141,  0.1126],\n","        [-0.5930,  0.2708]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4364, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7142,  0.1124],\n","        [-0.5935,  0.2704]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4355, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7143,  0.1123],\n","        [-0.5939,  0.2701]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4346, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7145,  0.1121],\n","        [-0.5944,  0.2697]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4338, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7146,  0.1120],\n","        [-0.5949,  0.2694]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4329, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7147,  0.1118],\n","        [-0.5954,  0.2690]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4320, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7149,  0.1116],\n","        [-0.5959,  0.2687]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4311, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7150,  0.1115],\n","        [-0.5964,  0.2683]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4302, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7151,  0.1113],\n","        [-0.5969,  0.2680]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4293, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7152,  0.1112],\n","        [-0.5974,  0.2676]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4284, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7154,  0.1110],\n","        [-0.5979,  0.2672]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4276, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7155,  0.1109],\n","        [-0.5984,  0.2669]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4267, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7156,  0.1107],\n","        [-0.5989,  0.2665]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4258, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7158,  0.1105],\n","        [-0.5994,  0.2662]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4249, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7159,  0.1104],\n","        [-0.5999,  0.2658]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4240, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7160,  0.1102],\n","        [-0.6004,  0.2655]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4231, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7162,  0.1101],\n","        [-0.6009,  0.2651]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4223, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7163,  0.1099],\n","        [-0.6014,  0.2648]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4214, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7164,  0.1098],\n","        [-0.6019,  0.2644]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4205, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7165,  0.1096],\n","        [-0.6024,  0.2641]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4196, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7167,  0.1094],\n","        [-0.6029,  0.2637]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4187, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7168,  0.1093],\n","        [-0.6034,  0.2634]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4178, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7169,  0.1091],\n","        [-0.6038,  0.2630]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4170, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7171,  0.1090],\n","        [-0.6043,  0.2627]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4161, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7172,  0.1088],\n","        [-0.6048,  0.2623]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4152, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7173,  0.1087],\n","        [-0.6053,  0.2619]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4143, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7175,  0.1085],\n","        [-0.6058,  0.2616]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4134, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7176,  0.1083],\n","        [-0.6063,  0.2612]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4126, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7177,  0.1082],\n","        [-0.6068,  0.2609]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4117, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7178,  0.1080],\n","        [-0.6073,  0.2605]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4108, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7180,  0.1079],\n","        [-0.6078,  0.2602]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4099, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7181,  0.1077],\n","        [-0.6083,  0.2598]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4090, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7182,  0.1076],\n","        [-0.6088,  0.2595]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4082, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7184,  0.1074],\n","        [-0.6093,  0.2591]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4073, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7185,  0.1072],\n","        [-0.6098,  0.2588]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4064, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7186,  0.1071],\n","        [-0.6103,  0.2584]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4055, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7188,  0.1069],\n","        [-0.6108,  0.2581]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4046, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7189,  0.1068],\n","        [-0.6113,  0.2577]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4038, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7190,  0.1066],\n","        [-0.6118,  0.2574]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4029, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7191,  0.1065],\n","        [-0.6123,  0.2570]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4020, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7193,  0.1063],\n","        [-0.6127,  0.2566]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4011, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7194,  0.1061],\n","        [-0.6132,  0.2563]], grad_fn=<AddmmBackward>)\n","loss tensor(2.4002, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7195,  0.1060],\n","        [-0.6137,  0.2559]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3994, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7197,  0.1058],\n","        [-0.6142,  0.2556]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3985, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7198,  0.1057],\n","        [-0.6147,  0.2552]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3976, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7199,  0.1055],\n","        [-0.6152,  0.2549]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3967, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7201,  0.1054],\n","        [-0.6157,  0.2545]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3959, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7202,  0.1052],\n","        [-0.6162,  0.2542]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3950, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7203,  0.1050],\n","        [-0.6167,  0.2538]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3941, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7204,  0.1049],\n","        [-0.6172,  0.2535]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3932, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7206,  0.1047],\n","        [-0.6177,  0.2531]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3924, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7207,  0.1046],\n","        [-0.6182,  0.2528]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3915, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7208,  0.1044],\n","        [-0.6187,  0.2524]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3906, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7210,  0.1043],\n","        [-0.6192,  0.2521]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3897, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7211,  0.1041],\n","        [-0.6197,  0.2517]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3889, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7212,  0.1039],\n","        [-0.6202,  0.2513]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3880, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7213,  0.1038],\n","        [-0.6207,  0.2510]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3871, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7215,  0.1036],\n","        [-0.6211,  0.2506]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3862, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7216,  0.1035],\n","        [-0.6216,  0.2503]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3854, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7217,  0.1033],\n","        [-0.6221,  0.2499]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3845, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7219,  0.1032],\n","        [-0.6226,  0.2496]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3836, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7220,  0.1030],\n","        [-0.6231,  0.2492]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3827, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7221,  0.1028],\n","        [-0.6236,  0.2489]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3819, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7222,  0.1027],\n","        [-0.6241,  0.2485]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3810, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7224,  0.1025],\n","        [-0.6246,  0.2482]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3801, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7225,  0.1024],\n","        [-0.6251,  0.2478]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3792, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7226,  0.1022],\n","        [-0.6256,  0.2475]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3784, grad_fn=<MseLossBackward>)\n","Step:500 Loss:2.378370523452759 \n","first thing None\n","y_pred tensor([[-0.7228,  0.1021],\n","        [-0.6261,  0.2471]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3775, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7229,  0.1019],\n","        [-0.6266,  0.2468]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3766, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7230,  0.1017],\n","        [-0.6271,  0.2464]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3758, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7231,  0.1016],\n","        [-0.6276,  0.2460]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3749, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7233,  0.1014],\n","        [-0.6281,  0.2457]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3740, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7234,  0.1013],\n","        [-0.6286,  0.2453]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3731, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7235,  0.1011],\n","        [-0.6290,  0.2450]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3723, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7237,  0.1010],\n","        [-0.6295,  0.2446]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3714, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7238,  0.1008],\n","        [-0.6300,  0.2443]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3705, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7239,  0.1006],\n","        [-0.6305,  0.2439]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3697, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7240,  0.1005],\n","        [-0.6310,  0.2436]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3688, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7242,  0.1003],\n","        [-0.6315,  0.2432]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3679, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7243,  0.1002],\n","        [-0.6320,  0.2429]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3670, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7244,  0.1000],\n","        [-0.6325,  0.2425]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3662, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7246,  0.0999],\n","        [-0.6330,  0.2422]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3653, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7247,  0.0997],\n","        [-0.6335,  0.2418]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3644, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7248,  0.0996],\n","        [-0.6340,  0.2415]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3636, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7249,  0.0994],\n","        [-0.6345,  0.2411]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3627, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7251,  0.0992],\n","        [-0.6350,  0.2407]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3618, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7252,  0.0991],\n","        [-0.6355,  0.2404]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3610, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7253,  0.0989],\n","        [-0.6360,  0.2400]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3601, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7255,  0.0988],\n","        [-0.6364,  0.2397]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3592, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7256,  0.0986],\n","        [-0.6369,  0.2393]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3584, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7257,  0.0985],\n","        [-0.6374,  0.2390]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3575, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7258,  0.0983],\n","        [-0.6379,  0.2386]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3566, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7260,  0.0981],\n","        [-0.6384,  0.2383]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3558, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7261,  0.0980],\n","        [-0.6389,  0.2379]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3549, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7262,  0.0978],\n","        [-0.6394,  0.2376]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3540, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7264,  0.0977],\n","        [-0.6399,  0.2372]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3532, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7265,  0.0975],\n","        [-0.6404,  0.2369]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3523, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7266,  0.0974],\n","        [-0.6409,  0.2365]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3514, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7267,  0.0972],\n","        [-0.6414,  0.2361]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3506, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7269,  0.0970],\n","        [-0.6419,  0.2358]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3497, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7270,  0.0969],\n","        [-0.6424,  0.2354]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3488, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7271,  0.0967],\n","        [-0.6429,  0.2351]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3480, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7273,  0.0966],\n","        [-0.6434,  0.2347]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3471, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7274,  0.0964],\n","        [-0.6438,  0.2344]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3462, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7275,  0.0963],\n","        [-0.6443,  0.2340]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3454, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7276,  0.0961],\n","        [-0.6448,  0.2337]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3445, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7278,  0.0959],\n","        [-0.6453,  0.2333]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3436, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7279,  0.0958],\n","        [-0.6458,  0.2330]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3428, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7280,  0.0956],\n","        [-0.6463,  0.2326]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3419, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7281,  0.0955],\n","        [-0.6468,  0.2323]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3411, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7283,  0.0953],\n","        [-0.6473,  0.2319]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3402, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7284,  0.0952],\n","        [-0.6478,  0.2316]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3393, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7285,  0.0950],\n","        [-0.6483,  0.2312]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3385, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7287,  0.0948],\n","        [-0.6488,  0.2308]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3376, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7288,  0.0947],\n","        [-0.6493,  0.2305]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3367, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7289,  0.0945],\n","        [-0.6498,  0.2301]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3359, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7290,  0.0944],\n","        [-0.6503,  0.2298]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3350, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7292,  0.0942],\n","        [-0.6508,  0.2294]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3341, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7293,  0.0941],\n","        [-0.6512,  0.2291]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3333, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7294,  0.0939],\n","        [-0.6517,  0.2287]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3324, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7295,  0.0938],\n","        [-0.6522,  0.2284]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3316, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7297,  0.0936],\n","        [-0.6527,  0.2280]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3307, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7298,  0.0934],\n","        [-0.6532,  0.2277]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3298, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7299,  0.0933],\n","        [-0.6537,  0.2273]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3290, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7301,  0.0931],\n","        [-0.6542,  0.2269]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3281, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7302,  0.0930],\n","        [-0.6547,  0.2266]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3273, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7303,  0.0928],\n","        [-0.6552,  0.2262]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3264, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7304,  0.0927],\n","        [-0.6557,  0.2259]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3255, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7306,  0.0925],\n","        [-0.6562,  0.2255]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3247, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7307,  0.0923],\n","        [-0.6567,  0.2252]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3238, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7308,  0.0922],\n","        [-0.6572,  0.2248]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3230, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7309,  0.0920],\n","        [-0.6577,  0.2245]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3221, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7311,  0.0919],\n","        [-0.6581,  0.2241]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3212, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7312,  0.0917],\n","        [-0.6586,  0.2238]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3204, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7313,  0.0916],\n","        [-0.6591,  0.2234]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3195, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7315,  0.0914],\n","        [-0.6596,  0.2231]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3187, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7316,  0.0912],\n","        [-0.6601,  0.2227]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3178, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7317,  0.0911],\n","        [-0.6606,  0.2223]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3169, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7318,  0.0909],\n","        [-0.6611,  0.2220]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3161, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7320,  0.0908],\n","        [-0.6616,  0.2216]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3152, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7321,  0.0906],\n","        [-0.6621,  0.2213]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3144, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7322,  0.0905],\n","        [-0.6626,  0.2209]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3135, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7323,  0.0903],\n","        [-0.6631,  0.2206]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3127, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7325,  0.0902],\n","        [-0.6636,  0.2202]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3118, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7326,  0.0900],\n","        [-0.6641,  0.2199]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3109, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7327,  0.0898],\n","        [-0.6646,  0.2195]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3101, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7328,  0.0897],\n","        [-0.6650,  0.2192]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3092, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7330,  0.0895],\n","        [-0.6655,  0.2188]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3084, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7331,  0.0894],\n","        [-0.6660,  0.2184]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3075, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7332,  0.0892],\n","        [-0.6665,  0.2181]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3067, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7334,  0.0891],\n","        [-0.6670,  0.2177]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3058, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7335,  0.0889],\n","        [-0.6675,  0.2174]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3049, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7336,  0.0887],\n","        [-0.6680,  0.2170]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3041, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7337,  0.0886],\n","        [-0.6685,  0.2167]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3032, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7339,  0.0884],\n","        [-0.6690,  0.2163]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3024, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7340,  0.0883],\n","        [-0.6695,  0.2160]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3015, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7341,  0.0881],\n","        [-0.6700,  0.2156]], grad_fn=<AddmmBackward>)\n","loss tensor(2.3007, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7342,  0.0880],\n","        [-0.6705,  0.2153]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2998, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7344,  0.0878],\n","        [-0.6710,  0.2149]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2990, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7345,  0.0877],\n","        [-0.6715,  0.2145]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2981, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7346,  0.0875],\n","        [-0.6719,  0.2142]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2972, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7347,  0.0873],\n","        [-0.6724,  0.2138]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2964, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7349,  0.0872],\n","        [-0.6729,  0.2135]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2955, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7350,  0.0870],\n","        [-0.6734,  0.2131]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2947, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7351,  0.0869],\n","        [-0.6739,  0.2128]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2938, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7352,  0.0867],\n","        [-0.6744,  0.2124]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2930, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7354,  0.0866],\n","        [-0.6749,  0.2121]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2921, grad_fn=<MseLossBackward>)\n","Step:600 Loss:2.2921195030212402 \n","first thing None\n","y_pred tensor([[-0.7355,  0.0864],\n","        [-0.6754,  0.2117]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2913, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7356,  0.0862],\n","        [-0.6759,  0.2113]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2904, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7358,  0.0861],\n","        [-0.6764,  0.2110]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2896, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7359,  0.0859],\n","        [-0.6769,  0.2106]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2887, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7360,  0.0858],\n","        [-0.6774,  0.2103]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2879, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7361,  0.0856],\n","        [-0.6779,  0.2099]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2870, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7363,  0.0855],\n","        [-0.6784,  0.2096]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2861, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7364,  0.0853],\n","        [-0.6788,  0.2092]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2853, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7365,  0.0852],\n","        [-0.6793,  0.2089]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2844, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7366,  0.0850],\n","        [-0.6798,  0.2085]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2836, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7368,  0.0848],\n","        [-0.6803,  0.2082]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2827, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7369,  0.0847],\n","        [-0.6808,  0.2078]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2819, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7370,  0.0845],\n","        [-0.6813,  0.2074]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2810, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7371,  0.0844],\n","        [-0.6818,  0.2071]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2802, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7373,  0.0842],\n","        [-0.6823,  0.2067]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2793, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7374,  0.0841],\n","        [-0.6828,  0.2064]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2785, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7375,  0.0839],\n","        [-0.6833,  0.2060]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2776, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7376,  0.0837],\n","        [-0.6838,  0.2057]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2768, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7378,  0.0836],\n","        [-0.6843,  0.2053]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2759, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7379,  0.0834],\n","        [-0.6848,  0.2050]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2751, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7380,  0.0833],\n","        [-0.6853,  0.2046]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2742, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7381,  0.0831],\n","        [-0.6858,  0.2042]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2734, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7383,  0.0830],\n","        [-0.6862,  0.2039]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2725, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7384,  0.0828],\n","        [-0.6867,  0.2035]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2717, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7385,  0.0827],\n","        [-0.6872,  0.2032]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2708, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7386,  0.0825],\n","        [-0.6877,  0.2028]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2700, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7388,  0.0823],\n","        [-0.6882,  0.2025]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2691, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7389,  0.0822],\n","        [-0.6887,  0.2021]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2683, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7390,  0.0820],\n","        [-0.6892,  0.2017]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2674, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7391,  0.0819],\n","        [-0.6897,  0.2014]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2666, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7393,  0.0817],\n","        [-0.6902,  0.2010]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2657, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7394,  0.0816],\n","        [-0.6907,  0.2007]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2649, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7395,  0.0814],\n","        [-0.6912,  0.2003]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2640, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7396,  0.0812],\n","        [-0.6917,  0.2000]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2632, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7398,  0.0811],\n","        [-0.6922,  0.1996]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2623, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7399,  0.0809],\n","        [-0.6927,  0.1993]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2615, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7400,  0.0808],\n","        [-0.6931,  0.1989]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2606, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7401,  0.0806],\n","        [-0.6936,  0.1985]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2598, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7403,  0.0805],\n","        [-0.6941,  0.1982]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2590, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7404,  0.0803],\n","        [-0.6946,  0.1978]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2581, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7405,  0.0802],\n","        [-0.6951,  0.1975]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2573, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7406,  0.0800],\n","        [-0.6956,  0.1971]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2564, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7408,  0.0798],\n","        [-0.6961,  0.1968]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2556, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7409,  0.0797],\n","        [-0.6966,  0.1964]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2547, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7410,  0.0795],\n","        [-0.6971,  0.1960]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2539, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7411,  0.0794],\n","        [-0.6976,  0.1957]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2530, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7413,  0.0792],\n","        [-0.6981,  0.1953]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2522, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7414,  0.0791],\n","        [-0.6986,  0.1950]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2513, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7415,  0.0789],\n","        [-0.6991,  0.1946]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2505, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7416,  0.0788],\n","        [-0.6996,  0.1943]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2496, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7418,  0.0786],\n","        [-0.7001,  0.1939]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2488, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7419,  0.0784],\n","        [-0.7005,  0.1936]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2480, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7420,  0.0783],\n","        [-0.7010,  0.1932]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2471, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7421,  0.0781],\n","        [-0.7015,  0.1928]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2463, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7423,  0.0780],\n","        [-0.7020,  0.1925]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2454, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7424,  0.0778],\n","        [-0.7025,  0.1921]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2446, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7425,  0.0777],\n","        [-0.7030,  0.1918]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2437, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7426,  0.0775],\n","        [-0.7035,  0.1914]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2429, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7428,  0.0773],\n","        [-0.7040,  0.1911]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2420, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7429,  0.0772],\n","        [-0.7045,  0.1907]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2412, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7430,  0.0770],\n","        [-0.7050,  0.1903]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2403, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7431,  0.0769],\n","        [-0.7055,  0.1900]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2395, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7433,  0.0767],\n","        [-0.7060,  0.1896]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2387, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7434,  0.0766],\n","        [-0.7065,  0.1893]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2378, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7435,  0.0764],\n","        [-0.7070,  0.1889]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2370, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7436,  0.0763],\n","        [-0.7075,  0.1886]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2361, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7438,  0.0761],\n","        [-0.7079,  0.1882]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2353, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7439,  0.0759],\n","        [-0.7084,  0.1878]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2344, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7440,  0.0758],\n","        [-0.7089,  0.1875]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2336, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7441,  0.0756],\n","        [-0.7094,  0.1871]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2328, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7443,  0.0755],\n","        [-0.7099,  0.1868]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2319, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7444,  0.0753],\n","        [-0.7104,  0.1864]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2311, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7445,  0.0752],\n","        [-0.7109,  0.1861]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2302, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7446,  0.0750],\n","        [-0.7114,  0.1857]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2294, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7447,  0.0749],\n","        [-0.7119,  0.1853]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2285, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7449,  0.0747],\n","        [-0.7124,  0.1850]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2277, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7450,  0.0745],\n","        [-0.7129,  0.1846]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2269, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7451,  0.0744],\n","        [-0.7134,  0.1843]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2260, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7452,  0.0742],\n","        [-0.7139,  0.1839]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2252, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7454,  0.0741],\n","        [-0.7144,  0.1835]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2243, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7455,  0.0739],\n","        [-0.7149,  0.1832]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2235, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7456,  0.0738],\n","        [-0.7153,  0.1828]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2227, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7457,  0.0736],\n","        [-0.7158,  0.1825]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2218, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7459,  0.0735],\n","        [-0.7163,  0.1821]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2210, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7460,  0.0733],\n","        [-0.7168,  0.1818]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2201, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7461,  0.0731],\n","        [-0.7173,  0.1814]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2193, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7462,  0.0730],\n","        [-0.7178,  0.1810]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2185, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7464,  0.0728],\n","        [-0.7183,  0.1807]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2176, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7465,  0.0727],\n","        [-0.7188,  0.1803]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2168, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7466,  0.0725],\n","        [-0.7193,  0.1800]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2159, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7467,  0.0724],\n","        [-0.7198,  0.1796]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2151, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7469,  0.0722],\n","        [-0.7203,  0.1792]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2143, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7470,  0.0721],\n","        [-0.7208,  0.1789]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2134, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7471,  0.0719],\n","        [-0.7213,  0.1785]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2126, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7472,  0.0717],\n","        [-0.7218,  0.1782]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2117, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7473,  0.0716],\n","        [-0.7223,  0.1778]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2109, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7475,  0.0714],\n","        [-0.7228,  0.1775]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2101, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7476,  0.0713],\n","        [-0.7232,  0.1771]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2092, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7477,  0.0711],\n","        [-0.7237,  0.1767]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2084, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7478,  0.0710],\n","        [-0.7242,  0.1764]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2075, grad_fn=<MseLossBackward>)\n","Step:700 Loss:2.2075366973876953 \n","first thing None\n","y_pred tensor([[-0.7480,  0.0708],\n","        [-0.7247,  0.1760]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2067, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7481,  0.0706],\n","        [-0.7252,  0.1757]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2059, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7482,  0.0705],\n","        [-0.7257,  0.1753]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2050, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7483,  0.0703],\n","        [-0.7262,  0.1749]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2042, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7485,  0.0702],\n","        [-0.7267,  0.1746]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2033, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7486,  0.0700],\n","        [-0.7272,  0.1742]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2025, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7487,  0.0699],\n","        [-0.7277,  0.1739]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2017, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7488,  0.0697],\n","        [-0.7282,  0.1735]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2008, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7489,  0.0696],\n","        [-0.7287,  0.1731]], grad_fn=<AddmmBackward>)\n","loss tensor(2.2000, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7491,  0.0694],\n","        [-0.7292,  0.1728]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1992, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7492,  0.0692],\n","        [-0.7297,  0.1724]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1983, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7493,  0.0691],\n","        [-0.7302,  0.1721]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1975, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7494,  0.0689],\n","        [-0.7307,  0.1717]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1966, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7496,  0.0688],\n","        [-0.7312,  0.1714]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1958, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7497,  0.0686],\n","        [-0.7316,  0.1710]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1950, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7498,  0.0685],\n","        [-0.7321,  0.1706]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1941, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7499,  0.0683],\n","        [-0.7326,  0.1703]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1933, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7501,  0.0682],\n","        [-0.7331,  0.1699]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1925, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7502,  0.0680],\n","        [-0.7336,  0.1696]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1916, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7503,  0.0678],\n","        [-0.7341,  0.1692]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1908, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7504,  0.0677],\n","        [-0.7346,  0.1688]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1900, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7505,  0.0675],\n","        [-0.7351,  0.1685]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1891, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7507,  0.0674],\n","        [-0.7356,  0.1681]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1883, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7508,  0.0672],\n","        [-0.7361,  0.1678]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1874, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7509,  0.0671],\n","        [-0.7366,  0.1674]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1866, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7510,  0.0669],\n","        [-0.7371,  0.1670]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1858, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7512,  0.0668],\n","        [-0.7376,  0.1667]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1849, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7513,  0.0666],\n","        [-0.7381,  0.1663]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1841, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7514,  0.0664],\n","        [-0.7386,  0.1660]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1833, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7515,  0.0663],\n","        [-0.7391,  0.1656]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1824, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7516,  0.0661],\n","        [-0.7396,  0.1652]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1816, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7518,  0.0660],\n","        [-0.7400,  0.1649]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1808, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7519,  0.0658],\n","        [-0.7405,  0.1645]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1799, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7520,  0.0657],\n","        [-0.7410,  0.1642]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1791, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7521,  0.0655],\n","        [-0.7415,  0.1638]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1783, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7523,  0.0654],\n","        [-0.7420,  0.1634]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1774, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7524,  0.0652],\n","        [-0.7425,  0.1631]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1766, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7525,  0.0650],\n","        [-0.7430,  0.1627]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1758, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7526,  0.0649],\n","        [-0.7435,  0.1623]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1749, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7527,  0.0647],\n","        [-0.7440,  0.1620]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1741, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7529,  0.0646],\n","        [-0.7445,  0.1616]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1733, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7530,  0.0644],\n","        [-0.7450,  0.1613]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1724, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7531,  0.0643],\n","        [-0.7455,  0.1609]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1716, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7532,  0.0641],\n","        [-0.7460,  0.1605]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1708, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7534,  0.0640],\n","        [-0.7465,  0.1602]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1699, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7535,  0.0638],\n","        [-0.7470,  0.1598]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1691, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7536,  0.0637],\n","        [-0.7475,  0.1595]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1683, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7537,  0.0635],\n","        [-0.7480,  0.1591]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1674, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7538,  0.0633],\n","        [-0.7485,  0.1587]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1666, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7540,  0.0632],\n","        [-0.7490,  0.1584]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1658, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7541,  0.0630],\n","        [-0.7494,  0.1580]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1649, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7542,  0.0629],\n","        [-0.7499,  0.1577]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1641, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7543,  0.0627],\n","        [-0.7504,  0.1573]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1633, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7545,  0.0626],\n","        [-0.7509,  0.1569]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1624, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7546,  0.0624],\n","        [-0.7514,  0.1566]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1616, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7547,  0.0623],\n","        [-0.7519,  0.1562]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1608, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7548,  0.0621],\n","        [-0.7524,  0.1558]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1599, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7549,  0.0619],\n","        [-0.7529,  0.1555]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1591, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7551,  0.0618],\n","        [-0.7534,  0.1551]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1583, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7552,  0.0616],\n","        [-0.7539,  0.1548]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1574, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7553,  0.0615],\n","        [-0.7544,  0.1544]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1566, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7554,  0.0613],\n","        [-0.7549,  0.1540]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1558, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7555,  0.0612],\n","        [-0.7554,  0.1537]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1549, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7557,  0.0610],\n","        [-0.7559,  0.1533]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1541, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7558,  0.0609],\n","        [-0.7564,  0.1529]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1533, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7559,  0.0607],\n","        [-0.7569,  0.1526]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1525, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7560,  0.0605],\n","        [-0.7574,  0.1522]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1516, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7562,  0.0604],\n","        [-0.7579,  0.1519]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1508, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7563,  0.0602],\n","        [-0.7584,  0.1515]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1500, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7564,  0.0601],\n","        [-0.7589,  0.1511]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1491, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7565,  0.0599],\n","        [-0.7593,  0.1508]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1483, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7566,  0.0598],\n","        [-0.7598,  0.1504]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1475, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7568,  0.0596],\n","        [-0.7603,  0.1500]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1466, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7569,  0.0595],\n","        [-0.7608,  0.1497]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1458, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7570,  0.0593],\n","        [-0.7613,  0.1493]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1450, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7571,  0.0591],\n","        [-0.7618,  0.1490]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1442, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7572,  0.0590],\n","        [-0.7623,  0.1486]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1433, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7574,  0.0588],\n","        [-0.7628,  0.1482]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1425, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7575,  0.0587],\n","        [-0.7633,  0.1479]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1417, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7576,  0.0585],\n","        [-0.7638,  0.1475]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1408, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7577,  0.0584],\n","        [-0.7643,  0.1471]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1400, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7579,  0.0582],\n","        [-0.7648,  0.1468]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1392, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7580,  0.0581],\n","        [-0.7653,  0.1464]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1384, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7581,  0.0579],\n","        [-0.7658,  0.1461]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1375, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7582,  0.0578],\n","        [-0.7663,  0.1457]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1367, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7583,  0.0576],\n","        [-0.7668,  0.1453]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1359, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7585,  0.0574],\n","        [-0.7673,  0.1450]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1350, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7586,  0.0573],\n","        [-0.7678,  0.1446]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1342, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7587,  0.0571],\n","        [-0.7683,  0.1442]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1334, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7588,  0.0570],\n","        [-0.7688,  0.1439]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1326, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7589,  0.0568],\n","        [-0.7693,  0.1435]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1317, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7591,  0.0567],\n","        [-0.7698,  0.1431]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1309, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7592,  0.0565],\n","        [-0.7703,  0.1428]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1301, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7593,  0.0564],\n","        [-0.7707,  0.1424]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1292, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7594,  0.0562],\n","        [-0.7712,  0.1421]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1284, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7595,  0.0560],\n","        [-0.7717,  0.1417]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1276, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7597,  0.0559],\n","        [-0.7722,  0.1413]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1268, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7598,  0.0557],\n","        [-0.7727,  0.1410]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1259, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7599,  0.0556],\n","        [-0.7732,  0.1406]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1251, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7600,  0.0554],\n","        [-0.7737,  0.1402]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1243, grad_fn=<MseLossBackward>)\n","Step:800 Loss:2.124277353286743 \n","first thing None\n","y_pred tensor([[-0.7601,  0.0553],\n","        [-0.7742,  0.1399]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1235, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7603,  0.0551],\n","        [-0.7747,  0.1395]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1226, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7604,  0.0550],\n","        [-0.7752,  0.1391]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1218, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7605,  0.0548],\n","        [-0.7757,  0.1388]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1210, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7606,  0.0546],\n","        [-0.7762,  0.1384]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1201, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7607,  0.0545],\n","        [-0.7767,  0.1380]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1193, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7609,  0.0543],\n","        [-0.7772,  0.1377]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1185, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7610,  0.0542],\n","        [-0.7777,  0.1373]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1177, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7611,  0.0540],\n","        [-0.7782,  0.1370]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1168, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7612,  0.0539],\n","        [-0.7787,  0.1366]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1160, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7613,  0.0537],\n","        [-0.7792,  0.1362]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1152, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7615,  0.0536],\n","        [-0.7797,  0.1359]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1144, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7616,  0.0534],\n","        [-0.7802,  0.1355]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1135, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7617,  0.0533],\n","        [-0.7807,  0.1351]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1127, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7618,  0.0531],\n","        [-0.7812,  0.1348]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1119, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7619,  0.0529],\n","        [-0.7817,  0.1344]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1111, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7621,  0.0528],\n","        [-0.7822,  0.1340]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1102, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7622,  0.0526],\n","        [-0.7827,  0.1337]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1094, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7623,  0.0525],\n","        [-0.7832,  0.1333]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1086, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7624,  0.0523],\n","        [-0.7837,  0.1329]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1078, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7625,  0.0522],\n","        [-0.7842,  0.1326]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1069, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7627,  0.0520],\n","        [-0.7846,  0.1322]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1061, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7628,  0.0519],\n","        [-0.7851,  0.1318]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1053, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7629,  0.0517],\n","        [-0.7856,  0.1315]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1045, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7630,  0.0516],\n","        [-0.7861,  0.1311]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1036, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7631,  0.0514],\n","        [-0.7866,  0.1307]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1028, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7633,  0.0512],\n","        [-0.7871,  0.1304]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1020, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7634,  0.0511],\n","        [-0.7876,  0.1300]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1012, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7635,  0.0509],\n","        [-0.7881,  0.1296]], grad_fn=<AddmmBackward>)\n","loss tensor(2.1003, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7636,  0.0508],\n","        [-0.7886,  0.1293]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0995, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7637,  0.0506],\n","        [-0.7891,  0.1289]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0987, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7639,  0.0505],\n","        [-0.7896,  0.1285]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0979, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7640,  0.0503],\n","        [-0.7901,  0.1282]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0970, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7641,  0.0502],\n","        [-0.7906,  0.1278]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0962, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7642,  0.0500],\n","        [-0.7911,  0.1274]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0954, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7643,  0.0498],\n","        [-0.7916,  0.1271]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0946, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7645,  0.0497],\n","        [-0.7921,  0.1267]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0938, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7646,  0.0495],\n","        [-0.7926,  0.1263]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0929, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7647,  0.0494],\n","        [-0.7931,  0.1260]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0921, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7648,  0.0492],\n","        [-0.7936,  0.1256]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0913, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7649,  0.0491],\n","        [-0.7941,  0.1252]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0905, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7651,  0.0489],\n","        [-0.7946,  0.1249]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0896, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7652,  0.0488],\n","        [-0.7951,  0.1245]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0888, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7653,  0.0486],\n","        [-0.7956,  0.1241]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0880, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7654,  0.0485],\n","        [-0.7961,  0.1238]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0872, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7655,  0.0483],\n","        [-0.7966,  0.1234]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0863, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7657,  0.0481],\n","        [-0.7971,  0.1230]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0855, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7658,  0.0480],\n","        [-0.7976,  0.1227]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0847, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7659,  0.0478],\n","        [-0.7981,  0.1223]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0839, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7660,  0.0477],\n","        [-0.7986,  0.1219]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0831, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7661,  0.0475],\n","        [-0.7991,  0.1216]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0822, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7662,  0.0474],\n","        [-0.7996,  0.1212]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0814, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7664,  0.0472],\n","        [-0.8001,  0.1208]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0806, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7665,  0.0471],\n","        [-0.8006,  0.1205]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0798, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7666,  0.0469],\n","        [-0.8011,  0.1201]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0790, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7667,  0.0468],\n","        [-0.8016,  0.1197]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0781, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7668,  0.0466],\n","        [-0.8021,  0.1194]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0773, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7670,  0.0464],\n","        [-0.8026,  0.1190]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0765, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7671,  0.0463],\n","        [-0.8031,  0.1186]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0757, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7672,  0.0461],\n","        [-0.8035,  0.1182]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0748, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7673,  0.0460],\n","        [-0.8040,  0.1179]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0740, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7674,  0.0458],\n","        [-0.8045,  0.1175]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0732, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7676,  0.0457],\n","        [-0.8050,  0.1171]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0724, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7677,  0.0455],\n","        [-0.8055,  0.1168]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0716, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7678,  0.0454],\n","        [-0.8060,  0.1164]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0707, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7679,  0.0452],\n","        [-0.8065,  0.1160]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0699, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7680,  0.0451],\n","        [-0.8070,  0.1157]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0691, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7681,  0.0449],\n","        [-0.8075,  0.1153]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0683, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7683,  0.0447],\n","        [-0.8080,  0.1149]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0675, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7684,  0.0446],\n","        [-0.8085,  0.1146]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0666, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7685,  0.0444],\n","        [-0.8090,  0.1142]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0658, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7686,  0.0443],\n","        [-0.8095,  0.1138]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0650, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7687,  0.0441],\n","        [-0.8100,  0.1135]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0642, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7689,  0.0440],\n","        [-0.8105,  0.1131]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0634, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7690,  0.0438],\n","        [-0.8110,  0.1127]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0625, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7691,  0.0437],\n","        [-0.8115,  0.1123]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0617, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7692,  0.0435],\n","        [-0.8120,  0.1120]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0609, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7693,  0.0434],\n","        [-0.8125,  0.1116]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0601, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7694,  0.0432],\n","        [-0.8130,  0.1112]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0593, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7696,  0.0430],\n","        [-0.8135,  0.1109]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0584, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7697,  0.0429],\n","        [-0.8140,  0.1105]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0576, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7698,  0.0427],\n","        [-0.8145,  0.1101]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0568, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7699,  0.0426],\n","        [-0.8150,  0.1098]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0560, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7700,  0.0424],\n","        [-0.8155,  0.1094]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0552, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7702,  0.0423],\n","        [-0.8160,  0.1090]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0543, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7703,  0.0421],\n","        [-0.8165,  0.1086]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0535, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7704,  0.0420],\n","        [-0.8170,  0.1083]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0527, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7705,  0.0418],\n","        [-0.8175,  0.1079]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0519, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7706,  0.0417],\n","        [-0.8180,  0.1075]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0511, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7707,  0.0415],\n","        [-0.8185,  0.1072]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0503, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7709,  0.0413],\n","        [-0.8190,  0.1068]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0494, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7710,  0.0412],\n","        [-0.8195,  0.1064]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0486, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7711,  0.0410],\n","        [-0.8200,  0.1060]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0478, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7712,  0.0409],\n","        [-0.8205,  0.1057]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0470, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7713,  0.0407],\n","        [-0.8210,  0.1053]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0462, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7715,  0.0406],\n","        [-0.8215,  0.1049]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0453, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7716,  0.0404],\n","        [-0.8220,  0.1046]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0445, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7717,  0.0403],\n","        [-0.8225,  0.1042]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0437, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7718,  0.0401],\n","        [-0.8230,  0.1038]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0429, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7719,  0.0400],\n","        [-0.8235,  0.1035]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0421, grad_fn=<MseLossBackward>)\n","Step:900 Loss:2.0420796871185303 \n","first thing None\n","y_pred tensor([[-0.7720,  0.0398],\n","        [-0.8240,  0.1031]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0413, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7722,  0.0396],\n","        [-0.8245,  0.1027]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0404, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7723,  0.0395],\n","        [-0.8250,  0.1023]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0396, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7724,  0.0393],\n","        [-0.8255,  0.1020]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0388, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7725,  0.0392],\n","        [-0.8260,  0.1016]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0380, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7726,  0.0390],\n","        [-0.8265,  0.1012]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0372, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7727,  0.0389],\n","        [-0.8270,  0.1008]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0364, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7729,  0.0387],\n","        [-0.8275,  0.1005]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0355, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7730,  0.0386],\n","        [-0.8280,  0.1001]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0347, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7731,  0.0384],\n","        [-0.8285,  0.0997]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0339, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7732,  0.0383],\n","        [-0.8290,  0.0994]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0331, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7733,  0.0381],\n","        [-0.8295,  0.0990]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0323, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7734,  0.0379],\n","        [-0.8300,  0.0986]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0315, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7736,  0.0378],\n","        [-0.8305,  0.0982]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0306, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7737,  0.0376],\n","        [-0.8310,  0.0979]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0298, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7738,  0.0375],\n","        [-0.8315,  0.0975]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0290, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7739,  0.0373],\n","        [-0.8320,  0.0971]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0282, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7740,  0.0372],\n","        [-0.8325,  0.0968]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0274, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7741,  0.0370],\n","        [-0.8330,  0.0964]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0266, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7743,  0.0369],\n","        [-0.8335,  0.0960]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0257, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7744,  0.0367],\n","        [-0.8340,  0.0956]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0249, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7745,  0.0366],\n","        [-0.8345,  0.0953]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0241, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7746,  0.0364],\n","        [-0.8350,  0.0949]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0233, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7747,  0.0363],\n","        [-0.8355,  0.0945]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0225, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7749,  0.0361],\n","        [-0.8360,  0.0941]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0217, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7750,  0.0359],\n","        [-0.8365,  0.0938]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0209, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7751,  0.0358],\n","        [-0.8370,  0.0934]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0200, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7752,  0.0356],\n","        [-0.8375,  0.0930]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0192, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7753,  0.0355],\n","        [-0.8380,  0.0926]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0184, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7754,  0.0353],\n","        [-0.8385,  0.0923]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0176, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7755,  0.0352],\n","        [-0.8390,  0.0919]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0168, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7757,  0.0350],\n","        [-0.8395,  0.0915]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0160, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7758,  0.0349],\n","        [-0.8400,  0.0911]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0152, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7759,  0.0347],\n","        [-0.8405,  0.0908]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0143, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7760,  0.0346],\n","        [-0.8410,  0.0904]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0135, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7761,  0.0344],\n","        [-0.8415,  0.0900]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0127, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7762,  0.0342],\n","        [-0.8420,  0.0896]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0119, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7764,  0.0341],\n","        [-0.8425,  0.0893]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0111, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7765,  0.0339],\n","        [-0.8430,  0.0889]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0103, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7766,  0.0338],\n","        [-0.8435,  0.0885]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0095, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7767,  0.0336],\n","        [-0.8440,  0.0882]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0086, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7768,  0.0335],\n","        [-0.8445,  0.0878]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0078, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7769,  0.0333],\n","        [-0.8450,  0.0874]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0070, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7771,  0.0332],\n","        [-0.8455,  0.0870]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0062, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7772,  0.0330],\n","        [-0.8460,  0.0867]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0054, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7773,  0.0329],\n","        [-0.8465,  0.0863]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0046, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7774,  0.0327],\n","        [-0.8470,  0.0859]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0038, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7775,  0.0326],\n","        [-0.8475,  0.0855]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0029, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7776,  0.0324],\n","        [-0.8480,  0.0852]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0021, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7778,  0.0322],\n","        [-0.8485,  0.0848]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0013, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7779,  0.0321],\n","        [-0.8490,  0.0844]], grad_fn=<AddmmBackward>)\n","loss tensor(2.0005, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7780,  0.0319],\n","        [-0.8495,  0.0840]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9997, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7781,  0.0318],\n","        [-0.8500,  0.0836]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9989, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7782,  0.0316],\n","        [-0.8505,  0.0833]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9981, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7783,  0.0315],\n","        [-0.8510,  0.0829]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9973, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7785,  0.0313],\n","        [-0.8515,  0.0825]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9964, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7786,  0.0312],\n","        [-0.8520,  0.0821]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9956, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7787,  0.0310],\n","        [-0.8525,  0.0818]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9948, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7788,  0.0309],\n","        [-0.8530,  0.0814]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9940, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7789,  0.0307],\n","        [-0.8535,  0.0810]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9932, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7790,  0.0306],\n","        [-0.8540,  0.0806]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9924, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7791,  0.0304],\n","        [-0.8545,  0.0803]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9916, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7793,  0.0302],\n","        [-0.8550,  0.0799]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9908, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7794,  0.0301],\n","        [-0.8555,  0.0795]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9899, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7795,  0.0299],\n","        [-0.8560,  0.0791]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9891, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7796,  0.0298],\n","        [-0.8566,  0.0788]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9883, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7797,  0.0296],\n","        [-0.8571,  0.0784]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9875, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7798,  0.0295],\n","        [-0.8576,  0.0780]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9867, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7800,  0.0293],\n","        [-0.8581,  0.0776]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9859, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7801,  0.0292],\n","        [-0.8586,  0.0772]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9851, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7802,  0.0290],\n","        [-0.8591,  0.0769]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9843, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7803,  0.0289],\n","        [-0.8596,  0.0765]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9834, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7804,  0.0287],\n","        [-0.8601,  0.0761]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9826, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7805,  0.0286],\n","        [-0.8606,  0.0757]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9818, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7806,  0.0284],\n","        [-0.8611,  0.0754]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9810, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7808,  0.0282],\n","        [-0.8616,  0.0750]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9802, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7809,  0.0281],\n","        [-0.8621,  0.0746]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9794, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7810,  0.0279],\n","        [-0.8626,  0.0742]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9786, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7811,  0.0278],\n","        [-0.8631,  0.0738]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9778, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7812,  0.0276],\n","        [-0.8636,  0.0735]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9770, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7813,  0.0275],\n","        [-0.8641,  0.0731]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9761, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7815,  0.0273],\n","        [-0.8646,  0.0727]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9753, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7816,  0.0272],\n","        [-0.8651,  0.0723]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9745, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7817,  0.0270],\n","        [-0.8656,  0.0720]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9737, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7818,  0.0269],\n","        [-0.8661,  0.0716]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9729, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7819,  0.0267],\n","        [-0.8666,  0.0712]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9721, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7820,  0.0266],\n","        [-0.8671,  0.0708]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9713, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7821,  0.0264],\n","        [-0.8676,  0.0704]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9705, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7823,  0.0262],\n","        [-0.8681,  0.0701]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9697, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7824,  0.0261],\n","        [-0.8686,  0.0697]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9689, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7825,  0.0259],\n","        [-0.8691,  0.0693]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9680, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7826,  0.0258],\n","        [-0.8696,  0.0689]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9672, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7827,  0.0256],\n","        [-0.8701,  0.0685]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9664, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7828,  0.0255],\n","        [-0.8706,  0.0682]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9656, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7829,  0.0253],\n","        [-0.8711,  0.0678]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9648, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7831,  0.0252],\n","        [-0.8716,  0.0674]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9640, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7832,  0.0250],\n","        [-0.8721,  0.0670]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9632, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7833,  0.0249],\n","        [-0.8726,  0.0666]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9624, grad_fn=<MseLossBackward>)\n","first thing None\n","y_pred tensor([[-0.7834,  0.0247],\n","        [-0.8731,  0.0663]], grad_fn=<AddmmBackward>)\n","loss tensor(1.9616, grad_fn=<MseLossBackward>)\n","first thing None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kWiyDkgd3fKL","colab_type":"text"},"source":["If the Loss decrease it means the gradient descent is working !! \n","\n","**Note:** Don't forget the zero_grad()\n","- we are doing gradient backpropagation at each step \n","- gradients are computed with the loss.backward \n","- after each update we must set to zero all the gradients values otherwise they get accumulated (hence zero_grad())"]},{"cell_type":"markdown","metadata":{"id":"HHQDkr5d3fKN","colab_type":"text"},"source":["### Questions : \n","\n","- plot the loss "]},{"cell_type":"code","metadata":{"id":"32iy09sZlMqo","colab_type":"code","outputId":"ae97708d-4381-424d-b40f-409707911c0b","executionInfo":{"status":"ok","timestamp":1585563756788,"user_tz":-120,"elapsed":10475,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":482}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","from torch.optim import SGD, Adam\n","\n","def plot_loss(lr, N, optim_alg, target=None, max_steps=None):\n","    \"\"\"\n","    This function takes as arguments:\n","    lr: the learning rate\n","    N: the number of samples\n","    optim_alg: the optimisation algorithm\n","    target: a target value for the loss ( a message should printed when this \n","            target is reached)\n","    max_steps: the number of gradient steps for the optimisation process\n","    \"\"\"\n","    model = MyModel(D_in, H, D_out)\n","    \n","    x = torch.randn(N, D_in)\n","    y = torch.randn(N, D_out)\n","    \n","    criterion = torch.nn.MSELoss(reduction='mean')\n","    optimizer = optim_alg(model.parameters(), lr=lr)\n","    # t is normally also an index over the samples (or batches) in your dataset,\n","    # but we will just consider it to be a time-step here\n","    loss_list = []\n","    for t in range(max_steps or 20000):\n","        # Forward pass: Compute predicted y by passing x to the model\n","        y_pred = model(x)\n","\n","        # Compute and print loss\n","        loss = criterion(y_pred, y)\n","        loss_list.append(loss.item()) # item is a method for obtaining a python\n","                                      # scalar from a 0-dim tensor\n","        if t % 2000 == 0:\n","            print(\"Step:{} Loss:{} \".format(t, loss.item()))\n","        \n","        if target is not None and loss.item() < target:\n","          print(\"Target {} reached at step {} !!\".format(target, t))\n","          target = None\n","\n","        # Zero gradients, perform a backward pass, and update the weights.\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    plt.plot(range(len(loss_list)), loss_list)\n","    plt.xlabel('steps')\n","    plt.ylabel('Mean Square Error')\n","\n","plt.title('lr: {}, N:{}, optim_alg:{}'.format(1e-4, 2, 'SGD'))\n","plot_loss(lr=1e-4, N=2, optim_alg=SGD)\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Step:0 Loss:0.41059061884880066 \n","Step:2000 Loss:0.13770100474357605 \n","Step:4000 Loss:0.04693802073597908 \n","Step:6000 Loss:0.017203692346811295 \n","Step:8000 Loss:0.00673338770866394 \n","Step:10000 Loss:0.0028918448369950056 \n","Step:12000 Loss:0.0013349975924938917 \n","Step:14000 Loss:0.0006410683272406459 \n","Step:16000 Loss:0.0003133623395115137 \n","Step:18000 Loss:0.00015432070358656347 \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"L7GlPukglC8E","colab_type":"text"},"source":["\n","- how many steps do you need for the loss to reach 1e-1 ? "]},{"cell_type":"code","metadata":{"id":"gVJ7w4EPlNV2","colab_type":"code","outputId":"5070926c-3832-4022-f5b9-4aeb684becfe","executionInfo":{"status":"ok","timestamp":1585563765345,"user_tz":-120,"elapsed":11139,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":501}},"source":["target = 1e-1\n","plt.title('Seeking target value {} for the loss with lr: {}, N:{}, optim_alg:{}'.format(target, 1e-4, 2, 'SGD'))\n","plot_loss(lr=1e-4, N=2, optim_alg=SGD, target=target)\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Step:0 Loss:1.242738962173462 \n","Step:2000 Loss:0.4518018662929535 \n","Step:4000 Loss:0.1473163366317749 \n","Target 0.1 reached at step 4590 !!\n","Step:6000 Loss:0.036303672939538956 \n","Step:8000 Loss:0.007822928950190544 \n","Step:10000 Loss:0.0018115142593160272 \n","Step:12000 Loss:0.0005138959386385977 \n","Step:14000 Loss:0.00017814431339502335 \n","Step:16000 Loss:7.028091931715608e-05 \n","Step:18000 Loss:2.9805873055011034e-05 \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAcEAAAEWCAYAAAAegCx/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"R6Q_z8HElOlt","colab_type":"text"},"source":["\n","- now same question if\n","        - lr=1e-5,1-3 \n","        - N = 10, 100, 1000 (NB : you can )\n","        - optim.Adam "]},{"cell_type":"code","metadata":{"id":"X9RS6C-glPXp","colab_type":"code","outputId":"cd1cdd4a-f4ae-4a4e-c575-8ae2b0147f02","executionInfo":{"status":"ok","timestamp":1585563831537,"user_tz":-120,"elapsed":65700,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for lr in [1e-5, 1e-3]:\n","  plt.title('Seeking target value {} for the loss with lr: {}, N:{}, optim_alg:{}'.format(target, lr, 2, 'SGD'))\n","  plot_loss(lr=lr, N=2, optim_alg=SGD, target=target)\n","  plt.show()\n","for N in [10, 100, 1000]:\n","  plt.title('Seeking target value {} for the loss with lr: {}, N:{}, optim_alg:{}'.format(target, 1e-4, N, 'SGD'))\n","  plot_loss(lr=1e-4, N=N, optim_alg=SGD, target=target)\n","  plt.show()\n","plt.title('Seeking target value {} for the loss with lr: {}, N:{}, optim_alg:{}'.format(target, 1e-4, 2, 'Adam'))\n","plot_loss(lr=1e-4, N=2, optim_alg=Adam, target=target)\n","plt.show()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Step:0 Loss:0.9140158295631409 \n","Step:2000 Loss:0.824977695941925 \n","Step:4000 Loss:0.7460771203041077 \n","Step:6000 Loss:0.6777891516685486 \n","Step:8000 Loss:0.6233746409416199 \n","Step:10000 Loss:0.572714626789093 \n","Step:12000 Loss:0.5254263281822205 \n","Step:14000 Loss:0.48114824295043945 \n","Step:16000 Loss:0.4400867521762848 \n","Step:18000 Loss:0.4019351899623871 \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAboAAAEWCAYAAAAQKVIQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Step:0 Loss:1.3782389163970947 \n","Target 0.1 reached at step 784 !!\n","Step:2000 Loss:6.656722689513117e-05 \n","Step:4000 Loss:8.632932702035134e-10 \n","Step:6000 Loss:1.1668233046435716e-10 \n","Step:8000 Loss:1.1381129372267651e-10 \n","Step:10000 Loss:1.1117873288668534e-10 \n","Step:12000 Loss:1.1025769186545631e-10 \n","Step:14000 Loss:1.0766948443929891e-10 \n","Step:16000 Loss:1.0676803885445452e-10 \n","Step:18000 Loss:1.0515732729032834e-10 \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAboAAAEWCAYAAAAQKVIQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Step:0 Loss:1.0732825994491577 \n","Step:2000 Loss:0.9217032194137573 \n","Step:4000 Loss:0.844029426574707 \n","Step:6000 Loss:0.7957220077514648 \n","Step:8000 Loss:0.7591313123703003 \n","Step:10000 Loss:0.7274149060249329 \n","Step:12000 Loss:0.6976639628410339 \n","Step:14000 Loss:0.6677900552749634 \n","Step:16000 Loss:0.6379891633987427 \n","Step:18000 Loss:0.6070249080657959 \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAckAAAEWCAYAAAANV2yLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyc08VwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Step:0 Loss:1.1433464288711548 \n","Step:2000 Loss:1.0694406032562256 \n","Step:4000 Loss:1.0305896997451782 \n","Step:6000 Loss:1.0077059268951416 \n","Step:8000 Loss:0.9928422570228577 \n","Step:10000 Loss:0.9820494055747986 \n","Step:12000 Loss:0.973360002040863 \n","Step:14000 Loss:0.9658969044685364 \n","Step:16000 Loss:0.959117591381073 \n","Step:18000 Loss:0.9528867602348328 \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdAAAAEWCAYAAADW7MapAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3gc1fX/8fdHkrtlW7bkKndcMDYY\nW2DTa+gEAoTQIYEQQkjgm/JLJSGEhJBGQugEQu8lOITeTCjGBdyNu43lJrnJDVed3x/3CtaKulZa\nlfN6nn20mnpmdnbO3jt37sjMcM4551z1pKU6AOecc64x8gTqnHPO1YAnUOecc64GPIE655xzNeAJ\n1DnnnKsBT6DOOedcDaQsgUq6X9IN5Yy7U9K19R1TYydpiaRjUx1HdUgaImmqpE2SvldH63hb0mVJ\nWlaD28eSXpJ0cQXjy/2ulTFtP0kmKSN5EbrGQtL5kl6t53Um7ftZ3ypNoJIOlfS+pCJJ6yS9J+mA\nugzKzK4ws98ke7mpPjmkev01peAmSWvj6yZJKmfaHpLGSVoRt7VfJYv/f8BbZpZpZrckIdbrJD1c\n2+U0JmZ2opk9ACDpEknvpjIeSSMlTZG0Nf4dWcG0nSU9J2mLpKWSzis1/rw4fIukf0nqXJV5a3Ac\nJq6z5Hv6YqnhD0u6rpx5Wkp6Ov7AMklHlhpf4XeoOvssWco6H5nZI2Z2XF2vO1kk7SPp1ZibNsR9\nd1LC+ExJf4mfyxZJn8bPaUzCNBbHbY6fzRuSvlaV9VeYQCV1AF4A/g50BnoBvwa212RjG7vGlviS\n6HLgdGA/YF/gVOBb5UxbDLwMnFnFZfcFZtUkqGb8eaRETAKVnTNaAs8DDwNZwAPA83F4WW4DdgDd\ngPOBOyTtE5e1D3AXcGEcvxW4vSrzUv3jsCxjJB1cjenfBS4AVpUxrtzvUA32mfvCv4HXgO5AV+B7\nwEYASa2AN4ERwClAB2Bv4HHgxFLL2c/M2gNDgPuBWyX9qtK1m1m5LyAP2FDJNN8A5gDrgVeAvgnj\nhsaNWwfMBc5OGHc/cEN8nwm8BdwCqNS4I4F84AdAAbAS+HrCcrrEnbgRmATcALxbTqyfAgZsjq+D\ngIFxJ68F1gCPAJ0S5lkC/BiYTvjhkAFcBCyN81wbpzk2Tp8G/ARYGMc/CXQub/2l4usJfFYyfRy2\nf4yrRRVjPbb0/k3cj6XW9QxQCCwGvlfBZ/w+cHnC/5cCEyo5LjLitvarYJo3gd3Atrg/BgMdgQdj\nXEuBXwBpcfpLgPeAm+M+uKHU8k4gnFB3xuVNi8PfBn4T590EvApkJ8w3Nm7jBmAacGQFMSfu41bA\nX4EV8fVXoFUcl0348bmBcPz/N2E7fgwsj7HMBY4pYz3947wl89wDFCSMfwi4JmH7LiOcHLbFfbqZ\n+N2Nx8JtwH/iOj8EBpazff3i55aRsOzfxn33GbBXJZ/7cXHbVOp7d0IZ07aLn9fgUtv1+/j+d8Cj\nCeMGxukzK5u3OsdhBfvgx4TakZLhDwPXVWH+/NLHEBV8h6qzz8pZ38GEc19R/Htwwri3gRuBiYRz\n5PNUcD4ifMfeTZjfgCuB+fHY+U38HN6Py3sSaFlJfFmE70IhIU+8AOSWivGy+D4d+DPh/LYYuCrx\neCy13Ow4rlM5672MkC/aVRKflT6ugbMI36UuFc1bWRXuPGC3pAcknSgpK3GkpNOAnwFnADmEk8Rj\ncVw7QvJ8lPDL4BzgdknDSi2jC/AG8J6Zfc9i9KV0J5xYexEOvNsSYrkN2BKnuTi+ynN4/NvJzNqb\n2QeEhH0jIaHsDfQGris137nAyUAnwkn+dsIv3h4JcZX4LuGX5hFxmetjjOWt/3NmtgL4gD1/NZ8H\nPG1mO6sYa6ViKeLfhGTRCzgGuEbS8eXMsk+ctsS0OKxWzOxowjFzVdwf8wi1HR2BAYR9eBHw9YTZ\nxgCLCKWO35Za3suEk+4TcXn7JYw+Ly6nK9AS+CGApF6ExHIDoZblh8AzknKqsAk/JyTfkYSSxYGE\nhA/hB18+4XvRjfA9MUlDCCeFA8wsEziekJRL75vFhBPU/nHQ4cBmSXvH/48AxpeaZw5wBfBB3P5O\nCaPPIdQeZQELKLXvKnEhoQSVCSyV9IKkn5Qz7T7A9FLf4+mUfbwMBnbFz71E4rG1x3FnZguJSbMK\n8ybD7cBglXPNO1YZHlrFZVX0HarOPisdQ2fC8XsLoTDxF+A/8bxa4iJCQacHsCtOC5WcjxIcD4wm\nHOv/D7ibUNLuDQwnnB8rkgb8k1Db1IfwQ+zWcqb9JqF0OBIYRTiXJm7vTyS9EP9dSziWH5Z0uqRu\npZZ1LPCKmW2pJL6yPE/48XVgRRNVmEDNbCNwKCFD3wMUxusKJYFeAdxoZnPMbBfh5DVSUl9CkXmJ\nmf3TzHaZ2ceEEs9XE1bRk3ASeMrMfkH5dgLXm9lOM3uR8GtpiKR0QrL5lZltNbPZhOqPKjOzBWb2\nmpltN7NCwgF4RKnJbjGzZWb2GeGXyb/N7F0z2wH8Mu6fElcAPzezfDPbTkhwZ1WjuvFR4gEZr5Gc\nE4dVNdaqOADIMbPrzWyHmS0ifL7nlDN9e8Kv2xJFQPvEazjJED/Pc4CfmtkmM1tC+DV6YcJkK8zs\n7/GY+qwai/+nmc2L8zxJ+IJCOBG8aGYvmlmxmb0GTAZOKm9BCc4nHJcF8fP4dUKsOwknrL7xuP1v\nPEHuJpRch0lqYWZLYmIoy3jgCEnd4/9Px//7E6qjppUzX1meM7OJ8Xv6SML2V8X9ZjYr7vOdZnaK\nmf2+nGlLHyvE/zPLmXZjBdNWtKzK5k2Gzwg/NMpsgGVmncysqtebK/oOVWeflXYyMN/MHoqfz2PA\nJ4Qq4hIPmdnMmEiuBc6O37Wq+oOZbTSzWcBM4FUzW2RmRcBLfPEjr0xmttbMnonn6E2EfVreeets\n4G/x/Lke2OM4M7Pfm9kp8b0BRxF+gP4ZWCnpHUmD4uTZJFSnx+vMGyRtlDS3kph3EkrBnSuartJG\nRDE5XmJmuYRfGz0JVVUQflH8LQZVUlUlQqmmL+EawoaE8ecTSoolTgbaAHdWEsba+MUvsZVw0OUQ\nfiUsSxiX+L5SkrpJelzSckkbCdU02aUmS1xmz8T/zWwr4ZdQib7AcwnbPIdw0iz966g8zwAHSepB\n+IVYTCilVTXWqugL9Cz12fysghg3E07YJToAm8upLaiNbEJV9dKEYUvZs4Rfrc83QeJ1qZLjB8K+\n+GqpfXEoIflVpmcZsfaM7/9I+HX8qqRFJSU2M1sAXEP4YVUQP8+elG08oer9cOAdQlXXEfH1XzMr\nrkKMJcrb/qqozj4vfawQ/99Ug2krGl+d9dTGP4Bukk6tdMqKVfQdqs22lD4GoeLvzFLCd6w6543V\nCe8/K+P/Co8lSW0l3aXQ0Gsj4VjuVE4S3+P8SiXHXky0V5nZQMJ3eQvhEhCE83KPhGmnxlqZMwg/\nYiuKuQUhv6yraLpq3cZiZp8QrqcMj4OWAd+Kv8RKXm3M7P04bnypce3N7NsJi7yHcKH/xVjlW12F\nhCqJ3IRhvSvahDKG/S4OH2FmHQglktIlq8T5ViauT1IbQtVJiWXAiaW2u7WZLS9n/XuuKPzqehX4\nGqHa8fGERFWVWEtsAdom/J/4w2UZsLhUjJlmVl6paxahirLEftSw4U8l1hBKbn0ThvUhXB8qUdk+\nrG5SX0b4hZ64L9pVUMJKtKKMWFcAxBL0D8xsAPBl4PuSjonjHjWzQ+O8BtxUzvLHA4cRkuh4QiOV\nQyij+jZBXTxeqTrLnAXsW6p2Yl/KPl7mARkJJQbY89ja47iTNIBw4ptXhXmTItYy/Zpw7a82NS4V\nfYeqs89KK30Mwv9+Z3qXGldSuqqvR3H9gNA4Z0w8b5VUHZe1P/c4v1Lx+XwPZraMcLmsJD+9ARxX\nw9xyGiG3TKxoospa1A2V9ANJufH/3oTqxQlxkjuBnya0musoqaSK9gXC9YMLJbWIrwMSruGUuIrQ\nkOLfMRlVmZntBp4Frou/coYS6vvLU0go0Q1IGJZJ+AVYFK+H/aiS1T4NnCrp4NhK7jr2PBDuBH4b\nq7GRlBOvFZe3/rI8GrfjrPi+JrFOBU5SaOrfnVDqKTER2CTpx5LaSEqXNFzl3570ICEB9IqlpR8Q\nfkiVSVJrvviF1yr+X6n4eT5J2H+ZcR9+n1DSrqrVQD9V0lo0wcOEz/P4uB9aSzqy5JivxGPAL+Jn\nnE2ozn8YQNIpkvaKJ8UiQi1EscJ9r0crtBDcRvgFX2ZJ0szmx/EXEH6MbozbdyblJ9DVQK5S14Lz\nbcK2fk9SK0lXxeFvlp4wVik+C1wvqZ2kQwgnrofiJI8QPpvD4knweuDZ+OOksnkrPA4Vbnd6u4rb\n9BDQmtBIrVxxe0vW0TIeSyXnhoq+Q29TwT5TuDVpSTmrfZFwnj1PUobC7RfDCOffEhdIGiapLWEf\nPh2/a1U9H9VWJuE43qBwzbai1q1PAlfH/dSJ0JCrTJKyJP06fs/S4nfwG3yRnx4kJOTn4vktPX4+\neRUss7Ok8wmJ+CYzW1vetFB5CXQTodHGh5K2xMBmEj58zOw5wq/nx2PRfCaxeXCs6z6OcE1rBaEK\n6SZKFZ1j6epyQoOL56t6sk1wFaHRySrCgf4Y5dxmE6tbfwu8F6vrxhJ+XY4inOT+Q/hSliteB/gu\noSn0SkJCK0hY59+AcYSqu02EfTamgvWXZRwwCFhlZonXuaoT60OEa2RLCCXaJxK2YTfhGvVIQku3\nNYSqqo7lLOsuQqOjGYTP+D9xGAAK908dljD9Z4T9AuF6THWuVX6XUHpeRChxPQrcV435n4p/10r6\nqLKJ46/WksZwhYQS6Y+oWu3MDYTrpdMJ++YjvrheNgh4nbAfPgBuN7O3CMf/7wn7fBWhUdNPK1jH\neMIljGUJ/yuuqyxvEkouqyStqcI2VJtCxw0/K2tcLLGdTvgBuIFwQjs9DkfSzyS9lDDLlYTLOAWE\n7+6343es5Lt2BSGRFhBOxFdWZd6oouOwN6FlcaXi9+WXlLoeVsZxPzeuoxfhjoTP+KJ0WO53qLJ9\nVlGs8QR/CuGcvJbQyOcUM0v87B8iJOtVhB8C34vzVvV8VFt/JXxOawjnw5crmPYewvlqOvAx4QfC\nLsIPjNLHzw5Ci+nXCdfDZxLOw5cAmNk2wjXS2YT9vZHwGR1AuNaaaJqkzYTLLpcB/2dmv6xsw5T8\ny1ipJekmoLuZVdQaN5nra0846AdZaDnpnGvgJE0l3D5UYQmjIVDoGehqC62sqzvv28DDZvaPpAdW\nDySdCNxpZqWrqRuERt8Xbqxm3lfBgYTbXJ6r43WeGquM2wF/IvyqXFKX63TOJY+ZjWwMyRPAzI6r\nSfJsjOIlpZNidXQvQnVvnZ7Pa6PRJ1BCtc6zhGq/JwjNmZ+v43Wexhc3zw8CzqmDFqnOOdcoxKrV\nzWW8Xqp87j0XRbhUtZ5QhTuHUH3eIDW5KlznnHOuPjSFEqhzzjlX71LWGbek+witxwrMbHgZ44cS\nun8aRejZ508J45YQWgjvJnTnlReHdyZU4/YjXJM8O95XWaHs7Gzr169f7TbIOeeamSlTpqwxs6p0\ne9kkpawKV9LhhCbmD5aTQLsSmoCfDqwvI4HmlWqqjaQ/AOvM7PcKPb9kmVm59xGVyMvLs8mTJ9dq\ne5xzrrmRNKWkANMcpawK18zeoYJukiz0LzqJ0GtGVZ3GF33hPkCpjoidc865ZGms10CN0FHBFEmX\nJwzvZmYr4/tVVL3/Weecc65aGusDiQ81s+Wxmvc1SZ/EEu3nzMwklVs/HRPv5QB9+vSp22idc841\nOY2yBBo7ZsfMCgg32ZY8s221wlNMiH8LKljG3WaWZ2Z5OTnN9hq4c865Gmp0CTR2HJ1Z8p7Q3+7M\nOHocXzxQ+2LqvkMF55xzzVQqb2N5jPCYpmxJ+YQum1oAmNmdCk8QmUx4Ll6xpGsITxnIJvSuDyH+\nR82spHPi3wNPSrqU8Ny70h0GO+ecc0mRsgRqZudWMn4Vez4XrsRG9nyuXuI8a4Fjah+dc845V7FG\nV4XbkLw0YyX3v+cPYHHOuebIE2gtvDZnNTe/Pp9du8t8HrJzzrkmzBNoLRy7dzeKPtvJlKWV9hbo\nnHOuifEEWguHDcqmRbp445Ny75ZxzjnXRHkCrYXM1i0YO6ALr89ZnepQnHPO1TNPoLV0zNCuLCrc\nwqLCzakOxTnnXD3yBFpLx+wdutt9Y45X4zrnXHPiCbSWenduy5BumV6N65xzzYwn0CQ4Zu+uTF66\nnqKt1XnymnPOucbME2gSHDusG7uLjbfneTWuc841F55Ak2Bkbiey27fkdb8O6pxzzYYn0CRISxNH\nDenK258UsGOX90rknHPNgSfQJDlxRHc2bd/FewvXpDoU55xz9cATaJIcslc2ma0yeGnGylSH4pxz\nrh54Ak2SVhnpHLN3V16dvZqd3rm8c841eZ5Ak+jEET3YsHUnExatTXUozjnn6pgn0CQ6YnAObVum\n8+KMVakOxTnnXB1LWQKVdJ+kAkkzyxk/VNIHkrZL+mHC8N6S3pI0W9IsSVcnjLtO0nJJU+PrpPrY\nlhKtW6Rz9NCuvDprFbuLrT5X7Zxzrp6lsgR6P3BCBePXAd8D/lRq+C7gB2Y2DBgLfEfSsITxN5vZ\nyPh6MZkBV8VJI3qwdssOJi5eV9+rds45V49SlkDN7B1CkixvfIGZTQJ2lhq+0sw+iu83AXOAXnUZ\na3UcOSSH1i3SeGmmt8Z1zrmmrFFfA5XUD9gf+DBh8FWSpscq4qwK5r1c0mRJkwsLC5MWU9uWGRw5\nuCsvzfRqXOeca8oabQKV1B54BrjGzDbGwXcAA4GRwErgz+XNb2Z3m1memeXl5OQkNbaT9+1B4abt\nfLjYW+M651xT1SgTqKQWhOT5iJk9WzLczFab2W4zKwbuAQ5MRXzH7t2Nti3TGTd1RSpW75xzrh40\nugQqScC9wBwz+0upcT0S/v0KUGYL37rWpmU6x+/TnRdnrGT7rt2pCME551wdS+VtLI8BHwBDJOVL\nulTSFZKuiOO7S8oHvg/8Ik7TATgEuBA4uozbVf4gaYak6cBRwP/V/5YFXx7Zk43bdjF+bvKurzrn\nnGs4MlK1YjM7t5Lxq4DcMka9C6iceS5MQmhJcehe2XRp15Lnp67guH26pzoc55xzSdboqnAbixbp\naZy8bw9en7OaTdt2Vj6Dc865RsUTaB06bWRPtu8q5tVZq1MdinPOuSTzBFqHRvXJIjerDf+aujzV\noTjnnEsyT6B1SBKnjezJewvWULBxW6rDcc45l0SeQOvYGaNyKTZ47mMvhTrnXFPiCbSODcxpz6g+\nnXhqSj5m3rWfc841FZ5A68FX83qzoGAzU5dtSHUozjnnksQTaD04Zd8etG6RxlNT8lMdinPOuSTx\nBFoPMlu34MThPfj3tBVs2+ld+znnXFPgCbSefDUvl03bdvHKrFWpDsU551wSeAKtJ2P7dyE3qw1P\nTfZqXOecawo8gdaTtDRx1uhc3lu4hvz1W1MdjnPOuVryBFqPzhod+sZ/ctKyFEfinHOutjyB1qPc\nrLYcNaQrj09axs7dxakOxznnXC14Aq1n54/pQ8Gm7bw22zuYd865xswTaD07ckhXenVqw8MTlqY6\nFOecc7WQsgQq6T5JBZJmljN+qKQPJG2X9MNS406QNFfSAkk/SRjeX9KHcfgTklrW9XZUV3qaOG9M\nH95fuJaFhZtTHY5zzrkaSmUJ9H7ghArGrwO+B/wpcaCkdOA24ERgGHCupGFx9E3AzWa2F7AeuDTJ\nMSfF2Xm9aZEuHv3w01SH4pxzroZSlkDN7B1CkixvfIGZTQJ2lhp1ILDAzBaZ2Q7gceA0SQKOBp6O\n0z0AnJ78yGsvJ7MVx+/Tnaen5HvPRM4510g1xmugvYDE+0Dy47AuwAYz21VqeJkkXS5psqTJhYWF\ndRZseS4Y25eiz3by72kr6n3dzjnnaq8xJtCkMLO7zSzPzPJycnLqff1j+ndmUNf2PPDBEn/MmXPO\nNUKNMYEuB3on/J8bh60FOknKKDW8QZLENw7tz8zlG/lwcbk12c455xqoxphAJwGDYovblsA5wDgL\nxbi3gLPidBcDz6coxir5yv696NyuJfe+uzjVoTjnnKumVN7G8hjwATBEUr6kSyVdIemKOL67pHzg\n+8Av4jQd4jXOq4BXgDnAk2Y2Ky72x8D3JS0gXBO9t763qzpat0jn/DF9eH3Oapas2ZLqcJxzzlWD\n/Pob5OXl2eTJk1Oy7oJN2zj0929x7oG9+fVpw1MSg3PO1YSkKWaWl+o4UqUxVuE2KV0zW3Pqfj15\ncnI+RVtL37HjnHOuofIE2gBcemh/Ptu5m0cnescKzjnXWHgCbQCG9ezAwQO78MD7S/wpLc4510h4\nAm0gLjusP6s2bmPcVO9YwTnnGoNaJVBJ6ZLeSlYwzdlRQ7oytHsmt7+9gOJib9jlnHMNXa0SqJnt\nBooldUxSPM2WJK48ai8WFm7h1dmrUh2Oc865SiSjCnczMEPSvZJuKXklYbnNzskjetCvS1tue2uh\nd+/nnHMNXDIS6LPAtcA7wJSEl6um9DTx7SMHMmN5Ef+dvybV4TjnnKtArROomT0APMYXifPROMzV\nwFf2z6VHx9bc+taCVIfinHOuArVOoJKOBOYTHnJ9OzBP0uG1XW5z1TIjjW8eNoCJi9cxaYl3Mu+c\ncw1VMqpw/wwcZ2ZHmNnhwPHAzUlYbrN1zoG9yW7fkr++Pi/VoTjnnCtHMhJoCzObW/KPmc0DWiRh\nuc1W25YZXHHEQN5bsJYPFq5NdTjOOefKkIwEOkXSPyQdGV/3AKnpmb0JuWBsX7p1aMVfXpvrLXKd\nc64BSkYCvQKYDXwvvmYD307Ccpu11i3SueroQUxasp53vEWuc841OLXuiQiYZmZ/MbMz4utmM9ue\npPiata/l9aZXpzb8+VUvhTrnXEOTjJ6I5krqk6R4XIKWGWlcfewgpucX8drs1akOxznnXIJkVOFm\nAbMkvSFpXMmrspkk3SepQNLMcsYr9mq0QNJ0SaPi8KMkTU14bZN0ehx3v6TFCeNGJmH7UuqM/XvR\nP7sdf3ltnveR65xzDUhGEpZxbQ3nux+4FXiwnPEnAoPiawxwBzDGzN4CRgJI6gwsAF5NmO9HZvZ0\nDWNqcDLS07jm2EFc/fhU/jV1OWeMyk11SM4550jONdC7zGx86Vdl85rZO0BFPQWcBjxowQSgk6Qe\npaY5C3jJzLbWeCMagVP37cm+uR354ytz2bZzd6rDcc45R8O+BtoLWJbwf34clugcQjeCiX4bq3xv\nltSqvIVLulzSZEmTCwsLkxNxHUlLEz87aW9WFm3j3ncXpzoc55xzpPAaaG3F0ugI4JWEwT8FhgIH\nAJ2BH5c3v5ndbWZ5ZpaXk5NTp7Emw9gBXfjSsG7c8fZC1mz2Rs7OOZdqqbwGWpnlQO+E/3PjsBJn\nA8+Z2c6SAWa2Mr7dLumfwA/rKLaU+MmJQznu5nf42+vz+c3pw1MdjnPONWs1LoFKGgoQr3dOKHX9\nMxlFpHHARbE17ligKCFBApxLqerbkmukkgScDpTZwrexGpjTnvPH9OHRiZ+yoGBTqsNxzrlmrTZV\nuI8mvP+g1LjbK5tZ0mNxviGS8iVdKukKSVfESV4EFhFa2d4DXJkwbz9C6bR0Y6VHJM0AZgDZwA1V\n3ppG4upjBtG2RTrXvzDHO1dwzrkUqk0Vrsp5X9b//8PMzq1kvAHfKWfcEv63QRFmdnRl623surRv\nxf99aTDXvzCbV2at5oTh3VMdknPONUu1KYFaOe/L+t8l0UUH9WVo90x+88JsPtvht7U451wq1CaB\n5saegv6e8L7k//8pHbrkyUhP49df3oflGz7j9rcXpDoc55xrlmpThfujhPelH1/mjzOrY2MGdOG0\nkT25a/wizhyVS7/sdqkOyTnnmpUaJ1AzeyCZgbjq+9lJe/P67NX8+t+zuO+SAwiNj51zztWHZHSk\n4FKkW4fW/N+XBvPW3EJenrkq1eE451yz4gm0kbvk4H7s07MDvxw3i6KtOyufwTnnXFJ4Am3kMtLT\nuOnMfVm3ZQc3vjQn1eE451yzUesEKmlw7Ad3Zvx/X0m/qH1orqqG9+rIZYf15/FJy3h/4ZpUh+Oc\nc81CMkqg9xA6cd8JYGbTCU9JcfXommMG07dLW3727Ax/5JlzztWDZCTQtmY2sdSwXUlYrquGNi3T\nufErI1iydit/fGVuqsNxzrkmLxkJdI2kgcTehySdBayseBZXFw7eK5sLx/bl3ncXe1Wuc87VsWQk\n0O8AdwFDJS0HrgGuqHgWV1d+etJQ+me340dPTWfjNm+V65xzdaVWCVRSOnClmR0L5ABDzexQM1ua\nlOhctbVtmcFfzt6PlUWf8etxs1MdjnPONVm1SqBmths4NL7fYmb+kMoGYP8+WXznqL145qN872DB\nOefqSG36wi3xsaRxwFPAlpKBZvZsEpbtaui7Rw/irbkF/Oy5GYzq24muma1THZJzzjUpybgG2hpY\nCxwNnBpfpyRhua4WWmakcfPZI9m8fRc/eHIaxcX+hDnnnEumWidQM/t6Ga9vVDafpPskFZR0wFDG\neMXHoy2QNF3SqIRxuyVNja9xCcP7S/owzvOEpJa13b7GbFC3TH516jD+O38Nd4xfmOpwnHOuSUlG\nT0StJX1H0u0xKd4n6b4qzHo/cEIF408EBsXX5cAdCeM+M7OR8fXlhOE3ATeb2V7AeuDSam1ME3Te\ngX04Zd8e/OW1eUxasi7V4TjnXJORjCrch4DuwPHAeCAXqLQxkZm9A1R0Rj8NeNCCCUAnST3Km1jh\nWV5HA0/HQQ8Ap1dpC5owSdx4xgh6Z7Xhu49+zLotO1IdknPONQnJSKB7mdm1wJb4jNCTgTFJWG4v\nYFnC//lxGEBrSZMlTZBUkiS7ABvMbFcZ0/8PSZfHZUwuLCxMQrgNV2brFtx63ijWbdnBD5/y66HO\nOZcMyUigJXfrb5A0HOgIdE3CcivS18zygPOAv8aekKrFzO42szwzy8vJyUl+hA3M8F4d+cUpe/Pm\nJwX8/c0FqQ7HOecavWQk0MwmyO4AACAASURBVLslZQHXAuOA2cAfkrDc5UDvhP9z4zDMrOTvIuBt\nYH9CS+BOkjJKT++CC8f25YxRvbj59Xm8MWd1qsNxzrlGLRmtcP9hZuvNbLyZDTCzrmZ2ZxJiGwdc\nFFvjjgWKzGylpCxJrQAkZQOHALPNzIC3gLPi/BcDzychjiZDEr/7ygiG9+rANY9PZVHh5lSH5Jxz\njZZC3qnFAqRfljXczK6vZL7HgCOBbGA18CugRZz3ztgo6FZCS92twNfNbLKkgwl97xYTfgD81czu\njcscADwOdAY+Bi4ws+2VbUNeXp5Nnjy58o1tIvLXb+XLt75H53Ytee7Kg8ls3SLVITnnGiFJU+Ll\ntGYpGQn0Bwn/tiZ0ojCnKveCNhTNLYECvL9wDRfeO5GjhnTlrgtHk56mVIfknGtkmnsCTUYV7p8T\nXr8llCoH1DoyV6cOHpjNtSfvzetzVnPji3NSHY5zzjU6yegLt7S2hAY8roG75JD+LF6zhX+8u5h+\n2e24YGzfVIfknHONRq0TqKQZxIdpA+mEx5pVeP3TNRzXnjKMT9dt5VfjZpGb1YYjh9T1HUjOOdc0\nJOM2llP4ohP544CeZnZrEpbr6kFGehp/P28Ug7tlctWjHzNn5cZUh+Scc41CMhLopoTXZ0AHSZ1L\nXklYvqtj7VtlcN8lebRvlcHF901k2bqtqQ7JOecavGQk0I+AQmAeMD++nxJfzatpayPWo2MbHrz0\nQLbvKuai+yayZnOld/8451yzlowE+hpwqpllm1kXQpXuq2bW38y8NW4jMrhbJvddksfKos+45J8T\n2bRtZ+UzOedcM5WMBDrWzF4s+cfMXgIOTsJyXQqM7tuZO84fzZyVm7j8wSls27k71SE551yDlIwE\nukLSLyT1i6+fAyuSsFyXIkcN7cqfv7ofExav5ZsPTvYk6pxzZUhGAj2XcOvKc/HVNQ5zjdjp+/fi\npjP25b/z13DlIx+xY1dxqkNyzrkGpdb3gZrZOuBqgPhUlg1W2/4BXYNw9gG92VlczM+fm8lVj37E\nbeePokV6Mn5zOedc41fjs6GkX0oaGt+3kvQmsABYLenYZAXoUuv8MX257tRhvDp7Nd977GMviTrn\nXFSb4sTXgLnx/cVxWV2BI4Df1TIu14Bcckh/rj1lGC/NXMW3H/aGRc45B7VLoDsSqmqPBx4zs91m\nNoe66WPXpdClh/bnhtOH88YnBVz6wCS27tiV6pCccy6lapNAt0saLikHOAp4NWFc29qF5RqiC8b2\n5c9f3Y8PFq7lonsnstHvE3XONWO1SaBXA08DnwA3m9liAEknER5m7ZqgM0fncut5o5i6bAPn3j2B\ngk3bUh2Sc86lRI0TqJl9aGZDzayLmf0mYfiLZlbpbSyS7pNUIGlmOeMl6RZJCyRNlzQqDh8p6QNJ\ns+LwryXMc7+kxZKmxtfImm6fK99JI3pwz8V5LCrcwldue5/5qzelOiTnnKt3qbwn4X7ghArGnwgM\niq/LgTvi8K3ARWa2T5z/r5I6Jcz3IzMbGV9Tkx+2AzhqSFee+NZYtu8q5sw73mfCorWpDsk55+pV\nyhKomb0DrKtgktOABy2YAHSS1MPM5pnZ/LiMFUABoSMHV8/2ze3Ec1ceTE5mKy66dyLPT12e6pCc\nc67eNOS74nsByxL+z4/DPifpQKAlsDBh8G9j1e7NklqVt3BJl0uaLGlyYWFhMuNuVnp3bsuz3z6E\nkX06cfXjU7nj7YV4PxrOueYgKQlU0sGSzpN0UckrGcutZJ09gIeAr5tZyd39PwWGAgcAnYEflze/\nmd1tZnlmlpeT4wXY2ujYtgUPXXogp+7Xk5te/oSf/2smO3d7hwvOuaat1vdrSnoIGAhMBUrusDfg\nwVouejnQO+H/3DgMSR2A/wA/j9W7YaVmK+Pb7ZL+CfywljG4KmqVkc7fvjaS3Kw23PH2QhYWbOb2\n80fRpX25lQDOOdeoJaPDgzxgWB30fzsOuErS48AYoMjMVkpqSei0/kEzezpxhniNdKUkAacDZbbw\ndXUjLU38+IShDO7Wnp88M4Mv3/oed104muG9OqY6NOecS7pkVOHOBLpXdyZJjwEfAEMk5Uu6VNIV\nkq6Ik7wILCL0r3sPcGUcfjZwOHBJGberPCJpBjADyAZuqPFWuRr7yv65PPPtgzEzzrzjfZ77OD/V\nITnnXNKptgVHSW8BI4GJwPaS4Wb25dqFVn/y8vJs8uTJqQ6jyVmzeTvfeeQjPly8jksO7sdPTxpK\nq4z0VIflnEsSSVPMLC/VcaRKMqpwr0vCMlwTlN2+FQ9fNoYbX/yE+95bzJSl67n1vP3p26VdqkNz\nzrlaq3UJtCnwEmjde3XWKn741DTM4Kaz9uWkET1SHZJzrpaaewm01tdAJY2VNEnSZkk7JO2WtDEZ\nwbmm47h9uvPi1YcxsGt7rnzkI67910x/LJpzrlFLRiOiW4FzgflAG+Ay4LYkLNc1MblZbXnyWwfx\nzcP689CEpXzl9veZu8r70XXONU5J6UjBzBYA6fF5oP+k4j5uXTPWMiONn588jPsuyaNw0zZO/fu7\n3P3OQnYX+6UE51zjkowEujXemzlV0h8k/V+SluuasKOHduOVaw7nqKE5/O7FTzj3ngksW7c11WE5\n51yVJSPRXRiXcxWwhdB70JlJWK5r4rq0b8WdF4zmT1/dj9krNnLi3/7LE5M+9b50nXONQlJa4Upq\nA/Qxs7m1D6n+eSvc1Mtfv5UfPDmNDxev45C9uvC7r4zw212ca+C8FW4tSTqV0A/uy/H/kZLG1Xa5\nrnnJzWrLY98cyw2nD2fasiKO/+s73DV+Ibu8U3rnXAOVjCrc64ADgQ0A8SHW/ZOwXNfMpKWJC8b2\n5fXvH8Fhg3K48aVPOO2295i6bEOqQ3POuf+RjAS608yKSg3zi1iuxrp3bM3dF47mjvNHUbBpO6ff\n9h4/fno6azdvr3xm55yrJ8lIoLMknQekSxok6e/A+0lYrmvGJHHiiB68+YMjuPzwATzzUT5H/elt\nHvxgiVfrOucahGQk0O8C+xA6kn8M2Ahck4TlOkdm6xb87KS9efmawxiR25FfPj+LU299j0lL1qU6\nNOdcM+d94eKtcBsLM+Plmav4zQuzWVG0jROHd+dHxw9hQE77VIfmXLPU3Fvh1vhpLJW1tG1MjzNz\njUNJte4RQ3K4a/wi7vnvIl6bvZpzDuzN1ccMJiezVapDdM41IzUugUoqBJYRqm0/BJQ43szG1zq6\neuIl0MapYNM2bnljPo9NXEarjDS+edgAvnn4ANq3SsZT+pxzlWnuJdDaXAPtDvwMGA78DfgSsMbM\nxlc1eUq6T1KBpJnljJekWyQtkDRd0qiEcRdLmh9fFycMHy1pRpznFkkqa9mu8eua2ZobTh/Ba/93\nOEcMzuFvb8znyD++xUMfLGGnNzRyztWxGifQ2HH8y2Z2MTAWWAC8LemqaizmfirueP5EYFB8XQ7c\nASCpM/ArYAzhHtRfScqK89wBfDNhPu/YvokbkNOeOy4YzbNXHsyA7PZc+/wsjv7z2zw+8VN27PJE\n6pyrG7VqhSuplaQzgIeB7wC3AM9VdX4zeweoqDnlacCDFkwAOknqARwPvGZm68xsPfAacEIc18HM\nJliom34QOL1GG+canVF9snjiW2O59+I8stq25CfPzuCoP73NQx8s8WePOueSrjaNiB4kVN++CPza\nzMqshq2lXoTrrCXy47CKhueXMdw1E5I4Zu9uHD20K+PnFXLLG/O59vlZ3PrWAr51+EDOPbAPbVqm\npzpM51wTUJsS6AWEKtKrgfclbYyvTZI2Jie8uiPpckmTJU0uLCxMdTguySRx5JCuPPPtg3nksjH0\n69KO61+YzWF/eJO7xi9ky/ZdqQ7ROdfI1eYaaJqZZcZXh4RXppl1SFJ8ywmPRyuRG4dVNDy3jOFl\nxX+3meWZWV5OTk6SwnUNjSQO2SubJ751EE9cPpah3Ttw40ufcNCNb3DTy5+wqmhbqkN0zjVSDf3B\n1+OAi2Jr3LFAkZmtBF4BjpOUFRsPHQe8EsdtlDQ2tr69CHg+ZdG7BmXMgC48fNkYnr3yYA7ZK5u7\nxi/ksD+8yfefmMrsFQ2+0sQ518Ck9IY5SY8BRwLZkvIJLWtbAJjZnYTrqycRWvhuBb4ex62T9Btg\nUlzU9WZW0hjpSkLr3jbAS/Hl3OdG9cnijgtG8+nardz33mKenLyMZz9eziF7deGyQwdwxOAc0tL8\n7ifnXMW8Kz+8I4XmrmjrTh6d+Cn3v7+Y1Ru3MzCnHReO7csZo3Pp0LpFqsNzrsFq7h0peALFE6gL\nduwq5j8zVnD/+0uZtmwDbVumc9rIXlw4ti/Deibrsr5zTYcnUE+gnkDd/5iev4GHJyzl+akr2L6r\nmLy+WVx4UF9OGN6dVhl+G4xz4AnUEyieQF35NmzdwdNT8nl4wlKWrN1Kl3YtOSsvl7PzejPQnwLj\nmjlPoJ5APYG6ShUXG+8uWMNDE5by5icF7C428vpmcXZeb07at4d3YO+aJU+gnkA9gbpqKdi0jec+\nWs4Tk5exqHALbVumc/KIHpx9QG/y+mbhzy9wzYUnUE+gnkBdjZgZH326nicn5fPC9BVs2bGb/tnt\nOHNUL04b2YvendumOkTn6pQnUE+gnkBdrW3ZvosXZ6zkqcn5TFwSbknO65vFafv34pQRPchq1zLF\nETqXfJ5APYF6AnVJtWzdVsZNW8G/Pl7O/ILNZKSJI4fkcNrIXhyzd1fatvTrpa5p8ATqCdQTqKsT\nZsbslRt5fuoKnp+6nNUbt9O6RRrHDO3Gyfv24KghXf3JMK5R8wTqCdQTqKtzu4uNiYvX8eKMlbw0\ncyVrNu+gbct0jtm7GyeP6MGRQ3Jo3cKTqWtcPIF6AvUE6urVrt3FTFy8jhdmrOTlmatYt2UH7Vqm\n86Vh3ThheHcOH5zj1byuUfAE6gnUE6hLmV27i/lg0Vr+M30lL89axYatO2mVkcZhg3I4fp9uHLt3\nN2+A5BosT6CeQD2BugZh1+5iJi5Zx6uzVvPqrFWsKNpGepo4oF8Wx+/TnWP37ua3xrgGxROoJ1BP\noK7BMTNmLt/IK7NW8ersVcxbvRmAId0yOXrvrhwztCv798ki3R+75lLIE6gnUE+grsFbvGYLb8xZ\nzZufFDBx8Tp2FRtZbVtw1JCuHL13Vw4fnOOPXnP1zhOoJ1BPoK5RKfpsJ/+dX8ibcwp4a24B67fu\nJCNNHNCvM0cOyeGIITkM6ZbpXQq6OucJ1BOoJ1DXaO0uNj7+dD1vfFLAm3MKmLt6EwA9OrbmiME5\nHDE4h0MGZXvp1NUJT6ApTKCSTgD+BqQD/zCz35ca3xe4D8gB1gEXmFm+pKOAmxMmHQqcY2b/knQ/\ncARQFMddYmZTK4rDE6hrKlYWfcb4uYWMn1fIu/PXsGn7LjLSxKi+WRwxOIcjh+QwrEcHL526pPAE\nmqIEKikdmAd8CcgHJgHnmtnshGmeAl4wswckHQ183cwuLLWczsACINfMtsYE+oKZPV3VWDyBuqZo\n5+5iPv50A2/PLWD8vEJmrdgIQE5mq8+T6WF75dCxrZdOXc009wSayru1DwQWmNkiAEmPA6cBsxOm\nGQZ8P75/C/hXGcs5C3jJzLbWYazONTot0tM4sH9nDuzfmf93wlAKNm5j/LxQOn1t9mqenpJPmmD/\nPlkcNiibwwZls29uJ1qkp6U6dOcahVSWQM8CTjCzy+L/FwJjzOyqhGkeBT40s79JOgN4Bsg2s7UJ\n07wJ/MXMXoj/3w8cBGwH3gB+Ymbby1j/5cDlAH369Bm9dOnSutlQ5xqgXbuLmZa/gfFzC3l7XiEz\nlhdhBu1bZTB2QBcOG5TNIXtlMzCnnVf3unI19xJoQ0+gPYFbgf7AO8CZwHAz2xDH9wCmAz3NbGfC\nsFVAS+BuYKGZXV9RLF6F65q7DVt38P7Ctby7YA3vzl/Dp+tChU6Pjq05aGAXxg7owkEDunhHDm4P\nzT2BprIKdznQO+H/3Djsc2a2AjgDQFJ74MyS5BmdDTxXkjzjPCvj2+2S/gn8sA5id65J6dS2JSeN\n6MFJI3oA8Onarby7YA3vLVjD+LmFPPtR+GrmZrXhoAFdPk+qPTu1SWXYzqVUKhPoJGCQpP6ExHkO\ncF7iBJKygXVmVgz8lNAiN9G5cXjiPD3MbKVCvdPpwMw6it+5JqtPl7ac16UP543pg5kxb/VmPli4\nhgmL1vHanNU8NSUfgL5d2u6RULt1aJ3iyJ2rPylLoGa2S9JVwCuE21juM7NZkq4HJpvZOOBI4EZJ\nRqjC/U7J/JL6EUqw40st+hFJOYCAqcAVdbwpzjVpkhjSPZMh3TO55JD+FBcbn6zaxAeL1jJh0Vpe\nnLGSxyctA2BAdjvGDgzVvWMHdCEns1WKo3eu7nhHCvg1UOdqY3exMWflRj5YuJYPFq1l4uJ1bN6+\nC4C9urbnwP6dOaBfFgf060xull9DbUqa+zVQT6B4AnUumXbtLmbWio2fl1CnLFnPpphQe3ZsTV6/\nzhwQk+rgrpmkeYf4jZYnUE+gnkCdq0O7i41PVm1k8pL1TFyyjkmL11GwKdxZ1qF1Rkio/UJCHZHb\nkVYZ6SmO2FVVc0+g/th751ydSk8T+/TsyD49O3Lxwf0wM5at+4xJS9Z9/nrzkwIAWmakMTK3Ewf0\nzyKvX2dG983yfnxdg+UlULwE6lyqrd28nclL1zNp8TomLV3PrOVF7Co2JBjcNZPR/bIY3SeLvH5Z\n9Onc1jt3aCCaewnUEyieQJ1raLbu2MXHn25gytL1TF66no+XfnEdNbt9K0b37cTovlmM7tuZ4b06\neLVvijT3BOpVuM65BqdtywwO2St0JwhQXGzML9jM5KXrmLJ0PVOWrueVWauBUO27b6+OjO6bxai+\nWYzum0V2e799xtU9L4HiJVDnGqPCTduZsnQ9H326nslL1jFz+UZ27C4GQgcP+/fuxMjendi/TxZ7\n9+hAywzvJD/ZmnsJ1BMonkCdawq27dzNzOVFocr30/V8/OmGz1v7tsxIY3jPDuzfJysm1U706tTG\nr6XWkidQT6CeQJ1rgsyMlUXbmLpsw+cJdcbyIrbvCqXU7Pat2L9PSKYje3di39xOtG/lV7Wqo7kn\nUD9anHNNkiR6dmpDz05tPu8kf+fuYj5ZuYmPl61n6qcb+HjZBl6bHa6lpgkGd8tkv9xO7Ne7E/vm\ndmRI90x/Pqorl5dA8RKoc83Z+i07mJq/4fOEOm3ZBoo+Cw94apWRxrCeHWJS7ci+uZ3o36Wd954U\nNfcSqCdQPIE6575gZny6bivT8ouYtmwD0/M3MHP5Rj7buRuAzFYZjMgNyXS/3I7s27sTPTu2bpbX\nU5t7AvUqXOecSyCJvl3a0bdLO768X08g9O+7oHAz05cVMS1/A9Pzi/jHfxexqzgUQLLbtwrJNLcT\n+/buyH65nejcrmUqN8PVA0+gzjlXiYz0NIZ278DQ7h04+4DeQGj1O2flRqbnf5FU35xbQEmlXm5W\nmz2qfof17ODdEjYxnkCdc64GWrdIZ/8+WezfJ+vzYZu27WTG8iKm5xcxPX8DU5dt4D8zVn4+vl+X\ntuzTqyPDe3ZkeK8O7NOzo5dUGzFPoM45lySZrVtw8MBsDh6Y/fmwNZu3MyO/iFkripi5fCPTlm3g\nP9O/SKo9O7beI6kO79WRrpmtmuU11cYmpQlU0gnA34B04B9m9vtS4/sC9wE5wDrgAjPLj+N2AzPi\npJ+a2Zfj8P7A40AXYApwoZntqIfNcc65/5HdvhVHDe3KUUO7fj5sw9YdzF6xkZkxqc5cUcTrc1Z/\nXv2b3b5VSKYJJdXcLO/4oaFJWStcSenAPOBLQD4wCTjXzGYnTPMU8IKZPSDpaODrZnZhHLfZzNqX\nsdwngWfN7HFJdwLTzOyOimLxVrjOuVTbvH0Xc1ZuZObykFRnrShifsFmdseGSh3btGCfnqGEWvI3\n1bfUeCvc1DkQWGBmiwAkPQ6cBsxOmGYY8P34/i3gXxUtUOHn2dHAeXHQA8B1QIUJ1DnnUq19q4z4\nYPHOnw/btnM3c1dt+rykOmtFEfe/t+TzPn/btUxnWM9QQh3eK5RW98ppT4Z3/lAvUplAewHLEv7P\nB8aUmmYacAahmvcrQKakLma2FmgtaTKwC/i9mf2LUG27wcx2JSyzV1krl3Q5cDlAnz59krNFzjmX\nRK1bpLNf79AzUomdu4uZv3ozM1cUMWt5ETNXbOSJScu4//0lQOj8YWj3zD2uqw7ulknrFv7It2Rr\n6I2IfgjcKukS4B1gObA7jutrZsslDQDelDQDKKrqgs3sbuBuCFW4SY3aOefqSIv00DvSsJ4dIC/c\nUrO72Fi8ZktsqBRKq/+etoJHP/wUgIw0MahbJsNj1e/wXh3Yu0cH2rZs6CmgYUvl3lsO9E74PzcO\n+5yZrSCUQJHUHjjTzDbEccvj30WS3gb2B54BOknKiKXQ/1mmc841NelpYq+u7dmra3tOGxkq3cyM\nZes+i9W/RcxasZE3PyngqSn5AEgwILsdt5y7P/v07JjK8ButVCbQScCg2Gp2OXAOX1y7BEBSNrDO\nzIqBnxJa5CIpC9hqZtvjNIcAfzAzk/QWcBahJe7FwPP1tUHOOddQSKJPl7b06dL28870zYzVG7eH\nUmq8rpqT6Q8fr6mUJVAz2yXpKuAVwm0s95nZLEnXA5PNbBxwJHCjJCNU4X4nzr43cJekYiCNcA20\npPHRj4HHJd0AfAzcW28b5ZxzDZgkundsTfeOrTl2WLdUh9PoeWfy+G0szjlXE839NhZv6+ycc87V\ngCdQ55xzrgY8gTrnnHM14AnUOeecqwFPoM4551wNeAJ1zjnnasATqHPOOVcDfh8oIKkQWFrD2bOB\nNUkMJ1k8rurxuKrH46qephpXXzPLSVYwjY0n0FqSNLkh3kjscVWPx1U9Hlf1eFxNk1fhOuecczXg\nCdQ555yrAU+gtXd3qgMoh8dVPR5X9Xhc1eNxNUF+DdQ555yrAS+BOuecczXgCdQ555yrAU+gtSDp\nBElzJS2Q9JM6XldvSW9Jmi1plqSr4/DrJC2XNDW+TkqY56cxtrmSjq+ruCUtkTQjrn9yHNZZ0muS\n5se/WXG4JN0S1z1d0qiE5Vwcp58v6eJaxjQkYZ9MlbRR0jWp2l+S7pNUIGlmwrCk7SNJo+NnsCDO\nq1rE9UdJn8R1PyepUxzeT9JnCfvuzsrWX9421jCupH12kvpL+jAOf0JSy1rE9URCTEskTU3B/irv\n/JDyY6xJMzN/1eAFpAMLgQFAS2AaMKwO19cDGBXfZwLzgGHAdcAPy5h+WIypFdA/xppeF3EDS4Ds\nUsP+APwkvv8JcFN8fxLwEiBgLPBhHN4ZWBT/ZsX3WUn8rFYBfVO1v4DDgVHAzLrYR8DEOK3ivCfW\nIq7jgIz4/qaEuPolTldqOWWuv7xtrGFcSfvsgCeBc+L7O4Fv1zSuUuP/DPwyBfurvPNDyo+xpvzy\nEmjNHQgsMLNFZrYDeBw4ra5WZmYrzeyj+H4TMAfoVcEspwGPm9l2M1sMLIgx11fcpwEPxPcPAKcn\nDH/QgglAJ0k9gOOB18xsnZmtB14DTkhSLMcAC82sot6m6nR/mdk7wLoy1lnrfRTHdTCzCRbOdA8m\nLKvacZnZq2a2K/47AcitaBmVrL+8bax2XBWo1mcXS05HA08nM6643LOBxypaRh3tr/LODyk/xpoy\nT6A11wtYlvB/PhUntKSR1A/YH/gwDroqVsPcl1DlU158dRG3Aa9KmiLp8jism5mtjO9XAd1SEFeJ\nc9jzpJbq/VUiWfuoV3xfFzF+g1DaKNFf0seSxks6LCHe8tZf3jbWVDI+uy7AhoQfCcnaX4cBq81s\nfsKwet9fpc4PjeEYa7Q8gTYyktoDzwDXmNlG4A5gIDASWEmoQqpvh5rZKOBE4DuSDk8cGX+xpuR+\nqXht68vAU3FQQ9hf/yOV+6g8kn4O7AIeiYNWAn3MbH/g+8CjkjpUdXlJ2MYG+dklOJc9f6jV+/4q\n4/xQq+W5inkCrbnlQO+E/3PjsDojqQXhy/GImT0LYGarzWy3mRUD9xCqrSqKL+lxm9ny+LcAeC7G\nsDpW+5RUWRXUd1zRicBHZrY6xpjy/ZUgWftoOXtWs9Y6RkmXAKcA58cTL7GKdG18P4VwfXFwJesv\nbxurLYmf3VpClWVGGfHWSFzWGcATCfHW6/4q6/xQwfJSfow1BZ5Aa24SMCi25mtJqCYcV1cri9dX\n7gXmmNlfEob3SJjsK0BJ68BxwDmSWknqDwwiNAJIatyS2knKLHlPaIAyMy6zpAXfxcDzCXFdFFsB\njgWKYhXTK8BxkrJi1dxxcVht7VEqSPX+KiUp+yiO2yhpbDxOLkpYVrVJOgH4f8CXzWxrwvAcSenx\n/QDCPlpUyfrL28aaxJWUzy7+IHgLOCsZcUXHAp+Y2efVnPW5v8o7P1SwvJQeY01GdVoc+WvPF6El\n2zzCL8uf1/G6DiVUv0wHpsbXScBDwIw4fBzQI2Gen8fY5pLQYi6ZcRNaOE6Lr1klyyNcZ3oDmA+8\nDnSOwwXcFtc9A8hLWNY3CA1AFgBfT8I+a0cobXRMGJaS/UVI4iuBnYTrR5cmcx8BeYSEshC4ldjL\nWA3jWkC4DlZynN0Zpz0zfsZTgY+AUytbf3nbWMO4kvbZxeN2YtzWp4BWNY0rDr8fuKLUtPW5v8o7\nP6T8GGvKL+/KzznnnKsBr8J1zjnnasATqHPOOVcDnkCdc865GvAE6pxzztWAJ1DnnHOuBjyBOpdC\nCk+IaZvqOJxz1ee3sTiXQpKWEO7BW5PqWJxz1eMlUOfqSey16T+SpkmaKelXQE/gLUlvxWmOk/SB\npI8kPRX7Ni155uofFJ7HOFHSXnH4V+Oypkl6J3Vb51zz4wnUufpzArDCzPYzs+HAX4EVwFFmdpSk\nbOAXwLEWOuefTOiEHAoHuQAAAUJJREFUvESRmY0g9ALz1zjsl8DxZrYfodN851w98QTqXP2ZAXxJ\n0k2SDjOzolLjxxIegvyepKmEvkv7Jox/LOHvQfH9e8D9kr5JeIC0c66eZFQ+iXMuGcxsnqRRhD5K\nb5D0RqlJRHiY8bnlLaL0ezO7QtIY4GRgiqTRFp8A4pyrW14Cda6eSOoJbDWzh4E/AqOATUBmnGQC\ncEjC9c12kgYnLOJrCX8/iNMMNLMPzeyXQCF7PorKOVeHvATqXP0ZAfxR0v9v745tEAhiIACuI+Iv\ngr5I6YF+aOETmqAIeiBBH/gqcIBAmsnv0pXvZO0n3eZxTT/F7lX1Wv+glyT3qjqtM7d0m0iSbFX1\nTPJO17Rl3XdOT6+PdCsO8AXWWOAPWHeB3+MJFwAGTKAAMGACBYABAQoAAwIUAAYEKAAMCFAAGDgA\nK9d4Iqh+M10AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Step:0 Loss:1.1768341064453125 \n","Step:2000 Loss:1.0983630418777466 \n","Step:4000 Loss:1.0641971826553345 \n","Step:6000 Loss:1.0483276844024658 \n","Step:8000 Loss:1.0402816534042358 \n","Step:10000 Loss:1.0357235670089722 \n","Step:12000 Loss:1.0327825546264648 \n","Step:14000 Loss:1.0306527614593506 \n","Step:16000 Loss:1.0289491415023804 \n","Step:18000 Loss:1.0274962186813354 \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdgAAAEWCAYAAADFO4ZdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzmXA/wffX5xhH29ORgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Step:0 Loss:1.0120646953582764 \n","Target 0.1 reached at step 1060 !!\n","Step:2000 Loss:0.0060042524710297585 \n","Step:4000 Loss:1.6222811982657959e-09 \n","Step:6000 Loss:2.4356072714226684e-12 \n","Step:8000 Loss:1.7985612998927536e-14 \n","Step:10000 Loss:3.552713678800501e-15 \n","Step:12000 Loss:0.0 \n","Step:14000 Loss:0.0 \n","Step:16000 Loss:0.0 \n","Step:18000 Loss:0.0 \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAcoAAAEWCAYAAADmYNeIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"N851da1slQGQ","colab_type":"text"},"source":["\n","- What can you conclude on the capacity of a neural network ? \n"]},{"cell_type":"markdown","metadata":{"id":"V3mHFJZR3fKO","colab_type":"text"},"source":["## Sequence Labelling with pytorch\n","\n","Now that we have seen how to build a simple neural network, let's build a model for a task more useful in NLP : _Sequence Labelling_ \n","\n","Recall : Sequence labelling is the task of predicting a label to a sequence among a fixed range of possibilities \n","\n","e.g : Sentiment Analysis \n","\n","\n","<img src=\"./imgs/sentiment_analysis.png\">\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ms6k_Gdv3fKQ","colab_type":"text"},"source":["### 1. Define the model\n","Define a neural network that uses an LSTM ([nn.LSTM](https://pytorch.org/docs/stable/nn.html)) to classify the elements of a sequence.\n","\n"," The input sequence will be given to the neural network as a series of indexes. Each index (corresponding to a token in the source vocabulary) will be transformed to a corresponding trainable embedding ([nn.Embedding](https://pytorch.org/docs/stable/nn.html)) before entering the LSTM.   "]},{"cell_type":"code","metadata":{"id":"woz45Oab3fKR","colab_type":"code","colab":{}},"source":["class SequenceLabeller(nn.Module):\n","\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, num_classes, sequence_model=\"LSTM\"):\n","        super(SequenceLabeller, self).__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        if sequence_model == \"LSTM\":\n","            # The LSTM takes word embeddings as inputs, and outputs hidden states\n","            # with dimensionality hidden_dim.\n","            self.seq = nn.LSTM(embedding_dim, hidden_dim,batch_first=True)\n","        else:\n","            raise(Exception(\"Sequence model {} not supported\".format(sequence_model)))\n","\n","        # The linear layer that maps from hidden state space to class space\n","        self.hidden2tag = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, sentence):\n","        embeds = self.word_embeddings(sentence)\n","        seq_output, (h_n,c_n) = self.seq(embeds)\n","        tag_space = self.hidden2tag(seq_output)\n","        # Although we will be performing binary classification, this is a \n","        # general implementation displaying what should be done for n_classes>2\n","        tag_scores = F.log_softmax(tag_space, dim=2) # Computationally efficient for the criterion\n","        return tag_scores"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4VNxs5Vk3fKW","colab_type":"text"},"source":["### 2.1 Prepare the data\n","First, put the three files given [here](https://drive.google.com/drive/folders/19fFgwB0Vk9mfGcA2TNhIeViBHYR4zATX?usp=sharing) in your working folder. Then, choose a data file to perform your sequence labelling and use the given loop to read it.\n","*optional* \n","- inspect the data files\n","- try to guess how the data is being parsed by the loop\n","- inspect the ``re`` package [documentation](https://docs.python.org/3/library/re.html) and see whether you were right."]},{"cell_type":"code","metadata":{"id":"jYSg1-z03fK4","colab_type":"code","colab":{}},"source":["import re\n","import spacy\n","tokenizer = spacy.load(\"en_core_web_sm\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e82CihiY3fK9","colab_type":"code","outputId":"66ff97d1-8c1d-4ac1-9cc7-68c1b7b65e66","executionInfo":{"status":"ok","timestamp":1585564071967,"user_tz":-120,"elapsed":10292,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["\n","def get_data(path):\n","  data = []\n","  no_match = 0\n","  with open(path, \"r\") as f:\n","      for line in f:\n","          match  = re.search(\"(.*)\\s\\s([0-1]+).*\", line)\n","          if match is not None:\n","              tokenized = tokenizer(match.group(1).strip())\n","              sent = [token.text for token in  tokenized]\n","              score = match.group(2)\n","              data.append((sent,int(score)))\n","          else:\n","            match  = re.search(\"(.*),([0-1]+).*\", line)\n","            if match is not None:\n","              tokenized = tokenizer(match.group(1).strip())\n","              sent = [token.text for token in  tokenized]\n","              score = match.group(2)\n","              data.append((sent,int(score)))\n","            else:\n","              no_match += 1\n","  return data, no_match\n","\n","data, no_match = get_data(\"./imdb_labelled.csv\")\n","training_data = data[:int(len(data)*4/5)]\n","test_data = data[int(len(data)*4/5):]\n","print(\"Got {} training examples, {} test examples, and failed to capture \"\n","\"{} examples.\".format(len(training_data), len(test_data), no_match))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Got 800 training examples, 200 test examples, and failed to capture 1 examples.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EYBN9Tam-8s8","colab_type":"code","outputId":"57f12caf-6acb-4e7d-b25a-c6ac234b2afd","executionInfo":{"status":"ok","timestamp":1585573720478,"user_tz":-120,"elapsed":852,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["len(data)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"3OI3bPisL2Mt","colab_type":"text"},"source":["\n","Prepare:\n","- a structure that maps each token in your source vocabulary to a unique index.\n","- a structure that matches each index to it's corresponding token in the source vocabulary\n","- a structure that maps each label to an index\n","- a function that turns a token sequence to the corresponding index sequence\n","\n","The labels in this case are indexes themselves(`0`, `1`) but they can be otherwise (_e.g._ `positive`, `negative`, `amusing`, `anxious` ...)\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"8lB643ke3fKX","colab_type":"code","outputId":"7f8242d8-8478-49f9-ca9b-8ef1c62a1c91","executionInfo":{"status":"ok","timestamp":1585564134912,"user_tz":-120,"elapsed":1001,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["def prepare_sequence(seq, to_ix):\n","    idxs = [to_ix[w] if w in to_ix else len(to_ix) for w in seq]\n","    idxs = torch.tensor(idxs, dtype=torch.long).unsqueeze(0)\n","    return idxs\n","\n","word_to_ix = {}\n","tag_to_ix = {}\n","for sent, tag in training_data:\n","    if tag not in tag_to_ix:\n","        tag_to_ix[tag] = len(tag_to_ix)\n","    for word in sent:\n","        if word not in word_to_ix:\n","            word_to_ix[word] = len(word_to_ix)\n","print(tag_to_ix)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{0: 0, 1: 1}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WAs2u9_QRBzU","colab_type":"text"},"source":["Inspect your data \n","\n","1.   Élément de liste\n","2.   Élément de liste\n","\n"]},{"cell_type":"code","metadata":{"id":"BrxSekQOI9JL","colab_type":"code","outputId":"6d319b2d-0d31-44d6-cec7-1fc86a2fb399","executionInfo":{"status":"ok","timestamp":1585564146821,"user_tz":-120,"elapsed":1102,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["training_data[:6]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(['A',\n","   'very',\n","   ',',\n","   'very',\n","   ',',\n","   'very',\n","   'slow',\n","   '-',\n","   'moving',\n","   ',',\n","   'aimless',\n","   'movie',\n","   'about',\n","   'a',\n","   'distressed',\n","   ',',\n","   'drifting',\n","   'young',\n","   'man',\n","   '.'],\n","  0),\n"," (['Not',\n","   'sure',\n","   'who',\n","   'was',\n","   'more',\n","   'lost',\n","   '-',\n","   'the',\n","   'flat',\n","   'characters',\n","   'or',\n","   'the',\n","   'audience',\n","   ',',\n","   'nearly',\n","   'half',\n","   'of',\n","   'whom',\n","   'walked',\n","   'out',\n","   '.'],\n","  0),\n"," (['Attempting',\n","   'artiness',\n","   'with',\n","   'black',\n","   '&',\n","   'white',\n","   'and',\n","   'clever',\n","   'camera',\n","   'angles',\n","   ',',\n","   'the',\n","   'movie',\n","   'disappointed',\n","   '-',\n","   'became',\n","   'even',\n","   'more',\n","   'ridiculous',\n","   '-',\n","   'as',\n","   'the',\n","   'acting',\n","   'was',\n","   'poor',\n","   'and',\n","   'the',\n","   'plot',\n","   'and',\n","   'lines',\n","   'almost',\n","   'non',\n","   '-',\n","   'existent',\n","   '.'],\n","  0),\n"," (['Very', 'little', 'music', 'or', 'anything', 'to', 'speak', 'of', '.'], 0),\n"," (['The',\n","   'best',\n","   'scene',\n","   'in',\n","   'the',\n","   'movie',\n","   'was',\n","   'when',\n","   'Gerardo',\n","   'is',\n","   'trying',\n","   'to',\n","   'find',\n","   'a',\n","   'song',\n","   'that',\n","   'keeps',\n","   'running',\n","   'through',\n","   'his',\n","   'head',\n","   '.'],\n","  1),\n"," (['The',\n","   'rest',\n","   'of',\n","   'the',\n","   'movie',\n","   'lacks',\n","   'art',\n","   ',',\n","   'charm',\n","   ',',\n","   'meaning',\n","   '...',\n","   'If',\n","   'it',\n","   \"'s\",\n","   'about',\n","   'emptiness',\n","   ',',\n","   'it',\n","   'works',\n","   'I',\n","   'guess',\n","   'because',\n","   'it',\n","   \"'s\",\n","   'empty',\n","   '.'],\n","  0)]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"71smInd83fLD","colab_type":"text"},"source":["### 2.2 Forward pass\n","Instanciate the model and perform a forward pass on the first sentence in your data.  \n","See what the scores are before training.  \n","Note that element i,j of the output is the score for tag j for word i.  \n","Here we don't need to train, so the code is wrapped in `torch.no_grad()`"]},{"cell_type":"code","metadata":{"id":"nubhoMs03fLG","colab_type":"code","outputId":"d49220d6-21ed-41ec-d220-d54deaee436f","executionInfo":{"status":"ok","timestamp":1585564140477,"user_tz":-120,"elapsed":968,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":409}},"source":["# the additional vocabulary element is to account for unkown words\n","model = SequenceLabeller(50, 100, len(word_to_ix)+1, len(tag_to_ix)) \n","inputs = prepare_sequence(training_data[0][0], word_to_ix)\n","with torch.no_grad():\n","    sent_scores = model(torch.cat([inputs]))\n","    print(\"Input tokens {} scores {} \".format(inputs, sent_scores))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Input tokens tensor([[ 0,  1,  2,  1,  2,  1,  3,  4,  5,  2,  6,  7,  8,  9, 10,  2, 11, 12,\n","         13, 14]]) scores tensor([[[-0.7193, -0.6677],\n","         [-0.7390, -0.6493],\n","         [-0.6543, -0.7335],\n","         [-0.7037, -0.6827],\n","         [-0.6344, -0.7556],\n","         [-0.6942, -0.6921],\n","         [-0.7061, -0.6803],\n","         [-0.7275, -0.6599],\n","         [-0.6869, -0.6994],\n","         [-0.6416, -0.7475],\n","         [-0.6449, -0.7438],\n","         [-0.6966, -0.6897],\n","         [-0.7046, -0.6818],\n","         [-0.6964, -0.6899],\n","         [-0.7198, -0.6671],\n","         [-0.6572, -0.7305],\n","         [-0.6988, -0.6875],\n","         [-0.6903, -0.6960],\n","         [-0.7160, -0.6708],\n","         [-0.6540, -0.7339]]]) \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NAdkMtt9zczy","colab_type":"code","outputId":"9e984642-c96c-42a8-b04a-5c481c44e286","executionInfo":{"status":"ok","timestamp":1585577846508,"user_tz":-120,"elapsed":804,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":110}},"source":["model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SequenceLabeller(\n","  (word_embeddings): Embedding(2873, 50)\n","  (seq): LSTM(50, 100, batch_first=True)\n","  (hidden2tag): Linear(in_features=100, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"HmqMaU6E3fLM","colab_type":"text"},"source":["## Training \n","### 3.1  Optimizer and loss\n","Instanciate an optimizer and a loss function for your network from pytorch. "]},{"cell_type":"code","metadata":{"id":"2zti_PnN3fLN","colab_type":"code","colab":{}},"source":["loss_function = nn.NLLLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f5onpmKdYlqv","colab_type":"text"},"source":["\n","Normally, one would use nn.BCELoss for binary classification, but again, we will implement a generic n_class classification loss.\n","\n","You could also use ``nn.CrossEntropyLoss``, but for that, you have to remove the LogSoftmax because it applies it internally."]},{"cell_type":"markdown","metadata":{"id":"m7Ov4bpi3fLQ","colab_type":"text"},"source":["### 3.2 Training loop \n","Write a loop that goes through the data `n_epochs=40` times, and trains on it.  \n","The network should train all the word tags in a sentence to produce the entire sentence's label. This fuzzy kind of supervision is called weak-supervision (weakly-supervised learning). \n","tip: You should transform your target tags with [one_hot](https://pytorch.org/docs/stable/nn.functional.html#one-hot) before giving them to NLLLoss."]},{"cell_type":"code","metadata":{"id":"NDGhwRlU3fLU","colab_type":"code","outputId":"2253f2b4-f699-466f-90e4-46d670a12bcc","executionInfo":{"status":"ok","timestamp":1585564349802,"user_tz":-120,"elapsed":189664,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":764}},"source":["from torch.nn.functional import one_hot\n","n_epochs = 40\n","for epoch in range(n_epochs):  # again, normally you would NOT do 300 epochs, it is toy data\n","    loss_mean_ep = 0\n","    n_sample = 0\n","    for sentence, tags in training_data:\n","        if len(sentence) < 2: continue\n","        # Step 1. Remember that Pytorch accumulates gradients.\n","        # We need to clear them out before each instance\n","        model.zero_grad()\n","        # Step 2. Get our inputs ready for the network, that is, turn them into\n","        # Tensors of word indices.\n","        sentence_in = prepare_sequence(sentence, word_to_ix)\n","        #import pdb\n","        #pdb.set_trace()\n","        targets = prepare_sequence([tags], tag_to_ix)\n","        one_hot_targets = one_hot(targets.squeeze(0), num_classes=len(tag_to_ix))\n","        # Step 3. Run our forward pass.\n","        tag_scores = model(sentence_in)\n","        # Step 4. Compute the loss, gradients, and update the parameters by\n","        #  calling optimizer.step()\n","        #import pdb\n","        #pdb.set_trace()\n","        # print(tag_scores.shape, one_hot_targets.shape)\n","        loss = loss_function(tag_scores, one_hot_targets)\n","        loss_mean_ep += loss\n","        n_sample += 1\n","        loss.backward()\n","        optimizer.step()\n","    print(\"Epoch {} loss {:0.4f} \".format(epoch, loss/n_sample))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 0 loss 0.0009 \n","Epoch 1 loss 0.0009 \n","Epoch 2 loss 0.0009 \n","Epoch 3 loss 0.0009 \n","Epoch 4 loss 0.0009 \n","Epoch 5 loss 0.0009 \n","Epoch 6 loss 0.0008 \n","Epoch 7 loss 0.0008 \n","Epoch 8 loss 0.0008 \n","Epoch 9 loss 0.0008 \n","Epoch 10 loss 0.0008 \n","Epoch 11 loss 0.0008 \n","Epoch 12 loss 0.0008 \n","Epoch 13 loss 0.0008 \n","Epoch 14 loss 0.0008 \n","Epoch 15 loss 0.0007 \n","Epoch 16 loss 0.0007 \n","Epoch 17 loss 0.0007 \n","Epoch 18 loss 0.0007 \n","Epoch 19 loss 0.0007 \n","Epoch 20 loss 0.0006 \n","Epoch 21 loss 0.0006 \n","Epoch 22 loss 0.0006 \n","Epoch 23 loss 0.0006 \n","Epoch 24 loss 0.0006 \n","Epoch 25 loss 0.0005 \n","Epoch 26 loss 0.0005 \n","Epoch 27 loss 0.0005 \n","Epoch 28 loss 0.0005 \n","Epoch 29 loss 0.0004 \n","Epoch 30 loss 0.0004 \n","Epoch 31 loss 0.0004 \n","Epoch 32 loss 0.0004 \n","Epoch 33 loss 0.0004 \n","Epoch 34 loss 0.0004 \n","Epoch 35 loss 0.0003 \n","Epoch 36 loss 0.0003 \n","Epoch 37 loss 0.0003 \n","Epoch 38 loss 0.0003 \n","Epoch 39 loss 0.0003 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r5n1lRuOZj6F","colab_type":"code","outputId":"5488f388-a268-42e4-e144-013bf749e667","executionInfo":{"status":"ok","timestamp":1585571062132,"user_tz":-120,"elapsed":922,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["test_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(['In',\n","   'fact',\n","   ',',\n","   'this',\n","   'stinker',\n","   'smells',\n","   'like',\n","   'a',\n","   'direct',\n","   '-',\n","   'to',\n","   '-',\n","   'video',\n","   'release',\n","   '.'],\n","  0),\n"," (['Avoid', 'at', 'ALL', 'costs', '!'], 0),\n"," (['Star',\n","   'Trek',\n","   'V',\n","   'The',\n","   'final',\n","   'Frontier',\n","   'is',\n","   'the',\n","   'worst',\n","   'in',\n","   'the',\n","   'series',\n","   '.'],\n","  0),\n"," (['The',\n","   'acting',\n","   'from',\n","   'all',\n","   'involved',\n","   'and',\n","   'that',\n","   'includes',\n","   'those',\n","   'like',\n","   'Shatner',\n","   'and',\n","   'Nimoy',\n","   'is',\n","   'bad',\n","   'and',\n","   'washed',\n","   'out',\n","   'and',\n","   'making',\n","   'them',\n","   'seem',\n","   'as',\n","   'old',\n","   'as',\n","   'they',\n","   'look',\n","   'in',\n","   'real',\n","   'life',\n","   ',',\n","   'the',\n","   'special',\n","   'effects',\n","   'are',\n","   'tacky',\n","   'like',\n","   'when',\n","   'Spock',\n","   'has',\n","   'to',\n","   'rescue',\n","   'Kirk',\n","   'on',\n","   'a',\n","   'jet',\n","   'pack',\n","   'when',\n","   'he',\n","   'falls',\n","   'down',\n","   'from',\n","   'a',\n","   'mountain',\n","   '.'],\n","  0),\n"," (['The',\n","   'attempts',\n","   'at',\n","   'humor',\n","   'were',\n","   'pitiful',\n","   'and',\n","   'story',\n","   'is',\n","   'so',\n","   'awful',\n","   'it',\n","   \"dosen't\",\n","   'bear',\n","   'thinking',\n","   'about',\n","   'which',\n","   'basically',\n","   'involves',\n","   'a',\n","   'Vulcan',\n","   'stealing',\n","   'the',\n","   'Enterprise',\n","   'to',\n","   'find',\n","   'god',\n","   '(',\n","   'seriously',\n","   ')',\n","   'I',\n","   'just',\n","   'did',\n","   \"n't\",\n","   'care',\n","   'about',\n","   'any',\n","   'of',\n","   'this',\n","   'film',\n","   'and',\n","   'oh',\n","   'not',\n","   'to',\n","   'mention',\n","   'Uhura',\n","   'does',\n","   'a',\n","   'belly',\n","   'dance',\n","   'to',\n","   'distract',\n","   'male',\n","   'guards',\n","   '.'],\n","  0),\n"," (['The',\n","   'only',\n","   'place',\n","   'good',\n","   'for',\n","   'this',\n","   'film',\n","   'is',\n","   'in',\n","   'the',\n","   'garbage',\n","   '.'],\n","  0),\n"," (['The', 'worst', 'one', 'of', 'the', 'series', '.'], 0),\n"," (['Editing',\n","   ':',\n","   'The',\n","   'editing',\n","   'of',\n","   'this',\n","   'film',\n","   'was',\n","   'phenomenal',\n","   'in',\n","   'my',\n","   'opinion',\n","   '.'],\n","  1),\n"," (['When',\n","   'a',\n","   'song',\n","   'could',\n","   'explain',\n","   'the',\n","   'emotions',\n","   'of',\n","   'the',\n","   'subjects',\n","   'better',\n","   ',',\n","   'such',\n","   'as',\n","   'when',\n","   'Jay',\n","   'Adams',\n","   \"'\",\n","   'unfortunate',\n","   'life',\n","   'was',\n","   'a',\n","   'subject',\n","   'of',\n","   'talk',\n","   ',',\n","   'the',\n","   'song',\n","   'Old',\n","   'Man',\n","   'by',\n","   'Neil',\n","   'Young',\n","   'was',\n","   'played',\n","   ',',\n","   'which',\n","   'evokes',\n","   'many',\n","   'emotions',\n","   '.'],\n","  1),\n"," (['Cinematography',\n","   ':',\n","   'The',\n","   'film',\n","   'was',\n","   'shot',\n","   'in',\n","   'an',\n","   'interesting',\n","   'way',\n","   '.'],\n","  1),\n"," (['Of',\n","   'course',\n","   'the',\n","   'footage',\n","   'from',\n","   'the',\n","   '70s',\n","   'was',\n","   'grainy',\n","   ',',\n","   'but',\n","   'that',\n","   'only',\n","   'enhanced',\n","   'the',\n","   'film',\n","   '.'],\n","  1),\n"," (['This', 'film', 'offers', 'many', 'delights', 'and', 'surprises', '.'], 1),\n"," (['When',\n","   'Achille',\n","   'and',\n","   'Philippa',\n","   'beautifully',\n","   'sing',\n","   'a',\n","   'duet',\n","   'from',\n","   '\"',\n","   '\"',\n","   'Don',\n","   'Giovanni',\n","   '\"',\n","   '\"',\n","   'that',\n","   'perfectly',\n","   'describes',\n","   'their',\n","   'situation',\n","   'in',\n","   'the',\n","   'movie',\n","   ',',\n","   'you',\n","   'appreciate',\n","   'the',\n","   'subtle',\n","   'layers',\n","   'of',\n","   'this',\n","   'excellent',\n","   'film',\n","   '.'],\n","  1),\n"," (['The',\n","   'story',\n","   'unfolds',\n","   'in',\n","   '18th',\n","   'century',\n","   'Jutland',\n","   'and',\n","   'the',\n","   'use',\n","   'of',\n","   'period',\n","   'music',\n","   'played',\n","   'on',\n","   'period',\n","   'instruments',\n","   'is',\n","   'just',\n","   'one',\n","   'more',\n","   'fine',\n","   'touch',\n","   '.'],\n","  1),\n"," (['You',\n","   'share',\n","   'General',\n","   'Loewenhielm',\n","   \"'s\",\n","   'exquisite',\n","   'joy',\n","   'in',\n","   'his',\n","   'partaking',\n","   'of',\n","   'the',\n","   'Cailles',\n","   'en',\n","   'Sarcophage',\n","   'even',\n","   'though',\n","   'you',\n","   'are',\n","   'just',\n","   'watching',\n","   'a',\n","   'movie',\n","   '-',\n","   'but',\n","   'you',\n","   'do',\n","   'wish',\n","   'for',\n","   'just',\n","   'a',\n","   'small',\n","   'sample',\n","   'to',\n","   'savor',\n","   '.'],\n","  1),\n"," (['But',\n","   'this',\n","   'understated',\n","   'film',\n","   'leaves',\n","   'a',\n","   'lasting',\n","   'impression',\n","   '.'],\n","  1),\n"," (['The',\n","   'warmth',\n","   'it',\n","   'generates',\n","   'is',\n","   'in',\n","   'contrast',\n","   'to',\n","   'its',\n","   'austere',\n","   'backdrop',\n","   '.'],\n","  1),\n"," (['You',\n","   'will',\n","   'leave',\n","   'the',\n","   'theater',\n","   'wanting',\n","   'to',\n","   'go',\n","   'out',\n","   'and',\n","   'dance',\n","   'under',\n","   'the',\n","   'stars',\n","   '.'],\n","  1),\n"," (['The',\n","   'acting',\n","   ',',\n","   'as',\n","   'you',\n","   \"'d\",\n","   'expect',\n","   'from',\n","   'this',\n","   'cast',\n","   ',',\n","   'is',\n","   'top',\n","   'notch',\n","   '.'],\n","  1),\n"," (['The',\n","   'characters',\n","   'are',\n","   'fleshed',\n","   'out',\n","   'surprisingly',\n","   'well',\n","   ',',\n","   'particularly',\n","   'Grimes',\n","   'and',\n","   'Blake',\n","   ',',\n","   'and',\n","   'all',\n","   'the',\n","   'actors',\n","   'deliver',\n","   'their',\n","   'sharply',\n","   'scripted',\n","   'lines',\n","   'with',\n","   'just',\n","   'the',\n","   'right',\n","   'amount',\n","   'of',\n","   'deadpan',\n","   'tongue',\n","   'in',\n","   'cheek',\n","   'to',\n","   'make',\n","   'the',\n","   'dialogue',\n","   'both',\n","   'hilarious',\n","   'and',\n","   'realistic',\n","   '.'],\n","  1),\n"," (['Angus',\n","   'Scrimm',\n","   'also',\n","   'turns',\n","   'in',\n","   'a',\n","   'good',\n","   'performance',\n","   'in',\n","   'a',\n","   'somewhat',\n","   'brief',\n","   'but',\n","   'memorable',\n","   'role',\n","   'as',\n","   'the',\n","   'gently',\n","   'menacing',\n","   ',',\n","   'violin',\n","   '-',\n","   'playing',\n","   'anatomist',\n","   'Doctor',\n","   'Quinn',\n","   '.'],\n","  1),\n"," (['Conclusion', '-', 'I', 'loved', 'it', '.'], 1),\n"," (['It',\n","   \"'s\",\n","   'a',\n","   'long',\n","   'time',\n","   'since',\n","   'I',\n","   'was',\n","   'so',\n","   'entertained',\n","   'by',\n","   'a',\n","   'movie',\n","   '.'],\n","  1),\n"," (['I',\n","   'struggle',\n","   'to',\n","   'find',\n","   'anything',\n","   'bad',\n","   'to',\n","   'say',\n","   'about',\n","   'it',\n","   '.'],\n","  1),\n"," (['Mark',\n","   'my',\n","   'words',\n","   ',',\n","   'this',\n","   'is',\n","   'one',\n","   'of',\n","   'those',\n","   'cult',\n","   'films',\n","   'like',\n","   'Evil',\n","   'Dead',\n","   '2',\n","   'or',\n","   'Phantasm',\n","   'that',\n","   'people',\n","   'will',\n","   'still',\n","   'be',\n","   'discovering',\n","   'and',\n","   'falling',\n","   'in',\n","   'love',\n","   'with',\n","   '20',\n","   ',',\n","   '30',\n","   ',',\n","   '40',\n","   'years',\n","   'down',\n","   'the',\n","   'line',\n","   '.'],\n","  1),\n"," (['It',\n","   \"'s\",\n","   'pretty',\n","   'surprising',\n","   'that',\n","   'this',\n","   'wonderful',\n","   'film',\n","   'was',\n","   'made',\n","   'in',\n","   '1949',\n","   ',',\n","   'as',\n","   'Hollywood',\n","   'generally',\n","   'had',\n","   'its',\n","   'collective',\n","   'heads',\n","   'in',\n","   'the',\n","   'sand',\n","   'concerning',\n","   'black',\n","   'and',\n","   'white',\n","   'issues',\n","   'at',\n","   'that',\n","   'time',\n","   '.'],\n","  1),\n"," (['The',\n","   'film',\n","   'deserves',\n","   'strong',\n","   'kudos',\n","   'for',\n","   'taking',\n","   'this',\n","   'stand',\n","   ',',\n","   'for',\n","   'having',\n","   'exceptional',\n","   'acting',\n","   'from',\n","   'its',\n","   'mostly',\n","   'lesser',\n","   '-',\n","   'known',\n","   'cast',\n","   'and',\n","   'for',\n","   'the',\n","   'super',\n","   '-',\n","   'intelligent',\n","   'script',\n","   'that',\n","   'does',\n","   \"n't\",\n","   'insult',\n","   'the',\n","   'audience',\n","   'or',\n","   'take',\n","   'the',\n","   'easy',\n","   'way',\n","   'out',\n","   'when',\n","   'it',\n","   'comes',\n","   'to',\n","   'white',\n","   'racism',\n","   '.'],\n","  1),\n"," (['Plus',\n","   ',',\n","   'with',\n","   'the',\n","   'movie',\n","   \"'s\",\n","   'rather',\n","   'modest',\n","   'budget',\n","   'and',\n","   'fast',\n","   'running',\n","   'time',\n","   ',',\n","   'it',\n","   'does',\n","   'an',\n","   'amazing',\n","   'job',\n","   '!'],\n","  1),\n"," (['Juano',\n","   'Hernandez',\n","   '(',\n","   'an',\n","   'exceptional',\n","   'actor',\n","   'who',\n","   'played',\n","   'supporting',\n","   'roles',\n","   'in',\n","   'many',\n","   'films',\n","   'of',\n","   'the',\n","   'era',\n","   ')',\n","   'is',\n","   'a',\n","   'proud',\n","   'black',\n","   'man',\n","   'who',\n","   'is',\n","   'accused',\n","   'of',\n","   'murdering',\n","   'a',\n","   'white',\n","   'man',\n","   'in',\n","   'the',\n","   'South',\n","   '.'],\n","  1),\n"," (['Trumbull', 'on', 'I', 'LOVE', 'LUCY', ')', '.'], 1),\n"," (['See',\n","   'it',\n","   'with',\n","   'your',\n","   'kids',\n","   'if',\n","   'you',\n","   'have',\n","   'a',\n","   'chance',\n","   '--',\n","   'it',\n","   'will',\n","   'open',\n","   'up',\n","   'some',\n","   'amazing',\n","   'dialog',\n","   'about',\n","   'how',\n","   'far',\n","   'race',\n","   'relations',\n","   'have',\n","   'come',\n","   'in',\n","   'the',\n","   'last',\n","   '50',\n","   'years',\n","   '.'],\n","  1),\n"," (['See', 'both', 'films', 'if', 'you', 'can', '.'], 1),\n"," (['It',\n","   'was',\n","   'that',\n","   'year',\n","   ',',\n","   'however',\n","   ',',\n","   'that',\n","   'reminded',\n","   'us',\n","   'that',\n","   'Huston',\n","   'was',\n","   'still',\n","   'at',\n","   'the',\n","   'top',\n","   'of',\n","   'his',\n","   'game',\n","   'as',\n","   'evinced',\n","   'by',\n","   'his',\n","   'faithful',\n","   'adaptation',\n","   'of',\n","   'James',\n","   'Joyce',\n","   \"'s\",\n","   'acclaimed',\n","   'novella',\n","   '\"',\n","   '\"',\n","   'The',\n","   'Dead',\n","   '.'],\n","  1),\n"," (['Feelings',\n","   ',',\n","   'thoughts',\n","   '...',\n","   'Gabriel',\n","   \"'s\",\n","   'discomfort',\n","   'during',\n","   'the',\n","   'dance',\n","   '...',\n","   'all',\n","   'these',\n","   'intangibles',\n","   'leap',\n","   'to',\n","   'life',\n","   'and',\n","   'come',\n","   'within',\n","   'the',\n","   'viewer',\n","   \"'s\",\n","   'grasp',\n","   'in',\n","   'Huston',\n","   \"'s\",\n","   'portrayal',\n","   '.'],\n","  1),\n"," (['Very',\n","   'disappointed',\n","   'and',\n","   'wondered',\n","   'how',\n","   'it',\n","   'could',\n","   'be',\n","   'in',\n","   'the',\n","   'Oscar',\n","   'shortlist',\n","   '.'],\n","  0),\n"," (['It', \"'s\", 'very', 'slow', '.'], 0),\n"," (['Lot',\n","   'of',\n","   'holes',\n","   'in',\n","   'the',\n","   'plot',\n","   ':',\n","   'there',\n","   \"'s\",\n","   'nothing',\n","   'about',\n","   'how',\n","   'he',\n","   'became',\n","   'the',\n","   'emperor',\n","   ';',\n","   'nothing',\n","   'about',\n","   'where',\n","   'he',\n","   'spend',\n","   '20',\n","   'years',\n","   'between',\n","   'his',\n","   'childhood',\n","   'and',\n","   'mature',\n","   'age',\n","   '.'],\n","  0),\n"," ([')', 'Do', \"n't\", 'waste', 'your', 'time', '.'], 0),\n"," (['End',\n","   'of',\n","   'Days',\n","   'is',\n","   'one',\n","   'of',\n","   'the',\n","   'worst',\n","   'big',\n","   '-',\n","   'budget',\n","   'action',\n","   'movies',\n","   'I',\n","   \"'ve\",\n","   'ever',\n","   'seen',\n","   '.'],\n","  0),\n"," (['He',\n","   'surely',\n","   'does',\n","   \"n't\",\n","   'know',\n","   'how',\n","   'to',\n","   'make',\n","   'a',\n","   'coherent',\n","   'action',\n","   'movie',\n","   'from',\n","   'the',\n","   'screenwriter',\n","   'of',\n","   'Air',\n","   'Force',\n","   'One',\n","   'who',\n","   'was',\n","   'only',\n","   'obliged',\n","   'to',\n","   'write',\n","   'the',\n","   'script',\n","   'just',\n","   'for',\n","   'a',\n","   'big',\n","   'sum',\n","   'of',\n","   'money',\n","   '.'],\n","  0),\n"," (['This',\n","   'was',\n","   'one',\n","   'of',\n","   'the',\n","   'worst',\n","   'films',\n","   'i',\n","   'have',\n","   'ever',\n","   'seen',\n","   '.'],\n","  0),\n"," (['I',\n","   \"'m\",\n","   'still',\n","   'trying',\n","   'to',\n","   'get',\n","   'over',\n","   'how',\n","   'bad',\n","   'it',\n","   'was',\n","   '.'],\n","  0),\n"," (['This',\n","   'movie',\n","   'is',\n","   'possibly',\n","   'one',\n","   'of',\n","   'the',\n","   'most',\n","   'creative',\n","   'works',\n","   'of',\n","   'horror',\n","   'ever',\n","   '.'],\n","  1),\n"," (['It',\n","   'has',\n","   'everything',\n","   'you',\n","   'could',\n","   'want',\n","   '...',\n","   'suspense',\n","   ',',\n","   'drama',\n","   ',',\n","   'comedy',\n","   ',',\n","   'confusing',\n","   'subplots',\n","   ',',\n","   'native',\n","   'americans',\n","   ',',\n","   'brain',\n","   'eating',\n","   '...',\n","   'If',\n","   'you',\n","   \"'re\",\n","   'looking',\n","   'for',\n","   'the',\n","   'be',\n","   '-',\n","   'all',\n","   ',',\n","   'end',\n","   '-',\n","   'all',\n","   'of',\n","   'brainsucking',\n","   'movies',\n","   ',',\n","   'look',\n","   'no',\n","   'further',\n","   '.'],\n","  1),\n"," (['\"',\n","   '\"',\n","   'With',\n","   'great',\n","   'sound',\n","   'effects',\n","   ',',\n","   'and',\n","   'impressive',\n","   'special',\n","   'effects',\n","   ',',\n","   'I',\n","   'ca',\n","   \"n't\",\n","   'recommend',\n","   'this',\n","   'movie',\n","   'enough',\n","   '.'],\n","  1),\n"," (['Call',\n","   'me',\n","   'a',\n","   'nut',\n","   ',',\n","   'but',\n","   'I',\n","   'think',\n","   'this',\n","   'is',\n","   'one',\n","   'of',\n","   'the',\n","   'best',\n","   'movies',\n","   'ever',\n","   '.'],\n","  1),\n"," (['Great',\n","   'character',\n","   'actors',\n","   'Telly',\n","   'Savalas',\n","   'and',\n","   'Peter',\n","   'Boyle',\n","   '.'],\n","  1),\n"," (['1',\n","   'hour',\n","   '54',\n","   'minutes',\n","   'of',\n","   'sheer',\n","   'tedium',\n","   ',',\n","   'melodrama',\n","   'and',\n","   'horrible',\n","   'acting',\n","   ',',\n","   'a',\n","   'mess',\n","   'of',\n","   'a',\n","   'script',\n","   ',',\n","   'and',\n","   'a',\n","   'sinking',\n","   'feeling',\n","   'of',\n","   'GOOD',\n","   'LORD',\n","   ',',\n","   'WHAT',\n","   'WERE',\n","   'THEY',\n","   'THINKING',\n","   '?'],\n","  0),\n"," (['Lots', 'of', 'holes', 'in', 'the', 'script', '.'], 0),\n"," (['It', \"'s\", 'like', 'a', 'bad', 'two', 'hour', 'TV', 'movie', '.'], 0),\n"," (['Now',\n","   'imagine',\n","   'that',\n","   'every',\n","   'single',\n","   'one',\n","   'of',\n","   'those',\n","   'decisions',\n","   'was',\n","   'made',\n","   'wrong',\n","   '.'],\n","  0),\n"," (['The', 'dialogue', 'is', 'atrocious', '.'], 0),\n"," (['The', 'acting', 'is', 'beyond', 'abysmal', '.'], 0),\n"," (['Everything', 'stinks', '.'], 0),\n"," (['Trouble',\n","   'is',\n","   ',',\n","   'the',\n","   'writing',\n","   'and',\n","   'directing',\n","   'make',\n","   'it',\n","   'impossible',\n","   'to',\n","   'establish',\n","   'those',\n","   'things',\n","   'that',\n","   'make',\n","   'a',\n","   'movie',\n","   'watchable',\n","   ',',\n","   'like',\n","   'character',\n","   ',',\n","   'story',\n","   ',',\n","   'theme',\n","   'and',\n","   'so',\n","   'on',\n","   '.'],\n","  0),\n"," (['Worse',\n","   ',',\n","   'there',\n","   \"'s\",\n","   'an',\n","   'incredibly',\n","   'weak',\n","   'sub',\n","   '-',\n","   'plot',\n","   'thrown',\n","   'in',\n","   'that',\n","   'follows',\n","   'a',\n","   'little',\n","   'band',\n","   'of',\n","   'latter',\n","   '-',\n","   'day',\n","   'Mansonites',\n","   'as',\n","   'they',\n","   'go',\n","   'after',\n","   'a',\n","   'reporter',\n","   'who',\n","   \"'s\",\n","   'working',\n","   'on',\n","   'a',\n","   'story',\n","   'on',\n","   'the',\n","   'anniversary',\n","   'of',\n","   'the',\n","   'killings',\n","   '.'],\n","  0),\n"," (['It',\n","   \"'s\",\n","   'dumb',\n","   'and',\n","   'pointless',\n","   ',',\n","   'and',\n","   'a',\n","   'complete',\n","   'waste',\n","   'of',\n","   'time',\n","   '.'],\n","  0),\n"," (['In', 'short', ',', 'do', \"n't\", 'bother', 'with', 'this', 'movie', '.'],\n","  0),\n"," (['I',\n","   'wo',\n","   \"n't\",\n","   'spoil',\n","   'it',\n","   ',',\n","   'but',\n","   'the',\n","   'ending',\n","   'in',\n","   'pretty',\n","   'amazing',\n","   '.'],\n","  1),\n"," (['The',\n","   'best',\n","   'scene',\n","   'in',\n","   'the',\n","   'movie',\n","   'is',\n","   'at',\n","   'the',\n","   'end',\n","   ',',\n","   'but',\n","   'I',\n","   'wo',\n","   \"n't\",\n","   'spoil',\n","   'it',\n","   '.'],\n","  1),\n"," (['If',\n","   'there',\n","   'was',\n","   'ever',\n","   'an',\n","   'indication',\n","   'of',\n","   'a',\n","   'writer',\n","   'and',\n","   'a',\n","   'director',\n","   \"'s\",\n","   'ability',\n","   'to',\n","   'meld',\n","   'two',\n","   'highly',\n","   'volatile',\n","   'temperaments',\n","   'into',\n","   'a',\n","   'seamless',\n","   'union',\n","   'of',\n","   'creativity',\n","   ',',\n","   'then',\n","   'this',\n","   'is',\n","   'it',\n","   '!'],\n","  1),\n"," (['The',\n","   'result',\n","   'is',\n","   'a',\n","   'powerhouse',\n","   'achievement',\n","   ',',\n","   'made',\n","   'more',\n","   'timely',\n","   'now',\n","   'perhaps',\n","   'because',\n","   'of',\n","   'our',\n","   'culture',\n","   \"'s\",\n","   'disturbing',\n","   'fascination',\n","   'with',\n","   'celebrity',\n","   ',',\n","   'and',\n","   'it',\n","   \"'s\",\n","   'distorted',\n","   'interpretations',\n","   'of',\n","   'fame',\n","   '.'],\n","  1),\n"," (['A', 'film', 'not', 'easily', 'forgotten', '.'], 1),\n"," (['But',\n","   ',',\n","   'Kevin',\n","   'Spacey',\n","   'is',\n","   'an',\n","   'excellent',\n","   ',',\n","   'verbal',\n","   'tsunami',\n","   'as',\n","   'Buddy',\n","   'Ackerman',\n","   '\\x96',\n","   'and',\n","   'totally',\n","   'believable',\n","   'because',\n","   'he',\n","   'is',\n","   'a',\n","   'great',\n","   'actor',\n","   '.'],\n","  1),\n"," (['The',\n","   'scripting',\n","   'of',\n","   'the',\n","   'subtle',\n","   'comedy',\n","   'is',\n","   'unmatched',\n","   'by',\n","   'any',\n","   'movie',\n","   'in',\n","   'recent',\n","   'years',\n","   '.'],\n","  1),\n"," (['The',\n","   'characters',\n","   'are',\n","   'interesting',\n","   ',',\n","   'even',\n","   'if',\n","   'a',\n","   'bit',\n","   'predictable',\n","   '.'],\n","  1),\n"," (['Highly',\n","   'recommended',\n","   'for',\n","   'all',\n","   'ages',\n","   ',',\n","   'although',\n","   'the',\n","   'younger',\n","   'set',\n","   'will',\n","   'probably',\n","   'not',\n","   'appreciate',\n","   'some',\n","   'of',\n","   'the',\n","   'more',\n","   'subtle',\n","   'references',\n","   ',',\n","   'they',\n","   'will',\n","   'certainly',\n","   'appreciate',\n","   'one',\n","   'galley',\n","   'scene',\n","   'in',\n","   'particular',\n","   '!'],\n","  1),\n"," (['Great', 'movie', '!'], 1),\n"," (['Also', 'the', 'story', 'and', 'acting', 'were', 'weak', '.'], 0),\n"," (['At',\n","   'around',\n","   '4',\n","   'pm',\n","   'I',\n","   'bought',\n","   'it',\n","   ',',\n","   'at',\n","   'around',\n","   '8',\n","   'pm',\n","   'I',\n","   'started',\n","   'to',\n","   'watch',\n","   ',',\n","   'at',\n","   'around',\n","   '8.15pm',\n","   'I',\n","   'fast',\n","   'forwarded',\n","   'the',\n","   'remaining',\n","   'film',\n","   'to',\n","   'see',\n","   'if',\n","   'there',\n","   'was',\n","   'anything',\n","   'left',\n","   'watchable',\n","   'for',\n","   'a',\n","   'human',\n","   'being',\n","   'with',\n","   'a',\n","   'brain',\n","   '...',\n","   'but',\n","   'there',\n","   'was',\n","   \"n't\",\n","   '.'],\n","  0),\n"," (['Either', 'way', ',', 'it', 'sucks', '.'], 0),\n"," (['The', 'script', 'is', 'horrendously', 'stupid', '.'], 0),\n"," (['The',\n","   'story',\n","   'starts',\n","   'too',\n","   'fast',\n","   'with',\n","   'absolutely',\n","   'no',\n","   'suspense',\n","   'or',\n","   'build',\n","   '-',\n","   'up',\n","   'in',\n","   'the',\n","   'slightest',\n","   '.'],\n","  0),\n"," (['Everything',\n","   'Captain',\n","   'Howdy',\n","   'says',\n","   'is',\n","   'either',\n","   'laughable',\n","   'or',\n","   'just',\n","   'plain',\n","   'stupid',\n","   '.'],\n","  0),\n"," (['What', 'the', 'hell', 'kind', 'of', 'crap', 'is', 'that', '?', '!'], 0),\n"," (['Then', ',', 'there', \"'s\", 'the', 'plot', 'holes', '.'], 0),\n"," (['You',\n","   'could',\n","   'drive',\n","   'a',\n","   'semi',\n","   'truck',\n","   'into',\n","   'these',\n","   'holes',\n","   '!'],\n","  0),\n"," (['Linda',\n","   'Cardellini',\n","   'is',\n","   'the',\n","   'only',\n","   'thing',\n","   'good',\n","   'in',\n","   'this',\n","   'film',\n","   '.'],\n","  1),\n"," (['She', \"'s\", 'poised', 'and', 'amazing', '.'], 1),\n"," (['Dee', 'Snider', 'just', 'plain', 'sucks', '.'], 0),\n"," (['He',\n","   'ca',\n","   \"n't\",\n","   'act',\n","   '(',\n","   'one',\n","   'of',\n","   'the',\n","   'least',\n","   'scary',\n","   'villains',\n","   'I',\n","   'have',\n","   'ever',\n","   'seen',\n","   ')',\n","   ',',\n","   'he',\n","   'ca',\n","   \"n't\",\n","   'write',\n","   '(',\n","   'did',\n","   'he',\n","   'write',\n","   'this',\n","   'damn',\n","   'movie',\n","   'in',\n","   'his',\n","   'sleep',\n","   '?'],\n","  0),\n"," (['I', 'was', 'bored', 'throughout', 'the', 'whole', 'damn', 'thing', '.'],\n","  0),\n"," (['The',\n","   'acting',\n","   'sucks',\n","   ',',\n","   'the',\n","   'music',\n","   'sucks',\n","   ',',\n","   'the',\n","   'script',\n","   'sucks',\n","   ',',\n","   'the',\n","   'pacing',\n","   'sucks',\n","   ',',\n","   'the',\n","   'special',\n","   'FX',\n","   'suck',\n","   ',',\n","   'the',\n","   'directing',\n","   'sucks',\n","   '...',\n","   'basically',\n","   ',',\n","   'this',\n","   'movie',\n","   'sucks',\n","   '.'],\n","  0),\n"," (['This',\n","   'film',\n","   'tries',\n","   'to',\n","   'be',\n","   'a',\n","   'serious',\n","   'and',\n","   'sophisticated',\n","   'thriller',\n","   '/',\n","   'horror',\n","   'flick',\n","   'and',\n","   'it',\n","   'fails',\n","   'miserably',\n","   '.'],\n","  0),\n"," (['This',\n","   'is',\n","   'probably',\n","   'one',\n","   'of',\n","   'the',\n","   'least',\n","   'effective',\n","   'and',\n","   'utterly',\n","   'unoriginal',\n","   'films',\n","   'I',\n","   'have',\n","   'ever',\n","   'seen',\n","   'in',\n","   'my',\n","   'entire',\n","   'life',\n","   '.'],\n","  0),\n"," (['A',\n","   'piece',\n","   'of',\n","   'cinematic',\n","   'garbage',\n","   'captured',\n","   'on',\n","   'celluloid',\n","   '.'],\n","  0),\n"," (['Avoid', 'at', 'any', 'and', 'all', 'costs', '.'], 0),\n"," (['At',\n","   'any',\n","   'rate',\n","   'this',\n","   'film',\n","   'stinks',\n","   ',',\n","   'its',\n","   'not',\n","   'funny',\n","   ',',\n","   'and',\n","   'Fulci',\n","   'should',\n","   'have',\n","   'stayed',\n","   'with',\n","   'giallo',\n","   'and',\n","   'supernatural',\n","   'zombie',\n","   'movies',\n","   '.'],\n","  0),\n"," (['Avoid', 'this', 'film', 'at', 'all', 'costs', '.'], 0),\n"," (['I',\n","   'do',\n","   \"n't\",\n","   'know',\n","   'what',\n","   'happened',\n","   'in',\n","   'Season',\n","   'Five',\n","   ',',\n","   'what',\n","   'a',\n","   'mess',\n","   '.'],\n","  0),\n"," (['The',\n","   'only',\n","   'consistent',\n","   'thread',\n","   'holding',\n","   'the',\n","   'series',\n","   'together',\n","   'were',\n","   'the',\n","   'amazing',\n","   'performances',\n","   'of',\n","   'Leni',\n","   'Parker',\n","   'and',\n","   'Anita',\n","   'LaSelva',\n","   'as',\n","   'the',\n","   'two',\n","   'Taelons',\n","   'in',\n","   'quiet',\n","   'idealogical',\n","   'conflict',\n","   '.'],\n","  0),\n"," (['Now', 'this', 'is', 'a', 'movie', 'I', 'really', 'dislike', '.'], 0),\n"," (['It',\n","   \"'s\",\n","   'one',\n","   'of',\n","   'the',\n","   'most',\n","   'boring',\n","   'Horror',\n","   'movies',\n","   'from',\n","   'the',\n","   '90',\n","   \"'s\",\n","   'mainly',\n","   'because',\n","   'it',\n","   'starts',\n","   'slow',\n","   'and',\n","   'centers',\n","   'in',\n","   'a',\n","   'boring',\n","   'atmosphere',\n","   '.'],\n","  0),\n"," (['The',\n","   'puppets',\n","   'look',\n","   'really',\n","   'cheesy',\n","   ',',\n","   'not',\n","   'in',\n","   'a',\n","   'good',\n","   'way',\n","   'like',\n","   'in',\n","   'the',\n","   'Puppet',\n","   'Master',\n","   '80',\n","   \"'s\",\n","   'flicks',\n","   '.'],\n","  0),\n"," (['The',\n","   'story',\n","   'is',\n","   'lame',\n","   ',',\n","   'not',\n","   'interesting',\n","   'and',\n","   'NEVER',\n","   'really',\n","   'explains',\n","   'the',\n","   'sinister',\n","   'origins',\n","   'of',\n","   'the',\n","   'puppets',\n","   '.'],\n","  0),\n"," (['There',\n","   'are',\n","   \"n't\",\n","   'death',\n","   'scenes',\n","   'like',\n","   'in',\n","   'previous',\n","   'movies',\n","   'and',\n","   'the',\n","   'f',\n","   '/',\n","   'x',\n","   'are',\n","   'terrible',\n","   '.'],\n","  0),\n"," (['I',\n","   'felt',\n","   'asleep',\n","   'the',\n","   'first',\n","   'time',\n","   'I',\n","   'watched',\n","   'it',\n","   ',',\n","   'so',\n","   'I',\n","   'can',\n","   'recommend',\n","   'it',\n","   'for',\n","   'insomniacs',\n","   '.'],\n","  0),\n"," (['The',\n","   'fact',\n","   'is',\n","   ',',\n","   'this',\n","   'film',\n","   'is',\n","   'a',\n","   'wonderful',\n","   ',',\n","   'heartwarming',\n","   'tale',\n","   'about',\n","   'two',\n","   'people',\n","   'chasing',\n","   'their',\n","   'dreams',\n","   '.'],\n","  1),\n"," (['The',\n","   'best',\n","   'part',\n","   'about',\n","   '\"',\n","   '\"',\n","   'Nurse',\n","   'Betty',\n","   '\"',\n","   '\"',\n","   'is',\n","   'it',\n","   \"'s\",\n","   'unpredictability',\n","   '.'],\n","  1),\n"," (['Director',\n","   'Neil',\n","   'LaBute',\n","   'uses',\n","   'brutal',\n","   'violence',\n","   'to',\n","   'seperate',\n","   'dreams',\n","   'from',\n","   'reality',\n","   ',',\n","   'and',\n","   'along',\n","   'with',\n","   'the',\n","   'touching',\n","   'drama',\n","   ',',\n","   'and',\n","   'hilarious',\n","   'comedy',\n","   ',',\n","   'you',\n","   'can',\n","   'never',\n","   'tell',\n","   'what',\n","   'is',\n","   'going',\n","   'to',\n","   'happen',\n","   'next',\n","   '.'],\n","  1),\n"," (['Otherwise',\n","   ',',\n","   'do',\n","   \"n't\",\n","   'even',\n","   'waste',\n","   'your',\n","   'time',\n","   'on',\n","   'this',\n","   '.'],\n","  0),\n"," (['This',\n","   'one',\n","   'just',\n","   'fails',\n","   'to',\n","   'create',\n","   'any',\n","   'real',\n","   'suspense',\n","   '.'],\n","  0),\n"," (['As',\n","   'for',\n","   'the',\n","   'killer',\n","   ',',\n","   'do',\n","   \"n't\",\n","   'expect',\n","   'anything',\n","   'original',\n","   'or',\n","   'even',\n","   'remotely',\n","   'frightening',\n","   '.'],\n","  0),\n"," (['There',\n","   'is',\n","   ',',\n","   'however',\n","   ',',\n","   'some',\n","   'pretty',\n","   'good',\n","   'acting',\n","   '(',\n","   'at',\n","   'least',\n","   ',',\n","   'for',\n","   'this',\n","   'type',\n","   'of',\n","   'film',\n","   ')',\n","   '.'],\n","  1),\n"," (['I',\n","   \"'m\",\n","   'so',\n","   'sorry',\n","   'but',\n","   'I',\n","   'really',\n","   'ca',\n","   \"n't\",\n","   'recommend',\n","   'it',\n","   'to',\n","   'anyone',\n","   '.'],\n","  0),\n"," (['One',\n","   'of',\n","   'the',\n","   'most',\n","   'boring',\n","   ',',\n","   'pointless',\n","   'movies',\n","   'I',\n","   'have',\n","   'ever',\n","   'seen',\n","   '.'],\n","  0),\n"," (['The',\n","   'secondary',\n","   'plot',\n","   'line',\n","   'is',\n","   'incomprehensible',\n","   'and',\n","   'its',\n","   'relation',\n","   'to',\n","   'the',\n","   'primary',\n","   'plot',\n","   'line',\n","   'is',\n","   'mystifying',\n","   '.'],\n","  0),\n"," (['Hated', 'it', '.'], 0),\n"," (['This',\n","   'is',\n","   'one',\n","   'of',\n","   'the',\n","   'worst',\n","   'Sandra',\n","   'Bullock',\n","   'movie',\n","   'since',\n","   'Speed',\n","   '2',\n","   'But',\n","   'not',\n","   'quite',\n","   'that',\n","   'bad',\n","   '.'],\n","  0),\n"," (['I',\n","   'do',\n","   \"n't\",\n","   'understand',\n","   'how',\n","   'this',\n","   'garbage',\n","   'got',\n","   'on',\n","   'the',\n","   'shelves',\n","   'of',\n","   'the',\n","   'movie',\n","   'store',\n","   ',',\n","   'it',\n","   \"'s\",\n","   'not',\n","   'even',\n","   'a',\n","   'real',\n","   'movie',\n","   '!'],\n","  0),\n"," (['I',\n","   'highly',\n","   'doubt',\n","   'that',\n","   'anyone',\n","   'could',\n","   'ever',\n","   'like',\n","   'this',\n","   'trash',\n","   '.'],\n","  0),\n"," (['This', 'is', 'not', 'movie', '-', 'making', '.'], 0),\n"," (['The',\n","   'acting',\n","   'is',\n","   'like',\n","   'watching',\n","   'wooden',\n","   'puppets',\n","   'moving',\n","   'around',\n","   'and',\n","   'reading',\n","   'from',\n","   'a',\n","   'book',\n","   ',',\n","   'that',\n","   \"'s\",\n","   'how',\n","   'bad',\n","   'it',\n","   'is',\n","   '.'],\n","  0),\n"," (['So',\n","   'I',\n","   'am',\n","   'here',\n","   'to',\n","   'warn',\n","   'you',\n","   '--',\n","   'DO',\n","   'NOT',\n","   'RENT',\n","   'THIS',\n","   'MOVIE',\n","   ',',\n","   'it',\n","   'is',\n","   'the',\n","   'dumbest',\n","   'thing',\n","   'you',\n","   'have',\n","   'never',\n","   'seen',\n","   '!'],\n","  0),\n"," (['I',\n","   'saw',\n","   'this',\n","   'short',\n","   'film',\n","   'on',\n","   'HBO',\n","   'the',\n","   'other',\n","   'day',\n","   'and',\n","   'absolutely',\n","   'loved',\n","   'it',\n","   '.'],\n","  1),\n"," (['I',\n","   'did',\n","   \"n't\",\n","   'realize',\n","   'how',\n","   'wonderful',\n","   'the',\n","   'short',\n","   'really',\n","   'is',\n","   'until',\n","   'the',\n","   'last',\n","   'two',\n","   'scenes',\n","   '.'],\n","  1),\n"," (['Excellent', 'short', 'film', '.'], 1),\n"," (['Hopefully',\n","   ',',\n","   'the',\n","   'director',\n","   'James',\n","   'Cox',\n","   'can',\n","   'turn',\n","   'the',\n","   'short',\n","   'into',\n","   'a',\n","   'feature',\n","   'length',\n","   'film',\n","   'with',\n","   'the',\n","   'same',\n","   'cast',\n","   ',',\n","   'or',\n","   'win',\n","   'us',\n","   'over',\n","   'with',\n","   'a',\n","   'whole',\n","   'new',\n","   'film',\n","   '.'],\n","  1),\n"," (['I',\n","   'agree',\n","   'with',\n","   'Jessica',\n","   ',',\n","   'this',\n","   'movie',\n","   'is',\n","   'pretty',\n","   'bad',\n","   '.'],\n","  0),\n"," (['Characters',\n","   'are',\n","   'one',\n","   '-',\n","   'dimensional',\n","   ',',\n","   'even',\n","   'the',\n","   'good',\n","   'guys',\n","   'and',\n","   'especially',\n","   'the',\n","   'bad',\n","   'guys',\n","   '.'],\n","  0),\n"," (['The', 'story', 'line', 'is', 'totally', 'predictable', '.'], 0),\n"," (['Not',\n","   'much',\n","   'dialogue',\n","   ',',\n","   'not',\n","   'much',\n","   'music',\n","   ',',\n","   'the',\n","   'whole',\n","   'film',\n","   'was',\n","   'shot',\n","   'as',\n","   'elaborately',\n","   'and',\n","   'aesthetically',\n","   'like',\n","   'a',\n","   'sculpture',\n","   '.'],\n","  1),\n"," (['I',\n","   \"'ve\",\n","   'seen',\n","   'soap',\n","   'operas',\n","   'more',\n","   'intelligent',\n","   'than',\n","   'this',\n","   'movie',\n","   '.'],\n","  0),\n"," (['Bad', 'characters', ',', 'bad', 'story', 'and', 'bad', 'acting', '.'], 0),\n"," (['Really', 'awful', '.'], 0),\n"," (['Not', 'easy', 'to', 'watch', '.'], 0),\n"," (['Funny',\n","   ',',\n","   'clever',\n","   ',',\n","   'hip',\n","   '-',\n","   'just',\n","   'like',\n","   'Pray',\n","   \"'s\",\n","   'previous',\n","   'film',\n","   ',',\n","   'Hype',\n","   '!'],\n","  1),\n"," (['It',\n","   'was',\n","   'a',\n","   'long',\n","   'time',\n","   'that',\n","   'i',\n","   'did',\n","   \"n't\",\n","   'see',\n","   'a',\n","   'so',\n","   'charismatic',\n","   'actor',\n","   'on',\n","   'screen',\n","   '.'],\n","  1),\n"," (['Paolo',\n","   'Sorrentino',\n","   'has',\n","   'written',\n","   'a',\n","   'wonderful',\n","   'story',\n","   'about',\n","   'loneliness',\n","   'and',\n","   'Tony',\n","   'has',\n","   'built',\n","   'one',\n","   'of',\n","   'the',\n","   'most',\n","   'unforgettable',\n","   'characters',\n","   'seen',\n","   'in',\n","   'movies',\n","   'in',\n","   'recent',\n","   'years',\n","   '.'],\n","  1),\n"," (['The',\n","   'movie',\n","   'is',\n","   'not',\n","   'completely',\n","   'perfect',\n","   'but',\n","   \"'\",\n","   'Titta',\n","   'Di',\n","   'Girolamo',\n","   \"'\",\n","   'will',\n","   'stay',\n","   'with',\n","   'you',\n","   'for',\n","   'a',\n","   'long',\n","   'time',\n","   'after',\n","   'the',\n","   'vision',\n","   'of',\n","   'the',\n","   'movie',\n","   '.'],\n","  1),\n"," (['I', 'rate', 'this', 'movie', '9/10', '.'], 1),\n"," (['I',\n","   'do',\n","   'not',\n","   'know',\n","   'if',\n","   'this',\n","   'was',\n","   'Emilio',\n","   'Estevez',\n","   \"'s\",\n","   'directorial',\n","   'debut',\n","   ',',\n","   'but',\n","   'the',\n","   'pacing',\n","   ',',\n","   'the',\n","   'interplay',\n","   'and',\n","   'development',\n","   'of',\n","   'the',\n","   'characters',\n","   'as',\n","   'well',\n","   'as',\n","   'some',\n","   'clever',\n","   'camera',\n","   'work',\n","   'surrounding',\n","   'the',\n","   'character',\n","   'Estevez',\n","   'plays',\n","   'all',\n","   'suggest',\n","   'a',\n","   'natural',\n","   'eye',\n","   '.'],\n","  1),\n"," (['The',\n","   'interplay',\n","   'between',\n","   'Martin',\n","   'and',\n","   'Emilio',\n","   'contains',\n","   'the',\n","   'same',\n","   'wonderful',\n","   'chemistry',\n","   'we',\n","   'saw',\n","   'in',\n","   'Wall',\n","   'Street',\n","   'with',\n","   'Martin',\n","   'and',\n","   'Charlie',\n","   '.'],\n","  1),\n"," (['Kathy',\n","   'Bates',\n","   'is',\n","   'wonderful',\n","   'in',\n","   'her',\n","   'characters',\n","   'subtle',\n","   'desperation',\n","   'and',\n","   'escapism',\n","   ';',\n","   'a',\n","   'variation',\n","   'on',\n","   'her',\n","   'character',\n","   'in',\n","   '\"',\n","   '\"',\n","   'At',\n","   'Play',\n","   'In',\n","   'The',\n","   'Fields',\n","   'Of',\n","   'The',\n","   'Lord',\n","   '\"',\n","   '\"',\n","   '.'],\n","  1),\n"," (['For',\n","   'readers',\n","   'who',\n","   'have',\n","   'already',\n","   'seen',\n","   'one',\n","   'of',\n","   'Miyazaki',\n","   \"'s\",\n","   'films',\n","   ':',\n","   'he',\n","   'is',\n","   'still',\n","   'in',\n","   'top',\n","   'form',\n","   'and',\n","   'made',\n","   'another',\n","   'worthwhile',\n","   'experience',\n","   '.'],\n","  1),\n"," (['It',\n","   'never',\n","   'condescends',\n","   ',',\n","   'all',\n","   'the',\n","   'characters',\n","   'have',\n","   'good',\n","   'genuine',\n","   'hearts',\n","   'and',\n","   'believable',\n","   'problems',\n","   '.'],\n","  1),\n"," (['The',\n","   'two',\n","   'main',\n","   'characters',\n","   'may',\n","   'be',\n","   'two',\n","   'of',\n","   'the',\n","   'most',\n","   'believable',\n","   'children',\n","   'I',\n","   'ever',\n","   'saw',\n","   'put',\n","   'on',\n","   'screen',\n","   '.'],\n","  1),\n"," (['They',\n","   'are',\n","   'so',\n","   'easy',\n","   'to',\n","   'love',\n","   ',',\n","   'but',\n","   'even',\n","   'more',\n","   'easy',\n","   'to',\n","   'identify',\n","   'with',\n","   '.'],\n","  1),\n"," (['This',\n","   'movie',\n","   'is',\n","   'great',\n","   '--',\n","   'especially',\n","   'if',\n","   'you',\n","   'enjoy',\n","   'visual',\n","   'arts',\n","   '.'],\n","  1),\n"," (['The',\n","   'scenery',\n","   'that',\n","   'the',\n","   'two',\n","   'daughters',\n","   'paint',\n","   'and',\n","   'photograph',\n","   'are',\n","   'beautiful',\n","   '.'],\n","  1),\n"," (['The',\n","   'story',\n","   'is',\n","   'also',\n","   'both',\n","   'funny',\n","   'and',\n","   'poignant',\n","   'at',\n","   'times',\n","   '.'],\n","  1),\n"," (['People',\n","   'who',\n","   'like',\n","   'European',\n","   'films',\n","   'and',\n","   '\"',\n","   '\"',\n","   'art',\n","   'movies',\n","   '\"',\n","   '\"',\n","   'will',\n","   'like',\n","   'this',\n","   'movie',\n","   '.'],\n","  1),\n"," (['This',\n","   'is',\n","   'truly',\n","   'an',\n","   'art',\n","   'movie',\n","   '--',\n","   'it',\n","   'actually',\n","   'has',\n","   'a',\n","   'lot',\n","   'of',\n","   'art',\n","   'in',\n","   'it',\n","   '.'],\n","  1),\n"," (['Go', 'rent', 'it', '.'], 1),\n"," (['However',\n","   ',',\n","   'after',\n","   'finally',\n","   'watching',\n","   'this',\n","   'film',\n","   ',',\n","   'I',\n","   'realized',\n","   'that',\n","   'not',\n","   'only',\n","   'had',\n","   'I',\n","   'had',\n","   'a',\n","   'closed',\n","   'mind',\n","   'to',\n","   'the',\n","   'brilliance',\n","   'it',\n","   'depicts',\n","   ',',\n","   'I',\n","   'also',\n","   'found',\n","   'myself',\n","   'watching',\n","   'it',\n","   'over',\n","   'and',\n","   'over',\n","   'again',\n","   '.'],\n","  1),\n"," (['It',\n","   \"'s\",\n","   'the',\n","   'one',\n","   'movie',\n","   'that',\n","   'never',\n","   'ceases',\n","   'to',\n","   'interest',\n","   'me',\n","   ',',\n","   'simply',\n","   'because',\n","   'it',\n","   'keeps',\n","   'me',\n","   'alert',\n","   ',',\n","   'as',\n","   'I',\n","   'try',\n","   'to',\n","   'attempt',\n","   'to',\n","   'decipher',\n","   'it',\n","   \"'s\",\n","   'meanings',\n","   '.'],\n","  1),\n"," (['Brilliance', 'indeed', '.'], 1),\n"," (['But',\n","   'if',\n","   'you',\n","   'liked',\n","   'movies',\n","   'like',\n","   'The',\n","   'Matrix',\n","   '(',\n","   'and',\n","   'better',\n","   'yet',\n","   ',',\n","   'their',\n","   'sequels',\n","   ')',\n","   'I',\n","   'think',\n","   'you',\n","   \"'ll\",\n","   'appreciate',\n","   'the',\n","   'thought',\n","   'provoking',\n","   ',',\n","   'mindblowing',\n","   'experience',\n","   'this',\n","   'film',\n","   'will',\n","   'give',\n","   'you',\n","   '.'],\n","  1),\n"," (['Think', 'of', 'the', 'film', 'being', 'like', 'a', 'dream', '.'], 1),\n"," (['Simply', 'beautiful', '.'], 1),\n"," (['Both',\n","   'Rickman',\n","   'and',\n","   'Stowe',\n","   'play',\n","   'their',\n","   'roles',\n","   'to',\n","   'the',\n","   'hilt',\n","   'in',\n","   'this',\n","   'tale',\n","   'of',\n","   'a',\n","   'childrens',\n","   \"'\",\n","   'book',\n","   'writer',\n","   'who--',\n","   'maybe?--',\n","   'has',\n","   'written',\n","   'a',\n","   'subversive',\n","   'tract',\n","   '.'],\n","  1),\n"," (['It',\n","   \"'s\",\n","   'a',\n","   'gloriously',\n","   'fun',\n","   ',',\n","   'fast',\n","   'paced',\n","   'and',\n","   'fairly',\n","   'accurate',\n","   'portrayal',\n","   'of',\n","   'the',\n","   'night',\n","   'of',\n","   'a',\n","   'raver',\n","   '.'],\n","  1),\n"," (['It',\n","   'presents',\n","   'a',\n","   'idyllic',\n","   'yet',\n","   'serious',\n","   'portrayal',\n","   'of',\n","   'the',\n","   'ups',\n","   'and',\n","   'downs',\n","   'of',\n","   'the',\n","   'characters',\n","   'lives',\n","   '.'],\n","  1),\n"," (['Just',\n","   'whatever',\n","   'you',\n","   'do',\n","   ',',\n","   'avoid',\n","   '\"',\n","   '\"',\n","   'Groove',\n","   '\"',\n","   '\"',\n","   'as',\n","   'its',\n","   'the',\n","   'antithesis',\n","   'of',\n","   'all',\n","   'that',\n","   'is',\n","   'good',\n","   'about',\n","   'Human',\n","   'Traffic',\n","   '.'],\n","  0),\n"," (['It',\n","   \"'s\",\n","   'too',\n","   'bad',\n","   'that',\n","   'everyone',\n","   'else',\n","   'involved',\n","   'did',\n","   \"n't\",\n","   'share',\n","   'Crowe',\n","   \"'s\",\n","   'level',\n","   'of',\n","   'dedication',\n","   'to',\n","   'quality',\n","   ',',\n","   'for',\n","   'if',\n","   'they',\n","   'did',\n","   ',',\n","   'we',\n","   \"'d\",\n","   'have',\n","   'a',\n","   'far',\n","   'better',\n","   'film',\n","   'on',\n","   'our',\n","   'hands',\n","   'than',\n","   'this',\n","   'sub',\n","   '-',\n","   'par',\n","   'mess',\n","   '.'],\n","  0),\n"," (['The', 'movie', 'seemed', 'a', 'little', 'slow', 'at', 'first', '.'], 0),\n"," (['But',\n","   'it',\n","   'picked',\n","   'up',\n","   'speed',\n","   'and',\n","   'got',\n","   'right',\n","   'to',\n","   'the',\n","   'point',\n","   '.'],\n","  1),\n"," (['It',\n","   'showed',\n","   'exactly',\n","   'how',\n","   'the',\n","   'government',\n","   'and',\n","   'the',\n","   'scientist',\n","   'argued',\n","   'for',\n","   'humanity',\n","   'and',\n","   'the',\n","   'reasons',\n","   'of',\n","   'the',\n","   '\"',\n","   '\"',\n","   'gadget',\n","   '\"',\n","   '\"',\n","   '.'],\n","  1),\n"," (['I', 'enjoyed', 'it', '.'], 1),\n"," (['I', 'have', 'recommended', 'it', 'to', 'friends', '.'], 1),\n"," (['I',\n","   'was',\n","   'particularly',\n","   'pleased',\n","   'with',\n","   'the',\n","   'acting',\n","   'ability',\n","   'of',\n","   'Dwight',\n","   'Schultz',\n","   '.'],\n","  1),\n"," (['Both',\n","   'actors',\n","   'truly',\n","   'understand',\n","   'and',\n","   'become',\n","   'their',\n","   'particular',\n","   'character',\n","   ',',\n","   'delivering',\n","   'a',\n","   'convincing',\n","   ',',\n","   'sincere',\n","   'performance',\n","   '.'],\n","  1),\n"," (['Their',\n","   'on',\n","   '-',\n","   'screen',\n","   'chemistry',\n","   ',',\n","   'critical',\n","   'to',\n","   'the',\n","   'entire',\n","   'film',\n","   ',',\n","   'is',\n","   'genuine',\n","   '.'],\n","  1),\n"," (['The',\n","   'film',\n","   \"'s\",\n","   'dialogue',\n","   'is',\n","   'natural',\n","   ',',\n","   'real',\n","   'to',\n","   'life',\n","   '.'],\n","  1),\n"," (['The',\n","   'writer',\n","   ',',\n","   'Gorman',\n","   'Bechard',\n","   ',',\n","   'undoubtedly',\n","   'did',\n","   'his',\n","   'homework',\n","   'because',\n","   'all',\n","   'references',\n","   'are',\n","   'industry',\n","   'and',\n","   'character',\n","   '-',\n","   'age',\n","   'appropriate',\n","   '.'],\n","  1),\n"," (['The',\n","   'incredible',\n","   'soundtrack',\n","   'truly',\n","   'captures',\n","   'the',\n","   'essence',\n","   'of',\n","   'the',\n","   'film',\n","   '.'],\n","  1),\n"," (['Each',\n","   'track',\n","   'commands',\n","   'sentiment',\n","   ',',\n","   'actually',\n","   'contributing',\n","   'to',\n","   'the',\n","   'scenes',\n","   'and',\n","   'characters',\n","   '.'],\n","  1),\n"," (['Definitely',\n","   'worth',\n","   'seeing',\n","   '\\x85 ',\n","   'it',\n","   \"'s\",\n","   'the',\n","   'sort',\n","   'of',\n","   'thought',\n","   'provoking',\n","   'film',\n","   'that',\n","   'forces',\n","   'you',\n","   'to',\n","   'question',\n","   'your',\n","   'own',\n","   'threshold',\n","   'of',\n","   'loneliness',\n","   '.'],\n","  1),\n"," (['Hayao',\n","   'Miyazaki',\n","   \"'s\",\n","   'latest',\n","   'and',\n","   'eighth',\n","   'film',\n","   'for',\n","   'Studio',\n","   'Ghibili',\n","   ',',\n","   '\"',\n","   '\"',\n","   'Gake',\n","   'No',\n","   'Ue',\n","   'No',\n","   'Ponyo',\n","   '\"',\n","   '\"',\n","   '(',\n","   'Ponyo',\n","   'on',\n","   'the',\n","   'Cliff',\n","   'by',\n","   'the',\n","   'Sea',\n","   ')',\n","   'is',\n","   'a',\n","   'wonderfully',\n","   'fun',\n","   'and',\n","   'imaginative',\n","   'look',\n","   'at',\n","   'childhood',\n","   '.'],\n","  1),\n"," (['At',\n","   'a',\n","   'time',\n","   'when',\n","   'it',\n","   'seems',\n","   'that',\n","   'film',\n","   'animation',\n","   'has',\n","   'been',\n","   'dominated',\n","   'by',\n","   'Disney',\n","   '/',\n","   'Pixar',\n","   \"'s\",\n","   'CGI',\n","   'masterpieces',\n","   ',',\n","   'it',\n","   'is',\n","   'both',\n","   'refreshing',\n","   'and',\n","   'comforting',\n","   'to',\n","   'know',\n","   'that',\n","   'Miyazaki',\n","   'is',\n","   'still',\n","   'relying',\n","   'on',\n","   'traditional',\n","   'hand',\n","   '-',\n","   'drawn',\n","   'animation',\n","   'to',\n","   'tell',\n","   'his',\n","   'charming',\n","   'and',\n","   'enchanting',\n","   'stories',\n","   '.'],\n","  1),\n"," (['Enough',\n","   'can',\n","   'not',\n","   'be',\n","   'said',\n","   'of',\n","   'the',\n","   'remarkable',\n","   'animation',\n","   'in',\n","   'this',\n","   'film',\n","   '.'],\n","  1),\n"," (['The',\n","   'art',\n","   'style',\n","   'has',\n","   'the',\n","   'appearance',\n","   'of',\n","   'crayon',\n","   '/',\n","   'pencil',\n","   'drawings',\n","   'and',\n","   'is',\n","   'wonderfully',\n","   'colorful',\n","   'and',\n","   'fanciful',\n","   '.'],\n","  1),\n"," (['If',\n","   'you',\n","   'act',\n","   'in',\n","   'such',\n","   'a',\n","   'film',\n","   ',',\n","   'you',\n","   'should',\n","   'be',\n","   'glad',\n","   'that',\n","   'you',\n","   \"'re\",\n","   'gon',\n","   'na',\n","   'drift',\n","   'away',\n","   'from',\n","   'earth',\n","   'as',\n","   'far',\n","   'as',\n","   'possible',\n","   '!'],\n","  0),\n"," (['This',\n","   'one',\n","   'wants',\n","   'to',\n","   'surf',\n","   'on',\n","   'the',\n","   'small',\n","   'wave',\n","   'of',\n","   'space',\n","   'movies',\n","   'in',\n","   '1998',\n","   '(',\n","   'Deep',\n","   'Impact',\n","   'and',\n","   'Armageddon',\n","   ')',\n","   ',',\n","   'and',\n","   'this',\n","   'one',\n","   'fails',\n","   'everywhere',\n","   '.'],\n","  0),\n"," (['If',\n","   'you',\n","   'have',\n","   \"n't\",\n","   'choked',\n","   'in',\n","   'your',\n","   'own',\n","   'vomit',\n","   'by',\n","   'the',\n","   'end',\n","   '(',\n","   'by',\n","   'all',\n","   'the',\n","   'cheap',\n","   'drama',\n","   'and',\n","   'worthless',\n","   'dialogue',\n","   ')',\n","   'you',\n","   \"'ve\",\n","   'must',\n","   'have',\n","   'bored',\n","   'yourself',\n","   'to',\n","   'death',\n","   'with',\n","   'this',\n","   'waste',\n","   'of',\n","   'time',\n","   '.'],\n","  0),\n"," (['Still',\n","   ',',\n","   'it',\n","   'makes',\n","   'up',\n","   'for',\n","   'all',\n","   'of',\n","   'this',\n","   'with',\n","   'a',\n","   'super',\n","   'ending',\n","   'that',\n","   'depicts',\n","   'a',\n","   'great',\n","   'sea',\n","   'vessel',\n","   'being',\n","   'taken',\n","   'out',\n","   'by',\n","   'the',\n","   'mighty',\n","   'frost',\n","   '.'],\n","  1),\n"," (['Just',\n","   'consider',\n","   'the',\n","   'excellent',\n","   'story',\n","   ',',\n","   'solid',\n","   'acting',\n","   'and',\n","   'look',\n","   'of',\n","   'the',\n","   'film',\n","   'as',\n","   'added',\n","   'bonuses',\n","   '.'],\n","  1),\n"," (['Instead',\n","   ',',\n","   'we',\n","   'got',\n","   'a',\n","   'bore',\n","   'fest',\n","   'about',\n","   'a',\n","   'whiny',\n","   ',',\n","   'spoiled',\n","   'brat',\n","   'babysitting',\n","   '.'],\n","  0),\n"," (['Then',\n","   'I',\n","   'watched',\n","   'it',\n","   'again',\n","   'two',\n","   'Sundays',\n","   'ago',\n","   '(',\n","   'March',\n","   '20th',\n","   ',',\n","   '2005',\n","   ')',\n","   'and',\n","   'I',\n","   'began',\n","   'to',\n","   'really',\n","   'enjoy',\n","   'it',\n","   'and',\n","   'this',\n","   'time',\n","   'I',\n","   'taped',\n","   'the',\n","   'entire',\n","   'thing',\n","   '.'],\n","  1),\n"," (['It',\n","   'is',\n","   'a',\n","   'very',\n","   'well',\n","   'acted',\n","   'and',\n","   'done',\n","   'TV',\n","   'Movie',\n","   '.'],\n","  1),\n"," (['Judith',\n","   'Light',\n","   'is',\n","   'one',\n","   'of',\n","   'my',\n","   'favorite',\n","   'actresses',\n","   'and',\n","   'I',\n","   'think',\n","   'she',\n","   'does',\n","   'a',\n","   'superb',\n","   'job',\n","   'in',\n","   'this',\n","   'film',\n","   '!'],\n","  1),\n"," (['I', 'keep', 'watching', 'it', 'over', 'and', 'over', '.'], 1),\n"," (['It', \"'s\", 'a', 'sad', 'movie', ',', 'but', 'very', 'good', '.'], 1),\n"," (['If',\n","   'you',\n","   'have',\n","   'not',\n","   'seen',\n","   'this',\n","   'movie',\n","   ',',\n","   'I',\n","   'definitely',\n","   'recommend',\n","   'it',\n","   '!'],\n","  1),\n"," (['She', 'is', 'as', 'lovely', 'as', 'usual', ',', 'this', 'cutie', '!'], 1),\n"," (['Still',\n","   'it',\n","   \"'s\",\n","   'quite',\n","   'interesting',\n","   'and',\n","   'entertaining',\n","   'to',\n","   'follow',\n","   '.'],\n","  1),\n"," ([';)', 'Recommend', 'with', 'confidence', '!'], 1),\n"," (['This',\n","   'movie',\n","   'is',\n","   'well',\n","   '-',\n","   'balanced',\n","   'with',\n","   'comedy',\n","   'and',\n","   'drama',\n","   'and',\n","   'I',\n","   'thoroughly',\n","   'enjoyed',\n","   'myself',\n","   '.'],\n","  1),\n"," (['It',\n","   'was',\n","   'a',\n","   'riot',\n","   'to',\n","   'see',\n","   'Hugo',\n","   'Weaving',\n","   'play',\n","   'a',\n","   'sex',\n","   '-',\n","   'obsessed',\n","   'gay',\n","   'real',\n","   'estate',\n","   'salesman',\n","   'who',\n","   'uses',\n","   'his',\n","   'clients',\n","   \"'\",\n","   'houses',\n","   'for',\n","   'his',\n","   'trysts',\n","   'with',\n","   'the',\n","   'flaming',\n","   'Darren',\n","   '(',\n","   'Tom',\n","   'Hollander',\n","   ')',\n","   '.'],\n","  1),\n"," ([':)',\n","   'Anyway',\n","   ',',\n","   'the',\n","   'plot',\n","   'flowed',\n","   'smoothly',\n","   'and',\n","   'the',\n","   'male',\n","   '-',\n","   'bonding',\n","   'scenes',\n","   'were',\n","   'a',\n","   'hoot',\n","   '.'],\n","  1),\n"," (['The',\n","   'opening',\n","   'sequence',\n","   'of',\n","   'this',\n","   'gem',\n","   'is',\n","   'a',\n","   'classic',\n","   ',',\n","   'and',\n","   'the',\n","   'cat',\n","   'n',\n","   'mouse',\n","   'games',\n","   'that',\n","   'follow',\n","   'are',\n","   'a',\n","   'delight',\n","   'to',\n","   'watch',\n","   '.'],\n","  1),\n"," (['Fans', 'of', 'the', 'genre', 'will', 'be', 'in', 'heaven', '.'], 1),\n"," (['Lange', 'had', 'become', 'a', 'great', 'actress', '.'], 1),\n"," (['It', 'looked', 'like', 'a', 'wonderful', 'story', '.'], 1),\n"," (['I', 'never', 'walked', 'out', 'of', 'a', 'movie', 'faster', '.'], 0),\n"," (['I',\n","   'just',\n","   'got',\n","   'bored',\n","   'watching',\n","   'Jessice',\n","   'Lange',\n","   'take',\n","   'her',\n","   'clothes',\n","   'off',\n","   '!'],\n","  0),\n"," (['Unfortunately',\n","   ',',\n","   'any',\n","   'virtue',\n","   'in',\n","   'this',\n","   'film',\n","   \"'s\",\n","   'production',\n","   'work',\n","   'was',\n","   'lost',\n","   'on',\n","   'a',\n","   'regrettable',\n","   'script',\n","   '.'],\n","  0),\n"," (['In', 'a', 'word', ',', 'it', 'is', 'embarrassing', '.'], 0),\n"," (['Exceptionally', 'bad', '!'], 0),\n"," (['All',\n","   'in',\n","   'all',\n","   'its',\n","   'an',\n","   'insult',\n","   'to',\n","   'one',\n","   \"'s\",\n","   'intelligence',\n","   'and',\n","   'a',\n","   'huge',\n","   'waste',\n","   'of',\n","   'money',\n","   '.'],\n","  0)]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"0yns6Whi3fLa","colab_type":"text"},"source":["### 4. Evaluating model \n"]},{"cell_type":"markdown","metadata":{"id":"6AyKPKJFfVA5","colab_type":"text"},"source":["#### 1 - Evaluate your data qualitatively by inspecting 3 predictions for positive examples and 3 for negative ones on the test data"]},{"cell_type":"code","metadata":{"id":"T63LxBf_gAh3","colab_type":"code","outputId":"cfad4c58-acdc-47ed-da95-9e10bccf3999","executionInfo":{"status":"ok","timestamp":1585564351420,"user_tz":-120,"elapsed":1584,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["with torch.no_grad():\n","  label_count = [0, 0]\n","  n_samples = 5\n","  for sentence, tag in test_data:\n","          label_count[tag] += 1\n","          if label_count[tag] <= n_samples:\n","            sentence_in = prepare_sequence(sentence, word_to_ix)\n","            sentence_tag = 'Positive' if tag==1 else 'Negative'\n","            tag_scores = model(sentence_in)\n","            positive_score = torch.mean(torch.exp(tag_scores.squeeze(0)[:, 1])).item()\n","            print(\"{} sentence scored {} \\\"{}\\\".\"\n","            \"\".format(sentence_tag, positive_score,' '.join(sentence)) )\n","          if (label_count[0] >= n_samples) and (label_count[1] >= n_samples):\n","            break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Negative sentence scored 0.40734031796455383 \"In fact , this stinker smells like a direct - to - video release .\".\n","Negative sentence scored 0.3638526499271393 \"Avoid at ALL costs !\".\n","Negative sentence scored 0.3530091941356659 \"Star Trek V The final Frontier is the worst in the series .\".\n","Negative sentence scored 0.4768477976322174 \"The acting from all involved and that includes those like Shatner and Nimoy is bad and washed out and making them seem as old as they look in real life , the special effects are tacky like when Spock has to rescue Kirk on a jet pack when he falls down from a mountain .\".\n","Negative sentence scored 0.45193031430244446 \"The attempts at humor were pitiful and story is so awful it dosen't bear thinking about which basically involves a Vulcan stealing the Enterprise to find god ( seriously ) I just did n't care about any of this film and oh not to mention Uhura does a belly dance to distract male guards .\".\n","Positive sentence scored 0.24382783472537994 \"Editing : The editing of this film was phenomenal in my opinion .\".\n","Positive sentence scored 0.3998168706893921 \"When a song could explain the emotions of the subjects better , such as when Jay Adams ' unfortunate life was a subject of talk , the song Old Man by Neil Young was played , which evokes many emotions .\".\n","Positive sentence scored 0.4562082588672638 \"Cinematography : The film was shot in an interesting way .\".\n","Positive sentence scored 0.46290352940559387 \"Of course the footage from the 70s was grainy , but that only enhanced the film .\".\n","Positive sentence scored 0.46392199397087097 \"This film offers many delights and surprises .\".\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J4lCai_dlgNd","colab_type":"code","outputId":"8411f6a6-40b7-4a61-b136-f2a54f5ccd30","executionInfo":{"status":"ok","timestamp":1585579389346,"user_tz":-120,"elapsed":741,"user":{"displayName":"Angela Ciocan","photoUrl":"","userId":"14584136799251665478"}},"colab":{"base_uri":"https://localhost:8080/","height":166}},"source":["tag_scores"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.2755, -1.4238],\n","         [-0.8368, -0.5676],\n","         [-0.8061, -0.5917],\n","         [-1.6165, -0.2214],\n","         [-0.3636, -1.1880],\n","         [-2.1062, -0.1298],\n","         [-0.3040, -1.3388],\n","         [-0.1093, -2.2675]]])"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"pyJANoAfgBJ_","colab_type":"text"},"source":["\n","#### 2 - Evaluate your data quantitatively by measuring the [roc_auc](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) on the test set, and generating a [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"]},{"cell_type":"code","metadata":{"id":"FhDpNLn_3fLc","colab_type":"code","outputId":"960f8193-c80f-4bb3-cac9-7f54d4bf4034","executionInfo":{"status":"ok","timestamp":1583189491887,"user_tz":-60,"elapsed":777,"user":{"displayName":"Ghazi Felhi","photoUrl":"","userId":"05726306300565644804"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["from sklearn.metrics import roc_auc_score, classification_report\n","\n","ground_truth, scores = [], []\n","with torch.no_grad():\n","  for sentence, tag in test_data:\n","    sentence_in = prepare_sequence(sentence, word_to_ix)\n","    ground_truth.append(tag)\n","    tag_scores = model(sentence_in)\n","    scores.append(torch.mean(torch.exp(tag_scores.squeeze(0)[:, 1])).item())\n","\n","print(\"The AUC is \", roc_auc_score(ground_truth, scores))\n","print(\"Classification report:\\n\", classification_report(ground_truth, \n","                                                      np.array(scores)>0.5))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The AUC is  0.660342717258262\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       0.62      0.30      0.41        86\n","           1       0.62      0.86      0.72       114\n","\n","    accuracy                           0.62       200\n","   macro avg       0.62      0.58      0.56       200\n","weighted avg       0.62      0.62      0.59       200\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mm0a-kLygFtq","colab_type":"text"},"source":["\n","#### 3 - Evaluate how well your model behaves out of it's training domain (test it on one of the other given files)"]},{"cell_type":"code","metadata":{"id":"oQSGo1bKgGdx","colab_type":"code","outputId":"18293389-720c-422f-dab3-27149e969831","executionInfo":{"status":"ok","timestamp":1583189602446,"user_tz":-60,"elapsed":21262,"user":{"displayName":"Ghazi Felhi","photoUrl":"","userId":"05726306300565644804"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["\n","out_of_domain1, no_match = get_data(\"./amazon_cells_labelled.csv\")\n","print(\"Got {} examples, and failed to capture \"\n","\"{} examples.\".format(len(out_of_domain1), no_match))\n","out_of_domain2, no_match = get_data(\"./yelp_labelled.csv\")\n","print(\"Got {} examples, and failed to capture \"\n","\"{} examples.\".format(len(out_of_domain1), no_match))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Got 1000 examples, and failed to capture 0 examples.\n","Got 1000 examples, and failed to capture 8 examples.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W1VzoO0MtQmF","colab_type":"code","outputId":"bbd4243f-8d43-4bdd-c566-0b7ecafd4748","executionInfo":{"status":"ok","timestamp":1583189645895,"user_tz":-60,"elapsed":2620,"user":{"displayName":"Ghazi Felhi","photoUrl":"","userId":"05726306300565644804"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["\n","ground_truth, scores = [], []\n","with torch.no_grad():\n","  for sentence, tag in out_of_domain1:\n","    sentence_in = prepare_sequence(sentence, word_to_ix)\n","    ground_truth.append(tag)\n","    tag_scores = model(sentence_in)\n","    scores.append(torch.mean(torch.exp(tag_scores.squeeze(0)[:, 1])).item())\n","\n","print(\"The AUC for the first out of domain corpus is \", roc_auc_score(ground_truth, scores))\n","print(\"Classification report:\\n\", classification_report(ground_truth, \n","                                                      np.array(scores)>0.5))\n","\n","ground_truth, scores = [], []\n","with torch.no_grad():\n","  for sentence, tag in out_of_domain2:\n","    sentence_in = prepare_sequence(sentence, word_to_ix)\n","    ground_truth.append(tag)\n","    tag_scores = model(sentence_in)\n","    scores.append(torch.mean(torch.exp(tag_scores.squeeze(0)[:, 1])).item())\n","\n","print(\"The AUC for the second out of domain corpus is \", roc_auc_score(ground_truth, scores))\n","print(\"Classification report:\\n\", classification_report(ground_truth, \n","                                                      np.array(scores)>0.5))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The AUC for the first out of domain corpus is  0.573638\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       0.62      0.21      0.32       500\n","           1       0.53      0.87      0.66       500\n","\n","    accuracy                           0.54      1000\n","   macro avg       0.57      0.54      0.49      1000\n","weighted avg       0.57      0.54      0.49      1000\n","\n","The AUC for the second out of domain corpus is  0.6096778258324662\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       0.64      0.19      0.30       496\n","           1       0.53      0.89      0.66       496\n","\n","    accuracy                           0.54       992\n","   macro avg       0.58      0.54      0.48       992\n","weighted avg       0.58      0.54      0.48       992\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mVPLcfTetQFw","colab_type":"text"},"source":["### 4. Analysing token-wise tags\n","Go on and try to input some sentences of your own making, and to see how the score varies throughout the sentence."]},{"cell_type":"code","metadata":{"id":"ScyHqs1ct8Ea","colab_type":"code","colab":{}},"source":["import seaborn as sns\n","\n","def sentiment_heatmap(sentence):\n","  tokens = [str(w.text) for w in tokenizer(sentence)]\n","  sentence_in = prepare_sequence(tokens, word_to_ix)\n","  tag_scores = model(sentence_in)\n","  token_sentiments = torch.exp(tag_scores)[:, :, 1].detach().numpy()\n","  sns.heatmap(token_sentiments, xticklabels=tokens)\n","  plt.title(\"sentence score: \"\n","  \"{}\".format(torch.mean(torch.exp(tag_scores)[:, :, 1]).item()))\n","  plt.show()\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TcpN8RV1vJj_","colab_type":"code","outputId":"b7ca80d7-6cfa-4f1e-9484-99724445c7e4","executionInfo":{"status":"ok","timestamp":1583189738303,"user_tz":-60,"elapsed":1798,"user":{"displayName":"Ghazi Felhi","photoUrl":"","userId":"05726306300565644804"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["sample_sentences = [\n","                    \"Awful acting throughout the movie\",\n","                    \"I'd like to say that the actor was awful\",\n","                    \"Delightful scenery at the opening act of the movie\",\n","                    \"Bad movie, but pretty actress\"\n","]\n","for sentence in sample_sentences:\n","  sentiment_heatmap(sentence)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAV0AAAEICAYAAAD8yyfzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAV0AAAEICAYAAAD8yyfzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAV0AAAEvCAYAAADmYhJ9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYGY28Bx0zcwKctA1MyvIQdfMrKD/Be0thiBhHIwOAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWQAAAEICAYAAABoLY4BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAby0lEQVR4nO3debgdVZnv8e8vCXMIJISmJUASIGFU\noInQiChKwDgCDw7h4tPkikbuFQdoB2wVI1ODfW2v3dJCvAREhoA2Q9Q0qEAaZZAEDEOCQAxpk6DN\nkIRZIee894+1DqlszrDP4YS9dvH7PE89p2qtGtauXfXWu1fV3kcRgZmZtd6QVjfAzMwSB2Qzs0I4\nIJuZFcIB2cysEA7IZmaFcEA2MyuEA7KZWSFe9wFZ0gxJl7a6He1GybmSnszDuZLUw7z/IOnZyvCC\npE5Jo3P9JpJmSXpa0p8kndKw/GGSfifpeUk3SxpbqfuwpNty3byG5SZKuk7S45JWSbpB0m6V+qmS\nHpT0lKTHJP1A0ohKmy6U9F+SnpG0UNK7K8uOkxQNr+trlfpeX1NlvtPyeiZXykZJujLv1yckXdbV\nroZl356XPbOHdd+Y64c1lH9W0iOSnpP0gKSJlbptJV2e98lqSZc1LDtZ0t152RWSPtzdtm1gXvcB\n+fWo8QQdoOnAUcA+wJuA9wOf7G7GiDg7IoZ3DcC5wLyIeCLPMgOYAIwF3gF8UdKU3NbRwNXA14BR\nwALgysrqVwH/Fzinm01vDcwBdgO2A+4ErqvU3wocHBFbATsDw4Cu4DYMWA68HdgK+CpwlaRxjduo\nvLYzKuU9vqYuknYBPgT8sWGdZwIjgfHALrntMxqW3Qj4DvCbbl43ko4DNuqm/OPACcB7geHA+4An\nKrNcDfwJ2An4K+D/VJbdE7gc+Appn+wD3NXd9m2AIqJtBuBLwErgGeBB4LBcPgQ4Ffg98CRwFTAq\n140DAjge+APp4PtKrpsCvAi8BDwL3JPLtwIuJJ0oK0knyNBcNw34NelAXQ08Ary70sZRwEXAo7n+\n2krd+4CFwBrgNuBNPbxOAd8GHgOeBu4D9s51mwHfAv4LeCq3ZbNc9wFgUV7/PGCPyjqX5f13L/AX\nUsDZHvh34PH8Oj7Tj/fiNmB6ZfoE4I4mlhOwFDi+UvYocERl+gxgdh6fDtxWqdsCeAHYvWG9HycF\n+d62PSofC9t0UzccuASY28vy9wLHNBxXw3qYt8fXVCm7HnhPfm8mV8r/A/jflelPATc0LHsq8E3g\nYuDMhrqtgIeAv622kXSeLCefN920+YjclqE91F8OnNGq8//1MLS8AU03NGU5y4Ht8/Q4YJc8/lng\nDmAHYBPgAuCKynwBfJ8UzPbJAWmPXD8DuLRhW9fkdWxByhLuBD6Z66aRAvgngKHA/8onn3L9z0gZ\n3EhShvL2XL4fKcAemJc7Ph/8m3TzWt9Fyjy2JgWwPYA35LrzSMF2TF7PW/Jrngg8Bxyet/tFYAmw\ncV5uGelisGPeD0PyNk4DNiZliEuBd+X53wqs6eX9eAo4sDI9CXimiffxbaSL3/A8PTK/P9tV5vkg\ncF8e/w7wvYZ13E8OjJWyZgLyUcAfG8reml9L5P13RA/Lbgf8mXwhqBxXK4EVpIvw6GZeU57+EHBd\n5b2pBuT3AXPzekYCNwGfq9SPJQXc4XQfkM8DTqbhokHKeoN0viwnXYS/AQzJ9acBNwCXkhKb+eTj\nN9cvJV1Y7iMlK5eSEx8PgxTnWt2AphsKu5IC2mRgo4a6B6hc9YE3kILmsMpBuUOl/k5gah6fQSUg\n5xPvL+SsM5cdC9ycx6cBSyp1m+f1/3Xebicwspv2f4+G7IKU5b+9m3nfyboMZ0ilfAgpO9ynm2W+\nBlzVMO9K4NA8vQz4WKX+QOAPDev4MnBRk+9HB5UslfTxPMgXpl6WuxC4uDK9Y15u00rZ4cCyyvzn\nNKzjVmBaQ1mvAZl0sV4JHNtD/Zh8LEzspm4j4JfABZWy4aSL0LB8zPyYnMU28Zq2BB4GxlXem2pA\n3j5vrzMPvyBfWHP9dcBH8vjFVAJybtNC1j/2uwLyW/L0z0gX+3H5OPtErp+Z60/Ir3kq6dNW14Xm\nxdzWifn1/ztw2YY+919PQ9v0IUfEEuBzpJPmMUmzJW2fq8cC10haI2kNKUB3kE6ULn+qjD9POqC6\nM5Z0MP6xsr4LSJnyK9YVEc/n0eGkE3FVRKzuYb1/37XOvN4dSSdf42u9CfguKdN5TNLMfFNnNLAp\nqWum0fakboyudXSSsqAxlXmWN7Rn+4b2/APr77PePAtUbzSNAJ6NfOZ2R9LmpMzwBw3r6Vq+uq5n\nethOY32fJG0L/Bz4t4i4ort5ImIlqQthdsOyQ4AfkoLRSZX5n42IBRGxNiL+O9cdIWnLJl7TDOCH\nEbGshyZfRQqUW+blfk/KRpH0fmDLiLiycaHc1n8DPhsRa7tZ7wv57zcjYk3e/gWkbpOu+mURcWFE\nvBQRs0nHzMGV+osi4qGIeBY4u7KsDYK2CcgAEXF5RLyVFEyCdHMI0kHz7ojYujJsmk+yPlfbML2c\nlCGPrqxrRETs1cS6lgOjJG3dQ91ZDW3cvJcA8S8RsT+wJykj+QKp//vPpBs9jR4l7RcgPQVBCvjV\nfVB9rcuBRxras2VENHuCLSJ1/3TZJ5f15mjSTbh5LzcoXbz+2Mu61tuOpC1Ir7+vbXXNP5IUjOdE\nxFl9zD6Myr7N+/BC0kXqmIh4qZdlu/btkCZe02HAZ/LTF38ivU9XSfpSrt+XlI0/lwPf+awLfIcB\nkyrLfgT4nKTrSMF7EnBlrpufl1kh6RDSJ7IXWf84qI7fyyvPh97qe7z42gC1OkVvdiD1Ib+T1F+6\nMTAL+EGuO5l0ko/N09sCR+bxcTTcfMnzfjyPn0i6MVbtGriO1Hc5gnTR2oV1fcHTgF83tC2AXfP4\nz0g3P7r6kN+WyyeRguCBpH7hLUh3urfs5rW+Oc+3UZ7veuAbue484EZSRjwUOCjvk91IfaCH5eU+\nT+rzq/YhVz8WDwXuJt3o2yxP7w28ucn340TSJ5ExuS2LgBP7WObnwOndlJ8D/GfeZ7uTgtmUynv5\nFHAM6dPBuVRuHuZ2b5rbc0se3yjXjSB1T323h/YcB+yUx8fmNlxdqT+fdG9ieDfLHpj3+RBgG9J9\ng5ubfE3bkLq4uoblpE8OXf3qNwP/mt+XzUhZ7225bsuGZa8k3QAelY+rat2bScfmmMpxcAnw07ye\nHYDfASfkulGkG9HH5/36QdIFtKvL4mOkfuedSV11V5Ey/ZbHh7oMLW9A0w1Nj1bdSfrYtyofVF03\n+IYAp5AygGdIH/HOznXj6D0gb0MKyKuBu3PZVqQ+3xU5GPyWdX3O0+g9II8ifST/77zO6gk+hZS1\nrMkn6I/oPiAfRspGniVlxZdVTtbNSI95rcxtu4V1T1kcDSzO5f8J7FVZ5zIqATmXbQ9cQeqCWU0K\nPpNz3SGkLoie3g+R7vKvysM3qfQf57YfUpkeA6zt2k8N69qEdIF9Ou+3UxrqJ+fA8UJ+78ZV6qbl\n/V8dLs51x7PuZt2zlaErCJ+V3+Pn8t+Z5CcwWPcp7M8Nyx6X648lBafn8nt5CfDXzb6mhte33ntD\netztJ6Qba6tIF+QJPSx7MQ039Sp143jlsT+C1C3zDOlCcFrD+3YI6abds6RHDA9pWOc3SE/lPE7q\nynnF/RIPAx+6ngwwM7MWa6s+ZDOzOnNANjMrhAOymVkhHJDNzAoxGD8y06sr33BcW901PO7Jea1u\nQr/9v23f0eom9Nuwtjoq4CP3nt7qJvTbxN2ObnUT+u2RJ+/p9hcD++OlJ5Y2fXRtNHrnV729weQM\n2cysEBs8QzYze011drS6BQPmgGxm9dLR3c94tAcHZDOrlfS7Wu3JAdnM6qXTAdnMrAzOkM3MCuGb\nemZmhXCGbGZWhvBTFmZmhfBNPTOzQrjLwsysEL6pZ2ZWCGfIZmaF8E09M7NC+KaemVkZItyHbGZW\nBvchm5kVwl0WZmaFcIZsZlaIjpda3YIBc0A2s3pxl4WZWSHcZWFmVghnyGZmhXBANjMrQ/imnplZ\nIdyHbGZWCHdZmJkVwhmymVkhnCGbmRXCGbKZWSHW+gfqzczK4AzZzKwQ7kM2MyuEM2Qzs0I4QzYz\nK4QzZDOzQvgpCzOzQkS0ugUDNqTVDTAzG1Sdnc0PfZA0RdKDkpZIOrWb+p0k3Szpt5LulfSeSt2X\n83IPSnpXM013hmxm9TJIN/UkDQXOAw4HVgDzJc2JiMWV2b4KXBUR35O0JzAXGJfHpwJ7AdsDv5Q0\nMSI6etumM2Qzq5fobH7o3QHAkohYGhEvArOBIxu3BozI41sBj+bxI4HZEfGXiHgEWJLX1ytnyGZW\nLx29JqHrkTQdmF4pmhkRM/P4GGB5pW4FcGDDKmYAP5f0aWALYHJl2Tsalh3TV3sckM2sXvrRZZGD\n78w+Z+zZscDFEfEtSQcBP5S090BX5oBsZvUyeF8MWQnsWJneIZdVnQBMAYiI2yVtCoxuctlXcB+y\nmdXL4PUhzwcmSBovaWPSTbo5DfP8ATgMQNIewKbA43m+qZI2kTQemADc2dcGnSGbWa1E5+A8hxwR\nayWdBNwADAVmRcQiSacDCyJiDvD3wPclnUy6wTctIgJYJOkqYDGwFvhUX09YgAOymdXNIP6WRUTM\nJT3KVi07rTK+GDi4h2XPAs7qz/YckM2sXvrxlEVpHJDNrF78a29mZoVwQDYzK0Qb/7iQA7KZ1Ysz\nZDOzQgzSY2+t4IBsZvXipyzMzMoQ7rIwMyuEuyzMzArhf3JqZlYIZ8hmZoVY65t6ZmZlcJeFmVkh\n3GVhZlYGP/ZmZlYKZ8hmZoVwQDYzK4S/Om1mVobB+p96reCAbGb14oBsZlYIP2VhZlYIZ8hmZoVw\nQDYzK0N0uMvCzKwMzpDNzMrgx97MzErhgGxmVoj27UJ2QDazeom17RuRHZDNrF7aNx47IJtZvfim\nnplZKZwhm5mVwRmymVkpnCGbmZUh1ra6BQPngGxmtRLOkM3MCtHGAXlIqxtgZjaYorP5oS+Spkh6\nUNISSad2U/9tSQvz8JCkNZW6jkrdnGba7gzZzGplsLosJA0FzgMOB1YA8yXNiYjFL28r4uTK/J8G\n9qus4oWI2Lc/23SGbGa1Eh1qeujDAcCSiFgaES8Cs4Eje5n/WOCKV9N2B2Qzq5X+dFlImi5pQWWY\nXlnVGGB5ZXpFLnsFSWOB8cBNleJN8zrvkHRUM213l4WZ1Up09pn5rps3YiYwcxA2OxX4cUR0VMrG\nRsRKSTsDN0m6LyJ+39tKnCGbWa0M4k29lcCOlekdcll3ptLQXRERK/PfpcA81u9f7pYDspnVSoSa\nHvowH5ggabykjUlB9xVPS0jaHRgJ3F4pGylpkzw+GjgYWNy4bCN3WZhZrQzWUxYRsVbSScANwFBg\nVkQsknQ6sCAiuoLzVGB2RFR/RGMP4AJJnaTE95zq0xk9cUA2s1rp7PvpiaZFxFxgbkPZaQ3TM7pZ\n7jbgjf3dngOymdVKf27qlcYB2cxqxQHZzKwQ0b4/h+yAbGb14gzZzKwQTTzOViwHZDOrlY5BfMri\nteaAbGa14gzZzKwQ7kM2MyuEn7IwMyuEM2Qzs0J0dLbvb6Y5IJtZrbjLwsysEJ11fsoi/9bnkaz7\n1yUrgTkR8cCGbJiZ2UC082NvvXa2SPoS6R/7CbgzDwKu6O5fYpuZtVpE80Np+sqQTwD2ioiXqoWS\n/hlYBJzT3UL5HwVOB/j4iAOYvPmug9BUM7O+tXOXRV+3IzuB7bspf0Ou61ZEzIyISRExycHYzF5L\nHZ1Dmh5K01eG/DngRkkPs+7fYe8E7AqctCEbZmY2EAX2RDSt14AcEddLmggcwPo39eY3/LtrM7Mi\ntHOXRZ9PWUREJ3DHa9AWM7NXrZ2fsvBzyGZWK4P0T6dbwgHZzGolcIZsZlaEte6yMDMrgzNkM7NC\nuA/ZzKwQzpDNzArhDNnMrBAdzpDNzMrQxv/ByQHZzOql0xmymVkZavvjQmZm7cY39czMCtEpd1mY\nmRWhnX8X2AHZzGrFT1mYmRXCT1mYmRWinZ+yKO+//JmZvQqdan7oi6Qpkh6UtETSqd3Uf1vSwjw8\nJGlNpe54SQ/n4fhm2u4M2cxqZbAee5M0FDgPOBxYAcyXNCciFnfNExEnV+b/NLBfHh8FfB2YREra\n78rLru5tm86QzaxWOtT80IcDgCURsTQiXgRmA0f2Mv+xwBV5/F3ALyJiVQ7CvwCm9LVBB2Qzq5XO\nfgx9GAMsr0yvyGWvIGksMB64qb/LVjkgm1mt9CcgS5ouaUFlmD7AzU4FfhwRr+oxaPchm1mt9Odf\n6kXETGBmD9UrgR0r0zvksu5MBT7VsOyhDcvO66s9zpDNrFYGsctiPjBB0nhJG5OC7pzGmSTtDowE\nbq8U3wAcIWmkpJHAEbmsV86QzaxWBuur0xGxVtJJpEA6FJgVEYsknQ4siIiu4DwVmB0RUVl2laQz\nSEEd4PSIWNXXNh2QzaxWBvOr0xExF5jbUHZaw/SMHpadBczqz/YckM2sVvzzm2ZmhXBANjMrRDv/\nloUDspnVin9+08ysEP6BejOzQnS2caeFA7KZ1Ypv6pmZFaJ982MHZDOrGWfIZmaFWKv2zZEdkM2s\nVto3HDsgm1nNuMvCzKwQfuzNzKwQ7RuOHZDNrGbcZWFmVoiONs6RHZDNrFacIZuZFSKcIZuZlcEZ\nsplZIfzYm5lZIdo3HDsgm1nNrG3jkOyAbGa14pt6ZmaF8E09M7NCOEM2MyuEM2Qzs0J0hDNkM7Mi\n+DlkM7NCuA/ZzKwQ7kM2MyuEuyzMzArhLgszs0L4KQszs0K4y8LMrBC+qWdmVgj3IZuZFaKduyyG\ntLoBZmaDKSKaHvoiaYqkByUtkXRqD/N8WNJiSYskXV4p75C0MA9zmmm7M2Qzq5WOQcqQJQ0FzgMO\nB1YA8yXNiYjFlXkmAF8GDo6I1ZL+qrKKFyJi3/5s0xmymdVKJ9H00IcDgCURsTQiXgRmA0c2zPMJ\n4LyIWA0QEY+9mrY7IJtZrQxil8UYYHllekUuq5oITJR0q6Q7JE2p1G0qaUEuP6qZtrvLwsxqpT83\n9SRNB6ZXimZGxMx+bG4YMAE4FNgBuEXSGyNiDTA2IlZK2hm4SdJ9EfH7vlZmZlYb/XnsLQffngLw\nSmDHyvQOuaxqBfCbiHgJeETSQ6QAPT8iVuZtLJU0D9gP6DUgu8vCzGqlI6LpoQ/zgQmSxkvaGJgK\nND4tcS0pO0bSaFIXxlJJIyVtUik/GFhMH5whm1mtDNZzyBGxVtJJwA3AUGBWRCySdDqwICLm5Loj\nJC0GOoAvRMSTkt4CXCCpk5T4nlN9OqMnDshmViuD+cWQiJgLzG0oO60yHsApeajOcxvwxv5uzwHZ\nzGqlmS98lMoB2cxqpZ2/Ou2AbGa14h8XMjMrREe07w9wOiCbWa24D9nMrBDuQzYzK4T7kM3MCtHp\nLgszszI4QzYzK4SfsjAzK4S7LMzMCuEuCzOzQjhDNjMrhDNkM7NCdERHq5swYA7IZlYr/uq0mVkh\n/NVpM7NCOEM2MyuEn7IwMyuEn7IwMyuEvzptZlYI9yGbmRXCfchmZoVwhmxmVgg/h2xmVghnyGZm\nhfBTFmZmhfBNPTOzQrjLwsysEP6mnplZIZwhm5kVop37kNXOVxNJ0yNiZqvb0ax2ay+0X5vbrb3g\nNts6Q1rdgFdpeqsb0E/t1l5ovza3W3vBbbas3QOymVltOCCbmRWi3QNyu/VhtVt7of3a3G7tBbfZ\nsra+qWdmViftniGbmdWGA7KZWSGKDciSOiQtlHSPpLslvaWfy8+Q9PkN1b7BJulESX/X6na0A0nj\nJN3fj/kP7e/x0wqSjpK0Z2V6mqTtW9ietthvdVJsQAZeiIh9I2If4MvAP7a6QRtSRJwfEZe0uh01\ndShQRGCRNLSX6qOAPSvT04CWBWR62W+S/C3fDaDkgFw1AlgNIGm4pBtz1nyfpCO7ZpL0FUkPSfo1\nsNuGakzO0H4n6eK8vcskTZZ0q6SHJR0gaZSkayXdK+kOSW+SNETSMklbV9b1sKTtqhm9pF0kXS/p\nLkm/krT7hnotbWxY3u8PSPqxpM3zvh0NIGmSpHmSxgEnAifnT1yHbKgGVY6L7tp1rqS7gQ919/7m\nTPQDwD/ldn4JmARclqffK+nayrYOl3TNANt5bd72IknTc9mUfE7dk8+vcTTst3y8ny/pN8A3JW0h\naZakOyX9tutclLRXLluYj/8Jed6f5fXfL+kjr2Zf11ZEFDkAHcBC4HfAU8D+uXwYMCKPjwaWAAL2\nB+4DNicF8CXA5zdQ28YBa4E3ki5qdwGzcjuOBK4F/hX4ep7/ncDCPP4d4H/m8QOBX+bxGV3tBW4E\nJlTmuanV70dJQ97/ARycp2cBnweWAaNz2SRgXuO+bWG7vliZr9v3F7gY+GBlvnnApDyufC5sm6cv\nB94/wHaOyn83A+4HtgOWA+Mb6tfbb7l9PwWG5umzgY/m8a2Bh4At8rF/XC7fOG/nGOD7lXVt1erj\nqMSh5I8dL0TEvgCSDgIukbQ36cA8W9LbgE5gDOmAOgS4JiKez8vM2cDteyQi7svbWgTcGBEh6T7S\niTmWdBASETdJ2kbSCOBK4DTgImBqnn6ZpOGkj4k/ktRVvMkGfi3taHlE3JrHLwU+08rGVPTUrith\n4O9vPrZ+CHxU0kXAQcBA7zl8RtLReXxH0tegb4mIR/K2VvWy7I8ioiOPHwF8oHKvZlNgJ+B24CuS\ndgCujoiH83nxLUnnAj+NiF8NsO21VnJAfllE3J4/im4LvCf/3T8iXpK0jHQgvNb+UhnvrEx3kvbr\nSz0sdzuwq6RtSX2GZzbUDwHWdF2MrEeND9AH6VNLVzdcK46JrnZ0N/1c/vtq3t+LgJ8AfyYFxrX9\nXYGkQ4HJwEER8bykeaRPos12iz1XGRdwTEQ82DDPA7lb473AXEmfzEnJ35DO3zMl3RgRp/e3/XXX\nFn3IuQ91KPAksBXwWA7G7yBlogC3AEdJ2kzSlsD7W9Pal/0KOA5ePgmeiIinI31euwb4Z+CBiHiy\nulBEPA08IulDeVlJ2uc1bXlF7k8c06rt92Kn/MkJ4H8AvyZ1Deyfy46pzPsMsGUL2/WyPt7fxnau\nNx0RjwKPAl8lBeeB2ApYnYPx7sDfki5eb5M0PrdpVA/taXQD8GnlVF/SfvnvzsDSiPgX4DrgTUpP\nizwfEZcC/wT8zQDbX2slB+TN8k2BhaSPe8fnj0qXAZPyR6C/I/WrERF35/nuAf4DmN+aZr9sBrC/\npHuBc4DjK3VXAh+lobui4jjgBEn3AItI/dKvOUlDgF2B3j7CtsqDwKckPQCMBL4HfAP4jqQFpHsQ\nXX4CHL2hb+r10q5GPb2/s4Ev5Btku5D6bM/P7d4sz3MZqVvkgQG273rSDdEHSMflHcDjpG6Lq3Ob\nuo7LvvbbGcBGwL252+6MXP5h4P587u4NXEK633JnLvs6r/xkaPir09aL3Gf/sYg4pdVtaQf5yYSf\nRsTeG3Ab3wV+GxEXbqhtWOs4IJsNkg0dkCXdRerDPTwi/tLX/NZ+HJDNzApRch+ymdnrigOymVkh\nHJDNzArhgGxmVggHZDOzQvx/P59gUyqochcAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"xAcuZCZOzEW2","colab_type":"text"},"source":["**Question**\n","- What would you say about the interpretability of the results ? to what can we blame for this ?\n","- Do you think averaging the token scores was a good decision ? How could we do better ?"]}]}